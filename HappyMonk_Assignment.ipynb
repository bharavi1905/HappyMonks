{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0608c7ea",
   "metadata": {},
   "source": [
    "# Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8719b95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d714d603",
   "metadata": {},
   "source": [
    "# Reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a967ca5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_banknote_authentication.txt', sep=',', header=None,\n",
    "                  names=['variance', 'skewness', 'curtosis', 'entropy', 'class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c694bace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.6661</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.1674</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.6383</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.5228</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.4552</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variance  skewness  curtosis  entropy  class\n",
       "0   3.62160    8.6661   -2.8073 -0.44699      0\n",
       "1   4.54590    8.1674   -2.4586 -1.46210      0\n",
       "2   3.86600   -2.6383    1.9242  0.10645      0\n",
       "3   3.45660    9.5228   -4.0112 -3.59440      0\n",
       "4   0.32924   -4.4552    4.5718 -0.98880      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96736939",
   "metadata": {},
   "source": [
    "# Dataset information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62e2b13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1372 entries, 0 to 1371\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   variance  1372 non-null   float64\n",
      " 1   skewness  1372 non-null   float64\n",
      " 2   curtosis  1372 non-null   float64\n",
      " 3   entropy   1372 non-null   float64\n",
      " 4   class     1372 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 53.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "744747e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.433735</td>\n",
       "      <td>1.922353</td>\n",
       "      <td>1.397627</td>\n",
       "      <td>-1.191657</td>\n",
       "      <td>0.444606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.842763</td>\n",
       "      <td>5.869047</td>\n",
       "      <td>4.310030</td>\n",
       "      <td>2.101013</td>\n",
       "      <td>0.497103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-7.042100</td>\n",
       "      <td>-13.773100</td>\n",
       "      <td>-5.286100</td>\n",
       "      <td>-8.548200</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.773000</td>\n",
       "      <td>-1.708200</td>\n",
       "      <td>-1.574975</td>\n",
       "      <td>-2.413450</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.496180</td>\n",
       "      <td>2.319650</td>\n",
       "      <td>0.616630</td>\n",
       "      <td>-0.586650</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.821475</td>\n",
       "      <td>6.814625</td>\n",
       "      <td>3.179250</td>\n",
       "      <td>0.394810</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.824800</td>\n",
       "      <td>12.951600</td>\n",
       "      <td>17.927400</td>\n",
       "      <td>2.449500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          variance     skewness     curtosis      entropy        class\n",
       "count  1372.000000  1372.000000  1372.000000  1372.000000  1372.000000\n",
       "mean      0.433735     1.922353     1.397627    -1.191657     0.444606\n",
       "std       2.842763     5.869047     4.310030     2.101013     0.497103\n",
       "min      -7.042100   -13.773100    -5.286100    -8.548200     0.000000\n",
       "25%      -1.773000    -1.708200    -1.574975    -2.413450     0.000000\n",
       "50%       0.496180     2.319650     0.616630    -0.586650     0.000000\n",
       "75%       2.821475     6.814625     3.179250     0.394810     1.000000\n",
       "max       6.824800    12.951600    17.927400     2.449500     1.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23f70a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>variance</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.264026</td>\n",
       "      <td>-0.380850</td>\n",
       "      <td>0.276817</td>\n",
       "      <td>-0.724843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skewness</th>\n",
       "      <td>0.264026</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.786895</td>\n",
       "      <td>-0.526321</td>\n",
       "      <td>-0.444688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>curtosis</th>\n",
       "      <td>-0.380850</td>\n",
       "      <td>-0.786895</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.318841</td>\n",
       "      <td>0.155883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entropy</th>\n",
       "      <td>0.276817</td>\n",
       "      <td>-0.526321</td>\n",
       "      <td>0.318841</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.023424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <td>-0.724843</td>\n",
       "      <td>-0.444688</td>\n",
       "      <td>0.155883</td>\n",
       "      <td>-0.023424</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          variance  skewness  curtosis   entropy     class\n",
       "variance  1.000000  0.264026 -0.380850  0.276817 -0.724843\n",
       "skewness  0.264026  1.000000 -0.786895 -0.526321 -0.444688\n",
       "curtosis -0.380850 -0.786895  1.000000  0.318841  0.155883\n",
       "entropy   0.276817 -0.526321  0.318841  1.000000 -0.023424\n",
       "class    -0.724843 -0.444688  0.155883 -0.023424  1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "992fcf7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "762 records belongs to class 0\n",
      "610 records belongs to class 1\n"
     ]
    }
   ],
   "source": [
    "x0, x1 = df['class'].value_counts()\n",
    "print('{} records belongs to class 0'.format(x0))\n",
    "print('{} records belongs to class 1'.format(x1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105281d7",
   "metadata": {},
   "source": [
    "# Reading data from text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f2f93b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt('data_banknote_authentication.txt', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912c8113",
   "metadata": {},
   "source": [
    "## slicing features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea5f117a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1372, 4) (1372,)\n"
     ]
    }
   ],
   "source": [
    "X,y = data[:,:4], data[:,-1]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244de00d",
   "metadata": {},
   "source": [
    "## splitting dataset for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0b7d380",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0927d3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1097) (4, 275)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = X_train.T, X_test.T\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9abfa9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1097) (1, 275)\n"
     ]
    }
   ],
   "source": [
    "y_train, y_test = y_train.reshape(1, y_train.shape[0]), y_test.reshape(1, y_test.shape[0])\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f576911",
   "metadata": {},
   "source": [
    "# 1) Defining Structure\n",
    "\n",
    "Defining structure of neural network, i.e; number of input units and no.of hidden unitss.\n",
    "Input units are nothing but number of features that are available (4).\n",
    "We can make hidden layer to 4 units and a single layer output for binary classification.\n",
    "\n",
    "<img src='network.png' width='500' height='500'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8c88d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def structure(X,Y):\n",
    "    input_unit = X.shape[0] #4\n",
    "    hidden_unit = 4\n",
    "    output_unit = Y.shape[0] #4\n",
    "    \n",
    "    return (input_unit, hidden_unit, output_unit)\n",
    "\n",
    "input_unit, hidden_unit, output_unit = structure(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c715c9c9",
   "metadata": {},
   "source": [
    "# 2) Parameters Initialization\n",
    "\n",
    "Here weights and bias matrices are to be initilaized. Weights are choosen randomly and bias is set to zero initially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6a5fb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameters_init(input_unit, hidden_unit, output_unit):\n",
    "    \n",
    "    np.random.seed(2)\n",
    "    W1 = np.random.randn(hidden_unit, input_unit)*0.01\n",
    "    b1 = np.zeros((hidden_unit, 1))\n",
    "    W2 = np.random.randn(output_unit, hidden_unit)*0.01\n",
    "    b2 = np.zeros((output_unit,1))\n",
    "    parameters = {'W1':W1, 'b1':b1, 'W2':W2, 'b2':b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c72eff",
   "metadata": {},
   "source": [
    "# 3) Forward Propagation\n",
    "\n",
    "We need to compute the activation function for each layer, given the set of input features(X). For hidden layer, we can make use of any activation function. In this we will use numpy's inbuilt **tanh** function. For output layer **sigmoid** function is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b675ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "\n",
    "    Z1 = np.dot(W1, X) + b1\n",
    "    A1 = np.tanh(Z1)\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "\n",
    "    temp = {'Z1':Z1, 'A1':A1, 'Z2':Z2, 'A2':A2}\n",
    "    return A2, temp "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75d719c",
   "metadata": {},
   "source": [
    "# 4) Cross-entropy cost\n",
    "\n",
    "Next, we need to compute cross-entropy cost. Using A2 we can compute cross-entropy cost using following formula.\n",
    "\n",
    "<img src='cost.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32b95ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_cost(A2, Y, parameters):\n",
    "    \n",
    "    m = Y.shape[1] #no.of training examples\n",
    "    logs = np.multiply(np.log(A2),Y) + np.multiply((1-Y), np.log(1-A2))\n",
    "    cost = -np.sum(logs)/m\n",
    "    cost = float(np.squeeze(cost))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15992824",
   "metadata": {},
   "source": [
    "# 5) Backward Propagation\n",
    "\n",
    "In this step, we need to calculate the gradient w.r.to different parameters.\n",
    "<img src='bck.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd044951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(parameters, temp, X,Y):\n",
    "    m = X.shape[1]\n",
    "    W1 = parameters['W1']\n",
    "    A1 = temp['A1']\n",
    "    W2 = parameters['W2']\n",
    "    A2 = temp['A2']\n",
    "\n",
    "    dZ2 = A2-Y\n",
    "    dW2 = (1/m)*np.dot(dZ2, A1.T)\n",
    "    db2 = (1/m)*np.sum(dZ2, axis=1, keepdims=True)\n",
    "    dZ1 = np.multiply(np.dot(W2.T, dZ2), 1-np.power(A1,2))\n",
    "    dW1 = (1/m)*np.dot(dZ1, X.T)\n",
    "    db1 = (1/m)*np.sum(dZ1, axis=1, keepdims=True)\n",
    "    grads = {'dW1':dW1, 'dW2':dW2, 'db1':db1, 'db2':db2}\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb9aa3e",
   "metadata": {},
   "source": [
    "# 6) Updating Parameters\n",
    "\n",
    "We use Gradient Descent algorithm to update the parameters.\n",
    "<img src='gd.png' width='350' height='350'>\n",
    "\n",
    "ùõº is the learning rate and ùúÉ is the parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2adb1abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(parameters, grads, learning_rate=0.01):\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "\n",
    "    dW1 = grads['dW1']\n",
    "    db1 = grads['db1']\n",
    "    dW2 = grads['dW2']\n",
    "    db2 = grads['db2']\n",
    "\n",
    "    W1 = W1 - learning_rate*dW1\n",
    "    b1 = b1 - learning_rate*db1\n",
    "    W2 = W2 - learning_rate*dW2\n",
    "    b2 = b2 - learning_rate*db2\n",
    "\n",
    "    parameters = {'W1':W1, 'b1':b1, 'W2':W2, 'b2':b2}\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db19012e",
   "metadata": {},
   "source": [
    "# 7) Neural Network Model\n",
    "\n",
    "In this final step we put all functions together to build a neural network model with a single hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17820bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network_model(X,Y, hidden_unit, num_iterations=1000):\n",
    "    np.random.seed(3)\n",
    "    input_unit = structure(X,Y)[0]\n",
    "    output_unit = structure(X,Y)[2]\n",
    "\n",
    "    parameters = parameters_init(input_unit, hidden_unit, output_unit)\n",
    "\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "\n",
    "    loss = []\n",
    "    for i in range(0, num_iterations):\n",
    "        A2,temp = forward_propagation(X, parameters)\n",
    "        cost = cross_entropy_cost(A2, Y, parameters)\n",
    "        grads = backward_propagation(parameters, temp, X, Y)\n",
    "        parameters = gradient_descent(parameters, grads)\n",
    "        loss.append(cost)\n",
    "        if i%5==0:\n",
    "          print('cost after {} iterations is {}'.format(i, cost))\n",
    "\n",
    "    return parameters, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef7a486c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost after 0 iterations is 0.692974818256008\n",
      "cost after 5 iterations is 0.6926648536671564\n",
      "cost after 10 iterations is 0.6923506007257978\n",
      "cost after 15 iterations is 0.6920278241523767\n",
      "cost after 20 iterations is 0.6916920458848873\n",
      "cost after 25 iterations is 0.6913384704152844\n",
      "cost after 30 iterations is 0.6909619193114926\n",
      "cost after 35 iterations is 0.6905567783249688\n",
      "cost after 40 iterations is 0.6901169612153037\n",
      "cost after 45 iterations is 0.6896358948529898\n",
      "cost after 50 iterations is 0.6891065300308953\n",
      "cost after 55 iterations is 0.6885213814529922\n",
      "cost after 60 iterations is 0.6878725983665469\n",
      "cost after 65 iterations is 0.6871520642219461\n",
      "cost after 70 iterations is 0.6863515198266376\n",
      "cost after 75 iterations is 0.6854627003038677\n",
      "cost after 80 iterations is 0.6844774726883398\n",
      "cost after 85 iterations is 0.683387959237621\n",
      "cost after 90 iterations is 0.6821866323716287\n",
      "cost after 95 iterations is 0.6808663708916239\n",
      "cost after 100 iterations is 0.6794204733120174\n",
      "cost after 105 iterations is 0.6778426315375122\n",
      "cost after 110 iterations is 0.6761268750608289\n",
      "cost after 115 iterations is 0.674267500725816\n",
      "cost after 120 iterations is 0.6722590048317224\n",
      "cost after 125 iterations is 0.6700960327212819\n",
      "cost after 130 iterations is 0.6677733566076831\n",
      "cost after 135 iterations is 0.6652858864459862\n",
      "cost after 140 iterations is 0.6626287125485751\n",
      "cost after 145 iterations is 0.6597971736466778\n",
      "cost after 150 iterations is 0.656786941081276\n",
      "cost after 155 iterations is 0.6535941091140751\n",
      "cost after 160 iterations is 0.650215282793697\n",
      "cost after 165 iterations is 0.6466476577537552\n",
      "cost after 170 iterations is 0.6428890898305969\n",
      "cost after 175 iterations is 0.6389381554732061\n",
      "cost after 180 iterations is 0.6347942057465262\n",
      "cost after 185 iterations is 0.6304574168416028\n",
      "cost after 190 iterations is 0.6259288384299883\n",
      "cost after 195 iterations is 0.6212104384566473\n",
      "cost after 200 iterations is 0.6163051399445867\n",
      "cost after 205 iterations is 0.6112168431120806\n",
      "cost after 210 iterations is 0.6059504254535896\n",
      "cost after 215 iterations is 0.6005117138575229\n",
      "cost after 220 iterations is 0.5949074261847491\n",
      "cost after 225 iterations is 0.5891450842834897\n",
      "cost after 230 iterations is 0.5832329050565309\n",
      "cost after 235 iterations is 0.5771796797633065\n",
      "cost after 240 iterations is 0.5709946533701515\n",
      "cost after 245 iterations is 0.5646874151304608\n",
      "cost after 250 iterations is 0.5582678089358947\n",
      "cost after 255 iterations is 0.5517458680235875\n",
      "cost after 260 iterations is 0.5451317742425281\n",
      "cost after 265 iterations is 0.5384358381159327\n",
      "cost after 270 iterations is 0.5316684930062664\n",
      "cost after 275 iterations is 0.5248402951244728\n",
      "cost after 280 iterations is 0.5179619209742384\n",
      "cost after 285 iterations is 0.5110441549153464\n",
      "cost after 290 iterations is 0.5040978615517901\n",
      "cost after 295 iterations is 0.4971339402097105\n",
      "cost after 300 iterations is 0.4901632614615807\n",
      "cost after 305 iterations is 0.48319658810580995\n",
      "cost after 310 iterations is 0.4762444849317655\n",
      "cost after 315 iterations is 0.46931722280362204\n",
      "cost after 320 iterations is 0.4624246830193468\n",
      "cost after 325 iterations is 0.4555762675976457\n",
      "cost after 330 iterations is 0.44878082026302596\n",
      "cost after 335 iterations is 0.4420465616402489\n",
      "cost after 340 iterations is 0.4353810407516151\n",
      "cost after 345 iterations is 0.4287911035287706\n",
      "cost after 350 iterations is 0.4222828778528152\n",
      "cost after 355 iterations is 0.4158617737118241\n",
      "cost after 360 iterations is 0.40953249644617856\n",
      "cost after 365 iterations is 0.40329907072598964\n",
      "cost after 370 iterations is 0.3971648728270325\n",
      "cost after 375 iterations is 0.3911326688820031\n",
      "cost after 380 iterations is 0.3852046570197825\n",
      "cost after 385 iterations is 0.3793825116101662\n",
      "cost after 390 iterations is 0.3736674281597597\n",
      "cost after 395 iterations is 0.3680601677237701\n",
      "cost after 400 iterations is 0.3625610999875713\n",
      "cost after 405 iterations is 0.35717024442044204\n",
      "cost after 410 iterations is 0.3518873091084335\n",
      "cost after 415 iterations is 0.34671172703548275\n",
      "cost after 420 iterations is 0.34164268970608824\n",
      "cost after 425 iterations is 0.3366791780948208\n",
      "cost after 430 iterations is 0.3318199909736345\n",
      "cost after 435 iterations is 0.32706377071293014\n",
      "cost after 440 iterations is 0.32240902668146276\n",
      "cost after 445 iterations is 0.31785415638749126\n",
      "cost after 450 iterations is 0.3133974645122448\n",
      "cost after 455 iterations is 0.30903717998931823\n",
      "cost after 460 iterations is 0.30477147128187637\n",
      "cost after 465 iterations is 0.3005984600049468\n",
      "cost after 470 iterations is 0.29651623303362373\n",
      "cost after 475 iterations is 0.292522853230422\n",
      "cost after 480 iterations is 0.28861636891683345\n",
      "cost after 485 iterations is 0.284794822205708\n",
      "cost after 490 iterations is 0.2810562563026606\n",
      "cost after 495 iterations is 0.27739872187646714\n",
      "cost after 500 iterations is 0.2738202825904684\n",
      "cost after 505 iterations is 0.27031901987942725\n",
      "cost after 510 iterations is 0.26689303704912\n",
      "cost after 515 iterations is 0.2635404627692168\n",
      "cost after 520 iterations is 0.2602594540237223\n",
      "cost after 525 iterations is 0.2570481985774068\n",
      "cost after 530 iterations is 0.2539049170112459\n",
      "cost after 535 iterations is 0.250827864374899\n",
      "cost after 540 iterations is 0.2478153314996578\n",
      "cost after 545 iterations is 0.24486564601108518\n",
      "cost after 550 iterations is 0.24197717307670452\n",
      "cost after 555 iterations is 0.2391483159205729\n",
      "cost after 560 iterations is 0.2363775161333628\n",
      "cost after 565 iterations is 0.23366325380364764\n",
      "cost after 570 iterations is 0.23100404749343428\n",
      "cost after 575 iterations is 0.22839845407857307\n",
      "cost after 580 iterations is 0.22584506847249367\n",
      "cost after 585 iterations is 0.22334252324974127\n",
      "cost after 590 iterations is 0.22088948818400228\n",
      "cost after 595 iterations is 0.21848466971369856\n",
      "cost after 600 iterations is 0.2161268103467779\n",
      "cost after 605 iterations is 0.21381468801502082\n",
      "cost after 610 iterations is 0.2115471153870082\n",
      "cost after 615 iterations is 0.20932293914783606\n",
      "cost after 620 iterations is 0.20714103925271607\n",
      "cost after 625 iterations is 0.20500032816074787\n",
      "cost after 630 iterations is 0.20289975005438676\n",
      "cost after 635 iterations is 0.20083828004944768\n",
      "cost after 640 iterations is 0.1988149233998732\n",
      "cost after 645 iterations is 0.19682871470095042\n",
      "cost after 650 iterations is 0.1948787170941713\n",
      "cost after 655 iterations is 0.19296402147649724\n",
      "cost after 660 iterations is 0.1910837457164028\n",
      "cost after 665 iterations is 0.1892370338787259\n",
      "cost after 670 iterations is 0.1874230554600489\n",
      "cost after 675 iterations is 0.18564100463606129\n",
      "cost after 680 iterations is 0.18389009952211383\n",
      "cost after 685 iterations is 0.18216958144796203\n",
      "cost after 690 iterations is 0.18047871424750747\n",
      "cost after 695 iterations is 0.17881678356418007\n",
      "cost after 700 iterations is 0.17718309617245762\n",
      "cost after 705 iterations is 0.1755769793158908\n",
      "cost after 710 iterations is 0.17399778006189034\n",
      "cost after 715 iterations is 0.17244486467343237\n",
      "cost after 720 iterations is 0.17091761799775487\n",
      "cost after 725 iterations is 0.169415442872042\n",
      "cost after 730 iterations is 0.16793775954602935\n",
      "cost after 735 iterations is 0.1664840051214083\n",
      "cost after 740 iterations is 0.1650536330078588\n",
      "cost after 745 iterations is 0.1636461123955005\n",
      "cost after 750 iterations is 0.16226092774351802\n",
      "cost after 755 iterations is 0.160897578284687\n",
      "cost after 760 iterations is 0.1595555775455034\n",
      "cost after 765 iterations is 0.15823445288160032\n",
      "cost after 770 iterations is 0.15693374502812016\n",
      "cost after 775 iterations is 0.15565300766469742\n",
      "cost after 780 iterations is 0.15439180699469837\n",
      "cost after 785 iterations is 0.15314972133835786\n",
      "cost after 790 iterations is 0.1519263407394477\n",
      "cost after 795 iterations is 0.15072126658510893\n",
      "cost after 800 iterations is 0.14953411123848076\n",
      "cost after 805 iterations is 0.14836449768375762\n",
      "cost after 810 iterations is 0.14721205918330926\n",
      "cost after 815 iterations is 0.1460764389465014\n",
      "cost after 820 iterations is 0.14495728980985872\n",
      "cost after 825 iterations is 0.1438542739282163\n",
      "cost after 830 iterations is 0.1427670624765117\n",
      "cost after 835 iterations is 0.14169533536187626\n",
      "cost after 840 iterations is 0.14063878094568952\n",
      "cost after 845 iterations is 0.1395970957752694\n",
      "cost after 850 iterations is 0.13856998432487647\n",
      "cost after 855 iterations is 0.13755715874571914\n",
      "cost after 860 iterations is 0.13655833862465452\n",
      "cost after 865 iterations is 0.13557325075128626\n",
      "cost after 870 iterations is 0.1346016288931701\n",
      "cost after 875 iterations is 0.13364321357884493\n",
      "cost after 880 iterations is 0.13269775188841604\n",
      "cost after 885 iterations is 0.13176499725142368\n",
      "cost after 890 iterations is 0.1308447092517397\n",
      "cost after 895 iterations is 0.12993665343924218\n",
      "cost after 900 iterations is 0.12904060114802549\n",
      "cost after 905 iterations is 0.12815632932091117\n",
      "cost after 910 iterations is 0.12728362034003277\n",
      "cost after 915 iterations is 0.12642226186327515\n",
      "cost after 920 iterations is 0.1255720466663552\n",
      "cost after 925 iterations is 0.12473277249034012\n",
      "cost after 930 iterations is 0.12390424189440355\n",
      "cost after 935 iterations is 0.1230862621136294\n",
      "cost after 940 iterations is 0.12227864492167807\n",
      "cost after 945 iterations is 0.12148120649813698\n",
      "cost after 950 iterations is 0.12069376730038349\n",
      "cost after 955 iterations is 0.11991615193979446\n",
      "cost after 960 iterations is 0.1191481890621429\n",
      "cost after 965 iterations is 0.11838971123202699\n",
      "cost after 970 iterations is 0.1176405548211841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost after 975 iterations is 0.11690055990054617\n",
      "cost after 980 iterations is 0.11616957013589876\n",
      "cost after 985 iterations is 0.11544743268701224\n",
      "cost after 990 iterations is 0.11473399811011571\n",
      "cost after 995 iterations is 0.11402912026359288\n"
     ]
    }
   ],
   "source": [
    "parameters, loss = neural_network_model(X_train, y_train, 4, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40053302",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 1 - np.array(loss)\n",
    "#accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b32237ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights and bias for the activation of hidden layer\n",
      "\n",
      "<-----W1----->\n",
      "[[ 0.06521107  0.06642471 -0.00685537  0.01800601]\n",
      " [-0.56387281 -0.30989762 -0.34719833 -0.09989109]\n",
      " [-0.45605825 -0.23006511 -0.24961856 -0.07175504]\n",
      " [-0.47052236 -0.24868128 -0.26897584 -0.08918061]]\n",
      " \n",
      "<-----b1----->\n",
      "[[-0.00852729]\n",
      " [ 0.29754159]\n",
      " [ 0.1833203 ]\n",
      " [ 0.20013005]]\n"
     ]
    }
   ],
   "source": [
    "#these are the final parameters\n",
    "print('Weights and bias for the activation of hidden layer'+'\\n')\n",
    "print('<-----W1----->')\n",
    "print(parameters['W1'])\n",
    "print(' ')\n",
    "print('<-----b1----->')\n",
    "print(parameters['b1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4859685b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights and bias for the activation of output layer\n",
      "\n",
      "<-----W2----->\n",
      "[[-0.10448563  1.25174565  0.86289524  0.92569912]]\n",
      " \n",
      "<-----b2----->\n",
      "[[0.0798439]]\n"
     ]
    }
   ],
   "source": [
    "print('Weights and bias for the activation of output layer'+'\\n')\n",
    "print('<-----W2----->')\n",
    "print(parameters['W2'])\n",
    "print(' ')\n",
    "print('<-----b2----->')\n",
    "print(parameters['b2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d57628",
   "metadata": {},
   "source": [
    "# 8) Prediction\n",
    "\n",
    "By using learned parameters, we can predict the class for each example by forward propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "752cc369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(parameters, X):\n",
    "    A2, cache = forward_propagation(X, parameters)\n",
    "    predictions = np.round(A2)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0df455e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train = prediction(parameters, X_train)\n",
    "predictions_test = prediction(parameters, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379d4139",
   "metadata": {},
   "source": [
    "# 9) Metrics\n",
    "\n",
    "To find out the metrics that are useful to know the accuracy of the model and model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25dce658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_met(actual, predicted):\n",
    "        correct = 0\n",
    "        for i in range(len(actual)):\n",
    "                if actual[i] == predicted[i]:\n",
    "                        correct += 1\n",
    "        return correct / float(len(actual)) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e29bda29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.36363636363636"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_met(y_test.flatten(), predictions_test.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6f0ccce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.90337283500456"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_met(y_train.flatten(), predictions_train.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4baafdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Positives: 2\n",
      "False Negetives: 8\n",
      "True Positives: 119\n",
      "True Negetives: 146\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test.flatten(), predictions_test.flatten()).ravel()\n",
    "\n",
    "print('False Positives: {}'.format(fp))\n",
    "print('False Negetives: {}'.format(fn))\n",
    "print('True Positives: {}'.format(tp))\n",
    "print('True Negetives: {}'.format(tn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f346b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Test classification report----------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.95      0.97       154\n",
      "         1.0       0.94      0.98      0.96       121\n",
      "\n",
      "    accuracy                           0.96       275\n",
      "   macro avg       0.96      0.97      0.96       275\n",
      "weighted avg       0.96      0.96      0.96       275\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print('-'*10+'Test classification report'+'-'*10+'\\n')\n",
    "print(classification_report(predictions_test.flatten(), y_test.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bdcb3f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Train classification report----------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.98       621\n",
      "         1.0       0.97      0.98      0.98       476\n",
      "\n",
      "    accuracy                           0.98      1097\n",
      "   macro avg       0.98      0.98      0.98      1097\n",
      "weighted avg       0.98      0.98      0.98      1097\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('-'*10+'Train classification report'+'-'*10+'\\n')\n",
    "print(classification_report(predictions_train.flatten(), y_train.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db98b933",
   "metadata": {},
   "source": [
    "# 10) Visualizing our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14bc889f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x23161a33ac8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss)\n",
    "plt.plot(accuracy)\n",
    "plt.title('Model loss & accuracy')\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('%loss or %accuracy')\n",
    "plt.legend(['loss', 'accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793e61c3",
   "metadata": {},
   "source": [
    "# Using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1edba8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.iloc[:,:-1], df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99542394",
   "metadata": {},
   "source": [
    "# normalizing our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ac8cc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef64ccb",
   "metadata": {},
   "source": [
    "## splitting data into train and test  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6e4ee987",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68de189f",
   "metadata": {},
   "source": [
    "## Using Logistic Regression from scikit-learn\n",
    "\n",
    "Initializing LogisticRegression and use fit method to fit train data and predict method on testing data for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a9d58c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "929c5664",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = lg.fit(X_train, y_train)\n",
    "y_pred = lg.predict(X_test)\n",
    "y_pred_train = lg.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c583d6",
   "metadata": {},
   "source": [
    "## Metrics for model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0cc5c5b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9817684594348223"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b68fc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of the data is 0.9781818181818182\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('Test accuracy of the data is {}'.format(accuracy_score(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1ad7e058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy of the data is 0.9817684594348223\n"
     ]
    }
   ],
   "source": [
    "print('Train accuracy of the data is {}'.format(accuracy_score(y_pred_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d0a0819a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Test classification report----------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       146\n",
      "           1       0.98      0.97      0.98       129\n",
      "\n",
      "    accuracy                           0.98       275\n",
      "   macro avg       0.98      0.98      0.98       275\n",
      "weighted avg       0.98      0.98      0.98       275\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('-'*10+'Test classification report'+'-'*10+'\\n')\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b9b733e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Train classification report----------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       596\n",
      "           1       1.00      0.96      0.98       501\n",
      "\n",
      "    accuracy                           0.98      1097\n",
      "   macro avg       0.98      0.98      0.98      1097\n",
      "weighted avg       0.98      0.98      0.98      1097\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('-'*10+'Train classification report'+'-'*10+'\\n')\n",
    "print(classification_report(y_pred_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f116e3",
   "metadata": {},
   "source": [
    "# Using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3fed0991",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\deep\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\deep\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\deep\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\deep\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\deep\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\deep\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfcfe09",
   "metadata": {},
   "source": [
    "## splitting train data for training and validation purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4729dc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation data \n",
    "\n",
    "X_train, X_val, y_train, y_val= train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ccb63a",
   "metadata": {},
   "source": [
    "## converting train, test and validation labels to categorical array representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "daee1d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_test = to_categorical(y_test, num_classes=2)\n",
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_val = to_categorical(y_val, num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5d29d3",
   "metadata": {},
   "source": [
    "## building ANN model with one hidden layer\n",
    "\n",
    "Activation function for hidden layer is taken as **relu** function and for output layer **sigmoid** function is taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "896760da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(4, input_shape=(4,), activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2048b601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 30\n",
      "Trainable params: 30\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad347e1",
   "metadata": {},
   "source": [
    "## compiling the model \n",
    "\n",
    "model is compilied by using attributes like categorical_cross entropy for loss, Stochastic gradient descent as optimizer and accuracy for metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "884d19c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer='SGD', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3320b6e",
   "metadata": {},
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9cd8b004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\deep\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 877 samples, validate on 220 samples\n",
      "Epoch 1/1000\n",
      "877/877 [==============================] - 0s 168us/step - loss: 1.1653 - accuracy: 0.1984 - val_loss: 1.2771 - val_accuracy: 0.1773\n",
      "Epoch 2/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 1.1320 - accuracy: 0.1973 - val_loss: 1.2365 - val_accuracy: 0.1773\n",
      "Epoch 3/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 1.1019 - accuracy: 0.1973 - val_loss: 1.1994 - val_accuracy: 0.1773\n",
      "Epoch 4/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 1.0744 - accuracy: 0.1961 - val_loss: 1.1651 - val_accuracy: 0.1818\n",
      "Epoch 5/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 1.0491 - accuracy: 0.1961 - val_loss: 1.1336 - val_accuracy: 0.1727\n",
      "Epoch 6/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 1.0259 - accuracy: 0.1938 - val_loss: 1.1048 - val_accuracy: 0.1727\n",
      "Epoch 7/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 1.0046 - accuracy: 0.1893 - val_loss: 1.0784 - val_accuracy: 0.1727\n",
      "Epoch 8/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.9849 - accuracy: 0.1859 - val_loss: 1.0538 - val_accuracy: 0.1773\n",
      "Epoch 9/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.9668 - accuracy: 0.1824 - val_loss: 1.0309 - val_accuracy: 0.1727\n",
      "Epoch 10/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.9499 - accuracy: 0.1790 - val_loss: 1.0100 - val_accuracy: 0.1773\n",
      "Epoch 11/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.9343 - accuracy: 0.1802 - val_loss: 0.9905 - val_accuracy: 0.1727\n",
      "Epoch 12/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.9198 - accuracy: 0.1813 - val_loss: 0.9724 - val_accuracy: 0.1727\n",
      "Epoch 13/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.9062 - accuracy: 0.1790 - val_loss: 0.9556 - val_accuracy: 0.1727\n",
      "Epoch 14/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.8936 - accuracy: 0.1779 - val_loss: 0.9399 - val_accuracy: 0.1682\n",
      "Epoch 15/1000\n",
      "877/877 [==============================] - 0s 27us/step - loss: 0.8819 - accuracy: 0.1756 - val_loss: 0.9252 - val_accuracy: 0.1591\n",
      "Epoch 16/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.8708 - accuracy: 0.1767 - val_loss: 0.9115 - val_accuracy: 0.1591\n",
      "Epoch 17/1000\n",
      "877/877 [==============================] - 0s 30us/step - loss: 0.8605 - accuracy: 0.1802 - val_loss: 0.8985 - val_accuracy: 0.1682\n",
      "Epoch 18/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.8507 - accuracy: 0.1824 - val_loss: 0.8865 - val_accuracy: 0.1773\n",
      "Epoch 19/1000\n",
      "877/877 [==============================] - 0s 27us/step - loss: 0.8416 - accuracy: 0.1859 - val_loss: 0.8751 - val_accuracy: 0.1773\n",
      "Epoch 20/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.8330 - accuracy: 0.1927 - val_loss: 0.8647 - val_accuracy: 0.1818\n",
      "Epoch 21/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.8251 - accuracy: 0.1950 - val_loss: 0.8549 - val_accuracy: 0.1864\n",
      "Epoch 22/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.8176 - accuracy: 0.1938 - val_loss: 0.8457 - val_accuracy: 0.1909\n",
      "Epoch 23/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.8104 - accuracy: 0.1973 - val_loss: 0.8368 - val_accuracy: 0.1909\n",
      "Epoch 24/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.8036 - accuracy: 0.2007 - val_loss: 0.8286 - val_accuracy: 0.1955\n",
      "Epoch 25/1000\n",
      "877/877 [==============================] - 0s 32us/step - loss: 0.7971 - accuracy: 0.2075 - val_loss: 0.8207 - val_accuracy: 0.2045\n",
      "Epoch 26/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.7910 - accuracy: 0.2166 - val_loss: 0.8133 - val_accuracy: 0.2045\n",
      "Epoch 27/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.7852 - accuracy: 0.2269 - val_loss: 0.8065 - val_accuracy: 0.2136\n",
      "Epoch 28/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.7797 - accuracy: 0.2463 - val_loss: 0.7999 - val_accuracy: 0.2273\n",
      "Epoch 29/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.7743 - accuracy: 0.2623 - val_loss: 0.7936 - val_accuracy: 0.2409\n",
      "Epoch 30/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.7692 - accuracy: 0.2725 - val_loss: 0.7876 - val_accuracy: 0.2727\n",
      "Epoch 31/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.7643 - accuracy: 0.2942 - val_loss: 0.7818 - val_accuracy: 0.2773\n",
      "Epoch 32/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.7596 - accuracy: 0.3113 - val_loss: 0.7763 - val_accuracy: 0.2909\n",
      "Epoch 33/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.7550 - accuracy: 0.3330 - val_loss: 0.7711 - val_accuracy: 0.3136\n",
      "Epoch 34/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.7507 - accuracy: 0.3649 - val_loss: 0.7662 - val_accuracy: 0.3500\n",
      "Epoch 35/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.7465 - accuracy: 0.4105 - val_loss: 0.7614 - val_accuracy: 0.3909\n",
      "Epoch 36/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.7426 - accuracy: 0.4310 - val_loss: 0.7568 - val_accuracy: 0.4182\n",
      "Epoch 37/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.7387 - accuracy: 0.4561 - val_loss: 0.7524 - val_accuracy: 0.4409\n",
      "Epoch 38/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.7350 - accuracy: 0.4789 - val_loss: 0.7481 - val_accuracy: 0.4455\n",
      "Epoch 39/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.7314 - accuracy: 0.4914 - val_loss: 0.7441 - val_accuracy: 0.4500\n",
      "Epoch 40/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.7279 - accuracy: 0.5029 - val_loss: 0.7402 - val_accuracy: 0.4636\n",
      "Epoch 41/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.7246 - accuracy: 0.5097 - val_loss: 0.7364 - val_accuracy: 0.4636\n",
      "Epoch 42/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.7213 - accuracy: 0.5143 - val_loss: 0.7327 - val_accuracy: 0.4727\n",
      "Epoch 43/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.7182 - accuracy: 0.5188 - val_loss: 0.7292 - val_accuracy: 0.4773\n",
      "Epoch 44/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.7151 - accuracy: 0.5302 - val_loss: 0.7257 - val_accuracy: 0.4818\n",
      "Epoch 45/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.7122 - accuracy: 0.5359 - val_loss: 0.7223 - val_accuracy: 0.4864\n",
      "Epoch 46/1000\n",
      "877/877 [==============================] - 0s 17us/step - loss: 0.7092 - accuracy: 0.5416 - val_loss: 0.7191 - val_accuracy: 0.4864\n",
      "Epoch 47/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.7064 - accuracy: 0.5439 - val_loss: 0.7158 - val_accuracy: 0.4864\n",
      "Epoch 48/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.7036 - accuracy: 0.5496 - val_loss: 0.7127 - val_accuracy: 0.4864\n",
      "Epoch 49/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.7009 - accuracy: 0.5530 - val_loss: 0.7097 - val_accuracy: 0.4909\n",
      "Epoch 50/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.6983 - accuracy: 0.5587 - val_loss: 0.7068 - val_accuracy: 0.4909\n",
      "Epoch 51/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.6958 - accuracy: 0.5621 - val_loss: 0.7041 - val_accuracy: 0.4909\n",
      "Epoch 52/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.6934 - accuracy: 0.5633 - val_loss: 0.7015 - val_accuracy: 0.4909\n",
      "Epoch 53/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "877/877 [==============================] - 0s 25us/step - loss: 0.6911 - accuracy: 0.5633 - val_loss: 0.6989 - val_accuracy: 0.4955\n",
      "Epoch 54/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.6887 - accuracy: 0.5656 - val_loss: 0.6964 - val_accuracy: 0.4955\n",
      "Epoch 55/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.6865 - accuracy: 0.5656 - val_loss: 0.6940 - val_accuracy: 0.4909\n",
      "Epoch 56/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.6843 - accuracy: 0.5667 - val_loss: 0.6916 - val_accuracy: 0.4864\n",
      "Epoch 57/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.6822 - accuracy: 0.5667 - val_loss: 0.6893 - val_accuracy: 0.4909\n",
      "Epoch 58/1000\n",
      "877/877 [==============================] - 0s 16us/step - loss: 0.6801 - accuracy: 0.5667 - val_loss: 0.6871 - val_accuracy: 0.4909\n",
      "Epoch 59/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.6781 - accuracy: 0.5667 - val_loss: 0.6850 - val_accuracy: 0.4955\n",
      "Epoch 60/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.6761 - accuracy: 0.5667 - val_loss: 0.6830 - val_accuracy: 0.4955\n",
      "Epoch 61/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.6742 - accuracy: 0.5667 - val_loss: 0.6809 - val_accuracy: 0.4955\n",
      "Epoch 62/1000\n",
      "877/877 [==============================] - 0s 17us/step - loss: 0.6723 - accuracy: 0.5656 - val_loss: 0.6790 - val_accuracy: 0.4955\n",
      "Epoch 63/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.6704 - accuracy: 0.5644 - val_loss: 0.6771 - val_accuracy: 0.5955\n",
      "Epoch 64/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.6686 - accuracy: 0.6670 - val_loss: 0.6753 - val_accuracy: 0.7091\n",
      "Epoch 65/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.6668 - accuracy: 0.6933 - val_loss: 0.6735 - val_accuracy: 0.6955\n",
      "Epoch 66/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.6650 - accuracy: 0.6830 - val_loss: 0.6717 - val_accuracy: 0.7000\n",
      "Epoch 67/1000\n",
      "877/877 [==============================] - 0s 17us/step - loss: 0.6633 - accuracy: 0.6853 - val_loss: 0.6699 - val_accuracy: 0.7000\n",
      "Epoch 68/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.6615 - accuracy: 0.6842 - val_loss: 0.6682 - val_accuracy: 0.7045\n",
      "Epoch 69/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.6598 - accuracy: 0.6819 - val_loss: 0.6665 - val_accuracy: 0.7000\n",
      "Epoch 70/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.6581 - accuracy: 0.6830 - val_loss: 0.6647 - val_accuracy: 0.7000\n",
      "Epoch 71/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.6564 - accuracy: 0.6830 - val_loss: 0.6630 - val_accuracy: 0.7000\n",
      "Epoch 72/1000\n",
      "877/877 [==============================] - 0s 17us/step - loss: 0.6547 - accuracy: 0.6853 - val_loss: 0.6614 - val_accuracy: 0.7091\n",
      "Epoch 73/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.6530 - accuracy: 0.6830 - val_loss: 0.6597 - val_accuracy: 0.7091\n",
      "Epoch 74/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.6514 - accuracy: 0.6853 - val_loss: 0.6581 - val_accuracy: 0.7091\n",
      "Epoch 75/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.6498 - accuracy: 0.6864 - val_loss: 0.6565 - val_accuracy: 0.7091\n",
      "Epoch 76/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.6482 - accuracy: 0.6899 - val_loss: 0.6548 - val_accuracy: 0.7091\n",
      "Epoch 77/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.6466 - accuracy: 0.6910 - val_loss: 0.6532 - val_accuracy: 0.7091\n",
      "Epoch 78/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.6450 - accuracy: 0.6910 - val_loss: 0.6516 - val_accuracy: 0.7091\n",
      "Epoch 79/1000\n",
      "877/877 [==============================] - 0s 17us/step - loss: 0.6434 - accuracy: 0.6956 - val_loss: 0.6500 - val_accuracy: 0.7136\n",
      "Epoch 80/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.6418 - accuracy: 0.6956 - val_loss: 0.6485 - val_accuracy: 0.7136\n",
      "Epoch 81/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.6403 - accuracy: 0.7001 - val_loss: 0.6469 - val_accuracy: 0.7136\n",
      "Epoch 82/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.6388 - accuracy: 0.6990 - val_loss: 0.6453 - val_accuracy: 0.7136\n",
      "Epoch 83/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.6372 - accuracy: 0.7013 - val_loss: 0.6438 - val_accuracy: 0.7182\n",
      "Epoch 84/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.6357 - accuracy: 0.7024 - val_loss: 0.6422 - val_accuracy: 0.7182\n",
      "Epoch 85/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.6342 - accuracy: 0.7024 - val_loss: 0.6406 - val_accuracy: 0.7227\n",
      "Epoch 86/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.6327 - accuracy: 0.7035 - val_loss: 0.6391 - val_accuracy: 0.7318\n",
      "Epoch 87/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.6311 - accuracy: 0.7047 - val_loss: 0.6375 - val_accuracy: 0.7318\n",
      "Epoch 88/1000\n",
      "877/877 [==============================] - 0s 17us/step - loss: 0.6296 - accuracy: 0.7081 - val_loss: 0.6360 - val_accuracy: 0.7364\n",
      "Epoch 89/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.6281 - accuracy: 0.7104 - val_loss: 0.6344 - val_accuracy: 0.7364\n",
      "Epoch 90/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.6266 - accuracy: 0.7115 - val_loss: 0.6328 - val_accuracy: 0.7364\n",
      "Epoch 91/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.6250 - accuracy: 0.7138 - val_loss: 0.6313 - val_accuracy: 0.7500\n",
      "Epoch 92/1000\n",
      "877/877 [==============================] - 0s 17us/step - loss: 0.6235 - accuracy: 0.7138 - val_loss: 0.6297 - val_accuracy: 0.7500\n",
      "Epoch 93/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.6220 - accuracy: 0.7149 - val_loss: 0.6281 - val_accuracy: 0.7500\n",
      "Epoch 94/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.6204 - accuracy: 0.7149 - val_loss: 0.6265 - val_accuracy: 0.7500\n",
      "Epoch 95/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.6189 - accuracy: 0.7172 - val_loss: 0.6249 - val_accuracy: 0.7500\n",
      "Epoch 96/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.6173 - accuracy: 0.7172 - val_loss: 0.6232 - val_accuracy: 0.7500\n",
      "Epoch 97/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.6157 - accuracy: 0.7184 - val_loss: 0.6216 - val_accuracy: 0.7500\n",
      "Epoch 98/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.6141 - accuracy: 0.7218 - val_loss: 0.6200 - val_accuracy: 0.7545\n",
      "Epoch 99/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.6126 - accuracy: 0.7241 - val_loss: 0.6183 - val_accuracy: 0.7591\n",
      "Epoch 100/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.6110 - accuracy: 0.7241 - val_loss: 0.6167 - val_accuracy: 0.7636\n",
      "Epoch 101/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.6094 - accuracy: 0.7252 - val_loss: 0.6150 - val_accuracy: 0.7727\n",
      "Epoch 102/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.6078 - accuracy: 0.7263 - val_loss: 0.6134 - val_accuracy: 0.7773\n",
      "Epoch 103/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.6062 - accuracy: 0.7320 - val_loss: 0.6117 - val_accuracy: 0.7773\n",
      "Epoch 104/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.6045 - accuracy: 0.7343 - val_loss: 0.6100 - val_accuracy: 0.7773\n",
      "Epoch 105/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.6029 - accuracy: 0.7355 - val_loss: 0.6083 - val_accuracy: 0.7773\n",
      "Epoch 106/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.6013 - accuracy: 0.7377 - val_loss: 0.6066 - val_accuracy: 0.7818\n",
      "Epoch 107/1000\n",
      "877/877 [==============================] - 0s 27us/step - loss: 0.5996 - accuracy: 0.7377 - val_loss: 0.6049 - val_accuracy: 0.7818\n",
      "Epoch 108/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.5980 - accuracy: 0.7377 - val_loss: 0.6032 - val_accuracy: 0.7864\n",
      "Epoch 109/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "877/877 [==============================] - 0s 19us/step - loss: 0.5963 - accuracy: 0.7389 - val_loss: 0.6014 - val_accuracy: 0.7864\n",
      "Epoch 110/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.5947 - accuracy: 0.7400 - val_loss: 0.5997 - val_accuracy: 0.7864\n",
      "Epoch 111/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.5930 - accuracy: 0.7412 - val_loss: 0.5979 - val_accuracy: 0.7864\n",
      "Epoch 112/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.5914 - accuracy: 0.7423 - val_loss: 0.5962 - val_accuracy: 0.7864\n",
      "Epoch 113/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.5897 - accuracy: 0.7434 - val_loss: 0.5944 - val_accuracy: 0.7864\n",
      "Epoch 114/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.5880 - accuracy: 0.7434 - val_loss: 0.5927 - val_accuracy: 0.7864\n",
      "Epoch 115/1000\n",
      "877/877 [==============================] - 0s 65us/step - loss: 0.5864 - accuracy: 0.7434 - val_loss: 0.5909 - val_accuracy: 0.7864\n",
      "Epoch 116/1000\n",
      "877/877 [==============================] - 0s 31us/step - loss: 0.5847 - accuracy: 0.7446 - val_loss: 0.5891 - val_accuracy: 0.7909\n",
      "Epoch 117/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.5830 - accuracy: 0.7446 - val_loss: 0.5873 - val_accuracy: 0.7909\n",
      "Epoch 118/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.5813 - accuracy: 0.7457 - val_loss: 0.5855 - val_accuracy: 0.8000\n",
      "Epoch 119/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.5796 - accuracy: 0.7480 - val_loss: 0.5837 - val_accuracy: 0.8000\n",
      "Epoch 120/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.5779 - accuracy: 0.7491 - val_loss: 0.5819 - val_accuracy: 0.8000\n",
      "Epoch 121/1000\n",
      "877/877 [==============================] - 0s 17us/step - loss: 0.5762 - accuracy: 0.7491 - val_loss: 0.5801 - val_accuracy: 0.8045\n",
      "Epoch 122/1000\n",
      "877/877 [==============================] - 0s 16us/step - loss: 0.5745 - accuracy: 0.7503 - val_loss: 0.5783 - val_accuracy: 0.8045\n",
      "Epoch 123/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.5728 - accuracy: 0.7514 - val_loss: 0.5764 - val_accuracy: 0.8000\n",
      "Epoch 124/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.5711 - accuracy: 0.7526 - val_loss: 0.5746 - val_accuracy: 0.8000\n",
      "Epoch 125/1000\n",
      "877/877 [==============================] - 0s 27us/step - loss: 0.5693 - accuracy: 0.7526 - val_loss: 0.5728 - val_accuracy: 0.8000\n",
      "Epoch 126/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.5676 - accuracy: 0.7537 - val_loss: 0.5709 - val_accuracy: 0.8000\n",
      "Epoch 127/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.5659 - accuracy: 0.7537 - val_loss: 0.5691 - val_accuracy: 0.8091\n",
      "Epoch 128/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.5641 - accuracy: 0.7548 - val_loss: 0.5672 - val_accuracy: 0.8045\n",
      "Epoch 129/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.5624 - accuracy: 0.7548 - val_loss: 0.5653 - val_accuracy: 0.8091\n",
      "Epoch 130/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.5607 - accuracy: 0.7548 - val_loss: 0.5634 - val_accuracy: 0.8136\n",
      "Epoch 131/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.5589 - accuracy: 0.7548 - val_loss: 0.5615 - val_accuracy: 0.8136\n",
      "Epoch 132/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.5571 - accuracy: 0.7560 - val_loss: 0.5596 - val_accuracy: 0.8136\n",
      "Epoch 133/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.5554 - accuracy: 0.7560 - val_loss: 0.5577 - val_accuracy: 0.8136\n",
      "Epoch 134/1000\n",
      "877/877 [==============================] - ETA: 0s - loss: 0.5298 - accuracy: 0.80 - 0s 24us/step - loss: 0.5536 - accuracy: 0.7571 - val_loss: 0.5558 - val_accuracy: 0.8136\n",
      "Epoch 135/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.5518 - accuracy: 0.7571 - val_loss: 0.5539 - val_accuracy: 0.8136\n",
      "Epoch 136/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.5500 - accuracy: 0.7583 - val_loss: 0.5519 - val_accuracy: 0.8136\n",
      "Epoch 137/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.5483 - accuracy: 0.7594 - val_loss: 0.5500 - val_accuracy: 0.8136\n",
      "Epoch 138/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.5465 - accuracy: 0.7617 - val_loss: 0.5481 - val_accuracy: 0.8136\n",
      "Epoch 139/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.5447 - accuracy: 0.7617 - val_loss: 0.5461 - val_accuracy: 0.8136\n",
      "Epoch 140/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.5429 - accuracy: 0.7617 - val_loss: 0.5441 - val_accuracy: 0.8136\n",
      "Epoch 141/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.5411 - accuracy: 0.7628 - val_loss: 0.5422 - val_accuracy: 0.8136\n",
      "Epoch 142/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.5393 - accuracy: 0.7628 - val_loss: 0.5402 - val_accuracy: 0.8182\n",
      "Epoch 143/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.5375 - accuracy: 0.7651 - val_loss: 0.5382 - val_accuracy: 0.8182\n",
      "Epoch 144/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.5357 - accuracy: 0.7651 - val_loss: 0.5362 - val_accuracy: 0.8182\n",
      "Epoch 145/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.5339 - accuracy: 0.7640 - val_loss: 0.5342 - val_accuracy: 0.8182\n",
      "Epoch 146/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.5320 - accuracy: 0.7651 - val_loss: 0.5322 - val_accuracy: 0.8227\n",
      "Epoch 147/1000\n",
      "877/877 [==============================] - ETA: 0s - loss: 0.5079 - accuracy: 0.77 - 0s 27us/step - loss: 0.5302 - accuracy: 0.7662 - val_loss: 0.5301 - val_accuracy: 0.8227\n",
      "Epoch 148/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.5284 - accuracy: 0.7640 - val_loss: 0.5281 - val_accuracy: 0.8227\n",
      "Epoch 149/1000\n",
      "877/877 [==============================] - 0s 39us/step - loss: 0.5266 - accuracy: 0.7662 - val_loss: 0.5261 - val_accuracy: 0.8227\n",
      "Epoch 150/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.5247 - accuracy: 0.7662 - val_loss: 0.5240 - val_accuracy: 0.8227\n",
      "Epoch 151/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.5229 - accuracy: 0.7685 - val_loss: 0.5220 - val_accuracy: 0.8318\n",
      "Epoch 152/1000\n",
      "877/877 [==============================] - 0s 32us/step - loss: 0.5211 - accuracy: 0.7674 - val_loss: 0.5199 - val_accuracy: 0.8318\n",
      "Epoch 153/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.5192 - accuracy: 0.7674 - val_loss: 0.5179 - val_accuracy: 0.8318\n",
      "Epoch 154/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.5174 - accuracy: 0.7685 - val_loss: 0.5158 - val_accuracy: 0.8318\n",
      "Epoch 155/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.5155 - accuracy: 0.7685 - val_loss: 0.5137 - val_accuracy: 0.8318\n",
      "Epoch 156/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.5137 - accuracy: 0.7697 - val_loss: 0.5116 - val_accuracy: 0.8318\n",
      "Epoch 157/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.5118 - accuracy: 0.7697 - val_loss: 0.5096 - val_accuracy: 0.8364\n",
      "Epoch 158/1000\n",
      "877/877 [==============================] - 0s 27us/step - loss: 0.5100 - accuracy: 0.7697 - val_loss: 0.5075 - val_accuracy: 0.8364\n",
      "Epoch 159/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.5081 - accuracy: 0.7697 - val_loss: 0.5054 - val_accuracy: 0.8364\n",
      "Epoch 160/1000\n",
      "877/877 [==============================] - 0s 28us/step - loss: 0.5063 - accuracy: 0.7697 - val_loss: 0.5033 - val_accuracy: 0.8364\n",
      "Epoch 161/1000\n",
      "877/877 [==============================] - 0s 30us/step - loss: 0.5044 - accuracy: 0.7697 - val_loss: 0.5012 - val_accuracy: 0.8364\n",
      "Epoch 162/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.5026 - accuracy: 0.7685 - val_loss: 0.4991 - val_accuracy: 0.8364\n",
      "Epoch 163/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.5007 - accuracy: 0.7697 - val_loss: 0.4970 - val_accuracy: 0.8364\n",
      "Epoch 164/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "877/877 [==============================] - 0s 23us/step - loss: 0.4989 - accuracy: 0.7708 - val_loss: 0.4949 - val_accuracy: 0.8409\n",
      "Epoch 165/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.4971 - accuracy: 0.7731 - val_loss: 0.4928 - val_accuracy: 0.8409\n",
      "Epoch 166/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.4952 - accuracy: 0.7765 - val_loss: 0.4907 - val_accuracy: 0.8409\n",
      "Epoch 167/1000\n",
      "877/877 [==============================] - 0s 30us/step - loss: 0.4934 - accuracy: 0.7765 - val_loss: 0.4885 - val_accuracy: 0.8364\n",
      "Epoch 168/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.4915 - accuracy: 0.7754 - val_loss: 0.4864 - val_accuracy: 0.8364\n",
      "Epoch 169/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.4896 - accuracy: 0.7754 - val_loss: 0.4843 - val_accuracy: 0.8409\n",
      "Epoch 170/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.4878 - accuracy: 0.7754 - val_loss: 0.4821 - val_accuracy: 0.8500\n",
      "Epoch 171/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.4859 - accuracy: 0.7754 - val_loss: 0.4800 - val_accuracy: 0.8500\n",
      "Epoch 172/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.4841 - accuracy: 0.7765 - val_loss: 0.4779 - val_accuracy: 0.8500\n",
      "Epoch 173/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.4822 - accuracy: 0.7754 - val_loss: 0.4758 - val_accuracy: 0.8500\n",
      "Epoch 174/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.4804 - accuracy: 0.7788 - val_loss: 0.4736 - val_accuracy: 0.8500\n",
      "Epoch 175/1000\n",
      "877/877 [==============================] - 0s 15us/step - loss: 0.4785 - accuracy: 0.7811 - val_loss: 0.4715 - val_accuracy: 0.8500\n",
      "Epoch 176/1000\n",
      "877/877 [==============================] - 0s 14us/step - loss: 0.4766 - accuracy: 0.7845 - val_loss: 0.4694 - val_accuracy: 0.8500\n",
      "Epoch 177/1000\n",
      "877/877 [==============================] - 0s 15us/step - loss: 0.4747 - accuracy: 0.7856 - val_loss: 0.4673 - val_accuracy: 0.8500\n",
      "Epoch 178/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.4729 - accuracy: 0.7856 - val_loss: 0.4651 - val_accuracy: 0.8500\n",
      "Epoch 179/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.4710 - accuracy: 0.7879 - val_loss: 0.4630 - val_accuracy: 0.8500\n",
      "Epoch 180/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.4692 - accuracy: 0.7891 - val_loss: 0.4609 - val_accuracy: 0.8545\n",
      "Epoch 181/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.4673 - accuracy: 0.7879 - val_loss: 0.4588 - val_accuracy: 0.8545\n",
      "Epoch 182/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.4655 - accuracy: 0.7913 - val_loss: 0.4567 - val_accuracy: 0.8545\n",
      "Epoch 183/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.4636 - accuracy: 0.7925 - val_loss: 0.4546 - val_accuracy: 0.8545\n",
      "Epoch 184/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.4618 - accuracy: 0.7936 - val_loss: 0.4525 - val_accuracy: 0.8545\n",
      "Epoch 185/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.4599 - accuracy: 0.7948 - val_loss: 0.4504 - val_accuracy: 0.8545\n",
      "Epoch 186/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.4580 - accuracy: 0.7959 - val_loss: 0.4483 - val_accuracy: 0.8545\n",
      "Epoch 187/1000\n",
      "877/877 [==============================] - 0s 17us/step - loss: 0.4562 - accuracy: 0.7982 - val_loss: 0.4462 - val_accuracy: 0.8545\n",
      "Epoch 188/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.4543 - accuracy: 0.8005 - val_loss: 0.4441 - val_accuracy: 0.8545\n",
      "Epoch 189/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.4525 - accuracy: 0.8027 - val_loss: 0.4420 - val_accuracy: 0.8545\n",
      "Epoch 190/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.4506 - accuracy: 0.8039 - val_loss: 0.4399 - val_accuracy: 0.8545\n",
      "Epoch 191/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.4488 - accuracy: 0.8039 - val_loss: 0.4378 - val_accuracy: 0.8545\n",
      "Epoch 192/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.4469 - accuracy: 0.8050 - val_loss: 0.4357 - val_accuracy: 0.8545\n",
      "Epoch 193/1000\n",
      "877/877 [==============================] - 0s 28us/step - loss: 0.4450 - accuracy: 0.8073 - val_loss: 0.4336 - val_accuracy: 0.8545\n",
      "Epoch 194/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.4432 - accuracy: 0.8073 - val_loss: 0.4316 - val_accuracy: 0.8545\n",
      "Epoch 195/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.4413 - accuracy: 0.8073 - val_loss: 0.4295 - val_accuracy: 0.8545\n",
      "Epoch 196/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.4394 - accuracy: 0.8084 - val_loss: 0.4274 - val_accuracy: 0.8591\n",
      "Epoch 197/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.4376 - accuracy: 0.8084 - val_loss: 0.4254 - val_accuracy: 0.8591\n",
      "Epoch 198/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.4357 - accuracy: 0.8096 - val_loss: 0.4233 - val_accuracy: 0.8591\n",
      "Epoch 199/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.4338 - accuracy: 0.8107 - val_loss: 0.4212 - val_accuracy: 0.8636\n",
      "Epoch 200/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.4319 - accuracy: 0.8119 - val_loss: 0.4191 - val_accuracy: 0.8636\n",
      "Epoch 201/1000\n",
      "877/877 [==============================] - 0s 17us/step - loss: 0.4300 - accuracy: 0.8130 - val_loss: 0.4170 - val_accuracy: 0.8636\n",
      "Epoch 202/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.4282 - accuracy: 0.8153 - val_loss: 0.4149 - val_accuracy: 0.8636\n",
      "Epoch 203/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.4263 - accuracy: 0.8210 - val_loss: 0.4129 - val_accuracy: 0.8636\n",
      "Epoch 204/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.4244 - accuracy: 0.8221 - val_loss: 0.4108 - val_accuracy: 0.8636\n",
      "Epoch 205/1000\n",
      "877/877 [==============================] - 0s 17us/step - loss: 0.4225 - accuracy: 0.8244 - val_loss: 0.4088 - val_accuracy: 0.8636\n",
      "Epoch 206/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.4207 - accuracy: 0.8244 - val_loss: 0.4067 - val_accuracy: 0.8682\n",
      "Epoch 207/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.4188 - accuracy: 0.8278 - val_loss: 0.4047 - val_accuracy: 0.8682\n",
      "Epoch 208/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.4170 - accuracy: 0.8278 - val_loss: 0.4027 - val_accuracy: 0.8682\n",
      "Epoch 209/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.4151 - accuracy: 0.8278 - val_loss: 0.4006 - val_accuracy: 0.8682\n",
      "Epoch 210/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.4133 - accuracy: 0.8290 - val_loss: 0.3986 - val_accuracy: 0.8682\n",
      "Epoch 211/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.4115 - accuracy: 0.8312 - val_loss: 0.3966 - val_accuracy: 0.8682\n",
      "Epoch 212/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.4097 - accuracy: 0.8324 - val_loss: 0.3946 - val_accuracy: 0.8682\n",
      "Epoch 213/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.4078 - accuracy: 0.8347 - val_loss: 0.3925 - val_accuracy: 0.8682\n",
      "Epoch 214/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.4060 - accuracy: 0.8369 - val_loss: 0.3905 - val_accuracy: 0.8682\n",
      "Epoch 215/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.4042 - accuracy: 0.8381 - val_loss: 0.3884 - val_accuracy: 0.8682\n",
      "Epoch 216/1000\n",
      "877/877 [==============================] - 0s 16us/step - loss: 0.4024 - accuracy: 0.8381 - val_loss: 0.3864 - val_accuracy: 0.8727\n",
      "Epoch 217/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.4006 - accuracy: 0.8381 - val_loss: 0.3843 - val_accuracy: 0.8727\n",
      "Epoch 218/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.3988 - accuracy: 0.8392 - val_loss: 0.3823 - val_accuracy: 0.8727\n",
      "Epoch 219/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.3970 - accuracy: 0.8404 - val_loss: 0.3802 - val_accuracy: 0.8773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.3952 - accuracy: 0.8426 - val_loss: 0.3782 - val_accuracy: 0.8818\n",
      "Epoch 221/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.3934 - accuracy: 0.8438 - val_loss: 0.3762 - val_accuracy: 0.8818\n",
      "Epoch 222/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.3916 - accuracy: 0.8461 - val_loss: 0.3742 - val_accuracy: 0.8818\n",
      "Epoch 223/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.3898 - accuracy: 0.8472 - val_loss: 0.3722 - val_accuracy: 0.8818\n",
      "Epoch 224/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.3880 - accuracy: 0.8472 - val_loss: 0.3701 - val_accuracy: 0.8818\n",
      "Epoch 225/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.3862 - accuracy: 0.8483 - val_loss: 0.3681 - val_accuracy: 0.8818\n",
      "Epoch 226/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.3845 - accuracy: 0.8529 - val_loss: 0.3661 - val_accuracy: 0.8818\n",
      "Epoch 227/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.3827 - accuracy: 0.8552 - val_loss: 0.3640 - val_accuracy: 0.8818\n",
      "Epoch 228/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.3809 - accuracy: 0.8586 - val_loss: 0.3621 - val_accuracy: 0.8818\n",
      "Epoch 229/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.3791 - accuracy: 0.8609 - val_loss: 0.3601 - val_accuracy: 0.8818\n",
      "Epoch 230/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.3774 - accuracy: 0.8609 - val_loss: 0.3582 - val_accuracy: 0.8818\n",
      "Epoch 231/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.3756 - accuracy: 0.8609 - val_loss: 0.3562 - val_accuracy: 0.8864\n",
      "Epoch 232/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.3738 - accuracy: 0.8643 - val_loss: 0.3542 - val_accuracy: 0.8864\n",
      "Epoch 233/1000\n",
      "877/877 [==============================] - ETA: 0s - loss: 0.4175 - accuracy: 0.84 - 0s 18us/step - loss: 0.3720 - accuracy: 0.8666 - val_loss: 0.3523 - val_accuracy: 0.8864\n",
      "Epoch 234/1000\n",
      "877/877 [==============================] - 0s 17us/step - loss: 0.3702 - accuracy: 0.8666 - val_loss: 0.3503 - val_accuracy: 0.8864\n",
      "Epoch 235/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.3684 - accuracy: 0.8666 - val_loss: 0.3484 - val_accuracy: 0.8864\n",
      "Epoch 236/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.3667 - accuracy: 0.8666 - val_loss: 0.3465 - val_accuracy: 0.8864\n",
      "Epoch 237/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.3649 - accuracy: 0.8689 - val_loss: 0.3446 - val_accuracy: 0.8864\n",
      "Epoch 238/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.3631 - accuracy: 0.8712 - val_loss: 0.3427 - val_accuracy: 0.8955\n",
      "Epoch 239/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.3614 - accuracy: 0.8712 - val_loss: 0.3408 - val_accuracy: 0.8955\n",
      "Epoch 240/1000\n",
      "877/877 [==============================] - 0s 30us/step - loss: 0.3596 - accuracy: 0.8723 - val_loss: 0.3389 - val_accuracy: 0.8955\n",
      "Epoch 241/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.3579 - accuracy: 0.8734 - val_loss: 0.3370 - val_accuracy: 0.8955\n",
      "Epoch 242/1000\n",
      "877/877 [==============================] - 0s 27us/step - loss: 0.3562 - accuracy: 0.8757 - val_loss: 0.3351 - val_accuracy: 0.9000\n",
      "Epoch 243/1000\n",
      "877/877 [==============================] - 0s 42us/step - loss: 0.3545 - accuracy: 0.8780 - val_loss: 0.3333 - val_accuracy: 0.9000\n",
      "Epoch 244/1000\n",
      "877/877 [==============================] - 0s 31us/step - loss: 0.3528 - accuracy: 0.8780 - val_loss: 0.3315 - val_accuracy: 0.9000\n",
      "Epoch 245/1000\n",
      "877/877 [==============================] - 0s 34us/step - loss: 0.3511 - accuracy: 0.8780 - val_loss: 0.3296 - val_accuracy: 0.9000\n",
      "Epoch 246/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.3494 - accuracy: 0.8780 - val_loss: 0.3278 - val_accuracy: 0.9000\n",
      "Epoch 247/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.3477 - accuracy: 0.8780 - val_loss: 0.3260 - val_accuracy: 0.9000\n",
      "Epoch 248/1000\n",
      "877/877 [==============================] - 0s 33us/step - loss: 0.3461 - accuracy: 0.8780 - val_loss: 0.3242 - val_accuracy: 0.9000\n",
      "Epoch 249/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.3444 - accuracy: 0.8791 - val_loss: 0.3224 - val_accuracy: 0.9000\n",
      "Epoch 250/1000\n",
      "877/877 [==============================] - 0s 28us/step - loss: 0.3427 - accuracy: 0.8791 - val_loss: 0.3206 - val_accuracy: 0.9000\n",
      "Epoch 251/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.3410 - accuracy: 0.8791 - val_loss: 0.3189 - val_accuracy: 0.9000\n",
      "Epoch 252/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.3394 - accuracy: 0.8791 - val_loss: 0.3171 - val_accuracy: 0.9045\n",
      "Epoch 253/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.3377 - accuracy: 0.8803 - val_loss: 0.3153 - val_accuracy: 0.9045\n",
      "Epoch 254/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.3361 - accuracy: 0.8803 - val_loss: 0.3136 - val_accuracy: 0.9045\n",
      "Epoch 255/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.3345 - accuracy: 0.8803 - val_loss: 0.3119 - val_accuracy: 0.9091\n",
      "Epoch 256/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.3329 - accuracy: 0.8803 - val_loss: 0.3102 - val_accuracy: 0.9091\n",
      "Epoch 257/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.3313 - accuracy: 0.8814 - val_loss: 0.3084 - val_accuracy: 0.9091\n",
      "Epoch 258/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.3297 - accuracy: 0.8814 - val_loss: 0.3067 - val_accuracy: 0.9091\n",
      "Epoch 259/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.3281 - accuracy: 0.8814 - val_loss: 0.3050 - val_accuracy: 0.9091\n",
      "Epoch 260/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.3265 - accuracy: 0.8814 - val_loss: 0.3033 - val_accuracy: 0.9091\n",
      "Epoch 261/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.3249 - accuracy: 0.8814 - val_loss: 0.3016 - val_accuracy: 0.9091\n",
      "Epoch 262/1000\n",
      "877/877 [==============================] - 0s 16us/step - loss: 0.3234 - accuracy: 0.8814 - val_loss: 0.2999 - val_accuracy: 0.9091\n",
      "Epoch 263/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.3218 - accuracy: 0.8814 - val_loss: 0.2982 - val_accuracy: 0.9091\n",
      "Epoch 264/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.3203 - accuracy: 0.8826 - val_loss: 0.2965 - val_accuracy: 0.9091\n",
      "Epoch 265/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.3187 - accuracy: 0.8826 - val_loss: 0.2949 - val_accuracy: 0.9091\n",
      "Epoch 266/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.3171 - accuracy: 0.8837 - val_loss: 0.2932 - val_accuracy: 0.9091\n",
      "Epoch 267/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.3156 - accuracy: 0.8848 - val_loss: 0.2916 - val_accuracy: 0.9091\n",
      "Epoch 268/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.3141 - accuracy: 0.8848 - val_loss: 0.2900 - val_accuracy: 0.9091\n",
      "Epoch 269/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.3126 - accuracy: 0.8848 - val_loss: 0.2884 - val_accuracy: 0.9091\n",
      "Epoch 270/1000\n",
      "877/877 [==============================] - 0s 17us/step - loss: 0.3110 - accuracy: 0.8848 - val_loss: 0.2868 - val_accuracy: 0.9091\n",
      "Epoch 271/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.3095 - accuracy: 0.8848 - val_loss: 0.2852 - val_accuracy: 0.9091\n",
      "Epoch 272/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.3080 - accuracy: 0.8848 - val_loss: 0.2836 - val_accuracy: 0.9091\n",
      "Epoch 273/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.3065 - accuracy: 0.8860 - val_loss: 0.2820 - val_accuracy: 0.9091\n",
      "Epoch 274/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.3050 - accuracy: 0.8860 - val_loss: 0.2805 - val_accuracy: 0.9136\n",
      "Epoch 275/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "877/877 [==============================] - 0s 18us/step - loss: 0.3035 - accuracy: 0.8860 - val_loss: 0.2789 - val_accuracy: 0.9136\n",
      "Epoch 276/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.3020 - accuracy: 0.8871 - val_loss: 0.2773 - val_accuracy: 0.9136\n",
      "Epoch 277/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.3004 - accuracy: 0.8871 - val_loss: 0.2758 - val_accuracy: 0.9136\n",
      "Epoch 278/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.2990 - accuracy: 0.8871 - val_loss: 0.2743 - val_accuracy: 0.9136\n",
      "Epoch 279/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.2975 - accuracy: 0.8871 - val_loss: 0.2727 - val_accuracy: 0.9182\n",
      "Epoch 280/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.2960 - accuracy: 0.8871 - val_loss: 0.2712 - val_accuracy: 0.9182\n",
      "Epoch 281/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.2945 - accuracy: 0.8894 - val_loss: 0.2697 - val_accuracy: 0.9182\n",
      "Epoch 282/1000\n",
      "877/877 [==============================] - 0s 27us/step - loss: 0.2930 - accuracy: 0.8894 - val_loss: 0.2682 - val_accuracy: 0.9182\n",
      "Epoch 283/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.2916 - accuracy: 0.8894 - val_loss: 0.2668 - val_accuracy: 0.9182\n",
      "Epoch 284/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.2901 - accuracy: 0.8894 - val_loss: 0.2653 - val_accuracy: 0.9182\n",
      "Epoch 285/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.2886 - accuracy: 0.8894 - val_loss: 0.2638 - val_accuracy: 0.9182\n",
      "Epoch 286/1000\n",
      "877/877 [==============================] - 0s 17us/step - loss: 0.2871 - accuracy: 0.8894 - val_loss: 0.2623 - val_accuracy: 0.9182\n",
      "Epoch 287/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.2857 - accuracy: 0.8894 - val_loss: 0.2609 - val_accuracy: 0.9182\n",
      "Epoch 288/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.2842 - accuracy: 0.8905 - val_loss: 0.2594 - val_accuracy: 0.9182\n",
      "Epoch 289/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.2827 - accuracy: 0.8917 - val_loss: 0.2580 - val_accuracy: 0.9182\n",
      "Epoch 290/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.2813 - accuracy: 0.8928 - val_loss: 0.2566 - val_accuracy: 0.9182\n",
      "Epoch 291/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.2799 - accuracy: 0.8928 - val_loss: 0.2552 - val_accuracy: 0.9182\n",
      "Epoch 292/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.2784 - accuracy: 0.8928 - val_loss: 0.2538 - val_accuracy: 0.9182\n",
      "Epoch 293/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.2770 - accuracy: 0.8928 - val_loss: 0.2524 - val_accuracy: 0.9182\n",
      "Epoch 294/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.2755 - accuracy: 0.8928 - val_loss: 0.2510 - val_accuracy: 0.9182\n",
      "Epoch 295/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.2741 - accuracy: 0.8928 - val_loss: 0.2497 - val_accuracy: 0.9182\n",
      "Epoch 296/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.2727 - accuracy: 0.8928 - val_loss: 0.2483 - val_accuracy: 0.9182\n",
      "Epoch 297/1000\n",
      "877/877 [==============================] - 0s 17us/step - loss: 0.2713 - accuracy: 0.8928 - val_loss: 0.2469 - val_accuracy: 0.9182\n",
      "Epoch 298/1000\n",
      "877/877 [==============================] - 0s 17us/step - loss: 0.2699 - accuracy: 0.8928 - val_loss: 0.2456 - val_accuracy: 0.9227\n",
      "Epoch 299/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.2684 - accuracy: 0.8928 - val_loss: 0.2442 - val_accuracy: 0.9227\n",
      "Epoch 300/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.2670 - accuracy: 0.8928 - val_loss: 0.2429 - val_accuracy: 0.9227\n",
      "Epoch 301/1000\n",
      "877/877 [==============================] - 0s 14us/step - loss: 0.2656 - accuracy: 0.8928 - val_loss: 0.2415 - val_accuracy: 0.9227\n",
      "Epoch 302/1000\n",
      "877/877 [==============================] - 0s 15us/step - loss: 0.2642 - accuracy: 0.8928 - val_loss: 0.2402 - val_accuracy: 0.9227\n",
      "Epoch 303/1000\n",
      "877/877 [==============================] - 0s 15us/step - loss: 0.2627 - accuracy: 0.8940 - val_loss: 0.2389 - val_accuracy: 0.9227\n",
      "Epoch 304/1000\n",
      "877/877 [==============================] - 0s 15us/step - loss: 0.2614 - accuracy: 0.8951 - val_loss: 0.2376 - val_accuracy: 0.9227\n",
      "Epoch 305/1000\n",
      "877/877 [==============================] - 0s 16us/step - loss: 0.2600 - accuracy: 0.8962 - val_loss: 0.2363 - val_accuracy: 0.9227\n",
      "Epoch 306/1000\n",
      "877/877 [==============================] - 0s 14us/step - loss: 0.2586 - accuracy: 0.8962 - val_loss: 0.2350 - val_accuracy: 0.9273\n",
      "Epoch 307/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.2572 - accuracy: 0.8974 - val_loss: 0.2337 - val_accuracy: 0.9273\n",
      "Epoch 308/1000\n",
      "877/877 [==============================] - 0s 17us/step - loss: 0.2558 - accuracy: 0.8974 - val_loss: 0.2325 - val_accuracy: 0.9273\n",
      "Epoch 309/1000\n",
      "877/877 [==============================] - 0s 17us/step - loss: 0.2545 - accuracy: 0.8974 - val_loss: 0.2312 - val_accuracy: 0.9273\n",
      "Epoch 310/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.2531 - accuracy: 0.8985 - val_loss: 0.2300 - val_accuracy: 0.9318\n",
      "Epoch 311/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.2517 - accuracy: 0.9008 - val_loss: 0.2287 - val_accuracy: 0.9318\n",
      "Epoch 312/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.2503 - accuracy: 0.9019 - val_loss: 0.2275 - val_accuracy: 0.9318\n",
      "Epoch 313/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.2490 - accuracy: 0.9031 - val_loss: 0.2262 - val_accuracy: 0.9318\n",
      "Epoch 314/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.2476 - accuracy: 0.9042 - val_loss: 0.2250 - val_accuracy: 0.9318\n",
      "Epoch 315/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.2463 - accuracy: 0.9042 - val_loss: 0.2238 - val_accuracy: 0.9318\n",
      "Epoch 316/1000\n",
      "877/877 [==============================] - 0s 35us/step - loss: 0.2449 - accuracy: 0.9042 - val_loss: 0.2227 - val_accuracy: 0.9318\n",
      "Epoch 317/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.2436 - accuracy: 0.9065 - val_loss: 0.2215 - val_accuracy: 0.9318\n",
      "Epoch 318/1000\n",
      "877/877 [==============================] - 0s 32us/step - loss: 0.2422 - accuracy: 0.9076 - val_loss: 0.2203 - val_accuracy: 0.9318\n",
      "Epoch 319/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.2409 - accuracy: 0.9076 - val_loss: 0.2191 - val_accuracy: 0.9318\n",
      "Epoch 320/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.2395 - accuracy: 0.9076 - val_loss: 0.2180 - val_accuracy: 0.9318\n",
      "Epoch 321/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.2382 - accuracy: 0.9076 - val_loss: 0.2168 - val_accuracy: 0.9318\n",
      "Epoch 322/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.2368 - accuracy: 0.9088 - val_loss: 0.2157 - val_accuracy: 0.9318\n",
      "Epoch 323/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.2355 - accuracy: 0.9122 - val_loss: 0.2146 - val_accuracy: 0.9318\n",
      "Epoch 324/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.2342 - accuracy: 0.9122 - val_loss: 0.2135 - val_accuracy: 0.9318\n",
      "Epoch 325/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.2329 - accuracy: 0.9145 - val_loss: 0.2124 - val_accuracy: 0.9318\n",
      "Epoch 326/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.2316 - accuracy: 0.9156 - val_loss: 0.2113 - val_accuracy: 0.9318\n",
      "Epoch 327/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.2302 - accuracy: 0.9156 - val_loss: 0.2102 - val_accuracy: 0.9318\n",
      "Epoch 328/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.2289 - accuracy: 0.9168 - val_loss: 0.2091 - val_accuracy: 0.9318\n",
      "Epoch 329/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.2277 - accuracy: 0.9168 - val_loss: 0.2080 - val_accuracy: 0.9273\n",
      "Epoch 330/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.2264 - accuracy: 0.9145 - val_loss: 0.2070 - val_accuracy: 0.9273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 331/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.2251 - accuracy: 0.9145 - val_loss: 0.2059 - val_accuracy: 0.9273\n",
      "Epoch 332/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.2238 - accuracy: 0.9145 - val_loss: 0.2048 - val_accuracy: 0.9273\n",
      "Epoch 333/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.2225 - accuracy: 0.9145 - val_loss: 0.2038 - val_accuracy: 0.9273\n",
      "Epoch 334/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.2212 - accuracy: 0.9145 - val_loss: 0.2027 - val_accuracy: 0.9273\n",
      "Epoch 335/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.2200 - accuracy: 0.9145 - val_loss: 0.2017 - val_accuracy: 0.9273\n",
      "Epoch 336/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.2187 - accuracy: 0.9168 - val_loss: 0.2006 - val_accuracy: 0.9273\n",
      "Epoch 337/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.2175 - accuracy: 0.9190 - val_loss: 0.1996 - val_accuracy: 0.9273\n",
      "Epoch 338/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.2162 - accuracy: 0.9190 - val_loss: 0.1985 - val_accuracy: 0.9273\n",
      "Epoch 339/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.2149 - accuracy: 0.9190 - val_loss: 0.1975 - val_accuracy: 0.9273\n",
      "Epoch 340/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.2137 - accuracy: 0.9202 - val_loss: 0.1965 - val_accuracy: 0.9273\n",
      "Epoch 341/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.2125 - accuracy: 0.9202 - val_loss: 0.1955 - val_accuracy: 0.9273\n",
      "Epoch 342/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.2112 - accuracy: 0.9202 - val_loss: 0.1945 - val_accuracy: 0.9273\n",
      "Epoch 343/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.2100 - accuracy: 0.9202 - val_loss: 0.1935 - val_accuracy: 0.9273\n",
      "Epoch 344/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.2088 - accuracy: 0.9213 - val_loss: 0.1925 - val_accuracy: 0.9273\n",
      "Epoch 345/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.2076 - accuracy: 0.9213 - val_loss: 0.1915 - val_accuracy: 0.9273\n",
      "Epoch 346/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.2065 - accuracy: 0.9236 - val_loss: 0.1905 - val_accuracy: 0.9273\n",
      "Epoch 347/1000\n",
      "877/877 [==============================] - 0s 17us/step - loss: 0.2053 - accuracy: 0.9247 - val_loss: 0.1896 - val_accuracy: 0.9273\n",
      "Epoch 348/1000\n",
      "877/877 [==============================] - 0s 17us/step - loss: 0.2041 - accuracy: 0.9247 - val_loss: 0.1886 - val_accuracy: 0.9273\n",
      "Epoch 349/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.2029 - accuracy: 0.9247 - val_loss: 0.1877 - val_accuracy: 0.9273\n",
      "Epoch 350/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.2018 - accuracy: 0.9247 - val_loss: 0.1868 - val_accuracy: 0.9273\n",
      "Epoch 351/1000\n",
      "877/877 [==============================] - 0s 16us/step - loss: 0.2006 - accuracy: 0.9247 - val_loss: 0.1858 - val_accuracy: 0.9273\n",
      "Epoch 352/1000\n",
      "877/877 [==============================] - 0s 17us/step - loss: 0.1995 - accuracy: 0.9247 - val_loss: 0.1849 - val_accuracy: 0.9273\n",
      "Epoch 353/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.1983 - accuracy: 0.9247 - val_loss: 0.1840 - val_accuracy: 0.9273\n",
      "Epoch 354/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.1972 - accuracy: 0.9259 - val_loss: 0.1831 - val_accuracy: 0.9273\n",
      "Epoch 355/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.1961 - accuracy: 0.9259 - val_loss: 0.1822 - val_accuracy: 0.9273\n",
      "Epoch 356/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.1950 - accuracy: 0.9259 - val_loss: 0.1813 - val_accuracy: 0.9273\n",
      "Epoch 357/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.1938 - accuracy: 0.9259 - val_loss: 0.1805 - val_accuracy: 0.9273\n",
      "Epoch 358/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.1927 - accuracy: 0.9259 - val_loss: 0.1796 - val_accuracy: 0.9273\n",
      "Epoch 359/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.1916 - accuracy: 0.9259 - val_loss: 0.1787 - val_accuracy: 0.9273\n",
      "Epoch 360/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.1905 - accuracy: 0.9270 - val_loss: 0.1779 - val_accuracy: 0.9273\n",
      "Epoch 361/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.1894 - accuracy: 0.9270 - val_loss: 0.1770 - val_accuracy: 0.9273\n",
      "Epoch 362/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.1883 - accuracy: 0.9293 - val_loss: 0.1762 - val_accuracy: 0.9273\n",
      "Epoch 363/1000\n",
      "877/877 [==============================] - 0s 34us/step - loss: 0.1872 - accuracy: 0.9316 - val_loss: 0.1754 - val_accuracy: 0.9273\n",
      "Epoch 364/1000\n",
      "877/877 [==============================] - ETA: 0s - loss: 0.1749 - accuracy: 0.92 - 0s 27us/step - loss: 0.1861 - accuracy: 0.9316 - val_loss: 0.1745 - val_accuracy: 0.9273\n",
      "Epoch 365/1000\n",
      "877/877 [==============================] - 0s 30us/step - loss: 0.1850 - accuracy: 0.9316 - val_loss: 0.1737 - val_accuracy: 0.9273\n",
      "Epoch 366/1000\n",
      "877/877 [==============================] - 0s 31us/step - loss: 0.1840 - accuracy: 0.9316 - val_loss: 0.1729 - val_accuracy: 0.9273\n",
      "Epoch 367/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.1829 - accuracy: 0.9304 - val_loss: 0.1720 - val_accuracy: 0.9273\n",
      "Epoch 368/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.1818 - accuracy: 0.9327 - val_loss: 0.1712 - val_accuracy: 0.9273\n",
      "Epoch 369/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.1807 - accuracy: 0.9327 - val_loss: 0.1704 - val_accuracy: 0.9273\n",
      "Epoch 370/1000\n",
      "877/877 [==============================] - 0s 27us/step - loss: 0.1796 - accuracy: 0.9339 - val_loss: 0.1696 - val_accuracy: 0.9273\n",
      "Epoch 371/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.1785 - accuracy: 0.9339 - val_loss: 0.1688 - val_accuracy: 0.9273\n",
      "Epoch 372/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.1774 - accuracy: 0.9339 - val_loss: 0.1680 - val_accuracy: 0.9273\n",
      "Epoch 373/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.1763 - accuracy: 0.9350 - val_loss: 0.1672 - val_accuracy: 0.9273\n",
      "Epoch 374/1000\n",
      "877/877 [==============================] - 0s 32us/step - loss: 0.1753 - accuracy: 0.9339 - val_loss: 0.1665 - val_accuracy: 0.9227\n",
      "Epoch 375/1000\n",
      "877/877 [==============================] - 0s 30us/step - loss: 0.1742 - accuracy: 0.9327 - val_loss: 0.1657 - val_accuracy: 0.9227\n",
      "Epoch 376/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.1732 - accuracy: 0.9350 - val_loss: 0.1650 - val_accuracy: 0.9227\n",
      "Epoch 377/1000\n",
      "877/877 [==============================] - 0s 28us/step - loss: 0.1721 - accuracy: 0.9350 - val_loss: 0.1642 - val_accuracy: 0.9227\n",
      "Epoch 378/1000\n",
      "877/877 [==============================] - 0s 28us/step - loss: 0.1710 - accuracy: 0.9350 - val_loss: 0.1634 - val_accuracy: 0.9227\n",
      "Epoch 379/1000\n",
      "877/877 [==============================] - 0s 33us/step - loss: 0.1700 - accuracy: 0.9350 - val_loss: 0.1627 - val_accuracy: 0.9227\n",
      "Epoch 380/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.1689 - accuracy: 0.9350 - val_loss: 0.1620 - val_accuracy: 0.9227\n",
      "Epoch 381/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.1679 - accuracy: 0.9373 - val_loss: 0.1612 - val_accuracy: 0.9227\n",
      "Epoch 382/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.1669 - accuracy: 0.9384 - val_loss: 0.1605 - val_accuracy: 0.9227\n",
      "Epoch 383/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.1658 - accuracy: 0.9396 - val_loss: 0.1598 - val_accuracy: 0.9227\n",
      "Epoch 384/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.1648 - accuracy: 0.9396 - val_loss: 0.1591 - val_accuracy: 0.9227\n",
      "Epoch 385/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.1638 - accuracy: 0.9396 - val_loss: 0.1584 - val_accuracy: 0.9227\n",
      "Epoch 386/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "877/877 [==============================] - 0s 28us/step - loss: 0.1628 - accuracy: 0.9407 - val_loss: 0.1577 - val_accuracy: 0.9227\n",
      "Epoch 387/1000\n",
      "877/877 [==============================] - 0s 31us/step - loss: 0.1618 - accuracy: 0.9407 - val_loss: 0.1570 - val_accuracy: 0.9227\n",
      "Epoch 388/1000\n",
      "877/877 [==============================] - 0s 28us/step - loss: 0.1608 - accuracy: 0.9430 - val_loss: 0.1563 - val_accuracy: 0.9227\n",
      "Epoch 389/1000\n",
      "877/877 [==============================] - 0s 36us/step - loss: 0.1598 - accuracy: 0.9430 - val_loss: 0.1557 - val_accuracy: 0.9227\n",
      "Epoch 390/1000\n",
      "877/877 [==============================] - 0s 30us/step - loss: 0.1588 - accuracy: 0.9441 - val_loss: 0.1550 - val_accuracy: 0.9227\n",
      "Epoch 391/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.1578 - accuracy: 0.9441 - val_loss: 0.1543 - val_accuracy: 0.9227\n",
      "Epoch 392/1000\n",
      "877/877 [==============================] - 0s 28us/step - loss: 0.1569 - accuracy: 0.9453 - val_loss: 0.1537 - val_accuracy: 0.9227\n",
      "Epoch 393/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.1559 - accuracy: 0.9464 - val_loss: 0.1530 - val_accuracy: 0.9227\n",
      "Epoch 394/1000\n",
      "877/877 [==============================] - 0s 33us/step - loss: 0.1549 - accuracy: 0.9464 - val_loss: 0.1524 - val_accuracy: 0.9227\n",
      "Epoch 395/1000\n",
      "877/877 [==============================] - 0s 27us/step - loss: 0.1540 - accuracy: 0.9464 - val_loss: 0.1517 - val_accuracy: 0.9227\n",
      "Epoch 396/1000\n",
      "877/877 [==============================] - 0s 28us/step - loss: 0.1530 - accuracy: 0.9464 - val_loss: 0.1511 - val_accuracy: 0.9227\n",
      "Epoch 397/1000\n",
      "877/877 [==============================] - 0s 31us/step - loss: 0.1521 - accuracy: 0.9464 - val_loss: 0.1505 - val_accuracy: 0.9227\n",
      "Epoch 398/1000\n",
      "877/877 [==============================] - 0s 33us/step - loss: 0.1511 - accuracy: 0.9464 - val_loss: 0.1499 - val_accuracy: 0.9227\n",
      "Epoch 399/1000\n",
      "877/877 [==============================] - 0s 30us/step - loss: 0.1502 - accuracy: 0.9464 - val_loss: 0.1493 - val_accuracy: 0.9227\n",
      "Epoch 400/1000\n",
      "877/877 [==============================] - 0s 28us/step - loss: 0.1493 - accuracy: 0.9464 - val_loss: 0.1487 - val_accuracy: 0.9227\n",
      "Epoch 401/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.1483 - accuracy: 0.9475 - val_loss: 0.1481 - val_accuracy: 0.9227\n",
      "Epoch 402/1000\n",
      "877/877 [==============================] - 0s 27us/step - loss: 0.1474 - accuracy: 0.9487 - val_loss: 0.1475 - val_accuracy: 0.9227\n",
      "Epoch 403/1000\n",
      "877/877 [==============================] - 0s 36us/step - loss: 0.1465 - accuracy: 0.9487 - val_loss: 0.1469 - val_accuracy: 0.9227\n",
      "Epoch 404/1000\n",
      "877/877 [==============================] - 0s 28us/step - loss: 0.1456 - accuracy: 0.9498 - val_loss: 0.1463 - val_accuracy: 0.9273\n",
      "Epoch 405/1000\n",
      "877/877 [==============================] - 0s 32us/step - loss: 0.1447 - accuracy: 0.9498 - val_loss: 0.1457 - val_accuracy: 0.9273\n",
      "Epoch 406/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.1438 - accuracy: 0.9510 - val_loss: 0.1452 - val_accuracy: 0.9273\n",
      "Epoch 407/1000\n",
      "877/877 [==============================] - 0s 27us/step - loss: 0.1430 - accuracy: 0.9510 - val_loss: 0.1446 - val_accuracy: 0.9273\n",
      "Epoch 408/1000\n",
      "877/877 [==============================] - 0s 27us/step - loss: 0.1421 - accuracy: 0.9510 - val_loss: 0.1440 - val_accuracy: 0.9273\n",
      "Epoch 409/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.1412 - accuracy: 0.9510 - val_loss: 0.1435 - val_accuracy: 0.9273\n",
      "Epoch 410/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.1404 - accuracy: 0.9510 - val_loss: 0.1430 - val_accuracy: 0.9273\n",
      "Epoch 411/1000\n",
      "877/877 [==============================] - 0s 33us/step - loss: 0.1395 - accuracy: 0.9510 - val_loss: 0.1424 - val_accuracy: 0.9273\n",
      "Epoch 412/1000\n",
      "877/877 [==============================] - 0s 27us/step - loss: 0.1387 - accuracy: 0.9521 - val_loss: 0.1419 - val_accuracy: 0.9273\n",
      "Epoch 413/1000\n",
      "877/877 [==============================] - ETA: 0s - loss: 0.1224 - accuracy: 0.97 - 0s 32us/step - loss: 0.1378 - accuracy: 0.9532 - val_loss: 0.1414 - val_accuracy: 0.9273\n",
      "Epoch 414/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.1370 - accuracy: 0.9532 - val_loss: 0.1408 - val_accuracy: 0.9318\n",
      "Epoch 415/1000\n",
      "877/877 [==============================] - 0s 31us/step - loss: 0.1361 - accuracy: 0.9532 - val_loss: 0.1403 - val_accuracy: 0.9318\n",
      "Epoch 416/1000\n",
      "877/877 [==============================] - 0s 27us/step - loss: 0.1353 - accuracy: 0.9555 - val_loss: 0.1398 - val_accuracy: 0.9318\n",
      "Epoch 417/1000\n",
      "877/877 [==============================] - 0s 38us/step - loss: 0.1345 - accuracy: 0.9555 - val_loss: 0.1393 - val_accuracy: 0.9318\n",
      "Epoch 418/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.1337 - accuracy: 0.9555 - val_loss: 0.1388 - val_accuracy: 0.9318\n",
      "Epoch 419/1000\n",
      "877/877 [==============================] - 0s 27us/step - loss: 0.1328 - accuracy: 0.9555 - val_loss: 0.1383 - val_accuracy: 0.9318\n",
      "Epoch 420/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.1320 - accuracy: 0.9555 - val_loss: 0.1377 - val_accuracy: 0.9318\n",
      "Epoch 421/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.1312 - accuracy: 0.9555 - val_loss: 0.1372 - val_accuracy: 0.9318\n",
      "Epoch 422/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.1304 - accuracy: 0.9555 - val_loss: 0.1367 - val_accuracy: 0.9318\n",
      "Epoch 423/1000\n",
      "877/877 [==============================] - 0s 40us/step - loss: 0.1296 - accuracy: 0.9555 - val_loss: 0.1362 - val_accuracy: 0.9318\n",
      "Epoch 424/1000\n",
      "877/877 [==============================] - 0s 28us/step - loss: 0.1289 - accuracy: 0.9555 - val_loss: 0.1357 - val_accuracy: 0.9318\n",
      "Epoch 425/1000\n",
      "877/877 [==============================] - 0s 32us/step - loss: 0.1281 - accuracy: 0.9555 - val_loss: 0.1352 - val_accuracy: 0.9318\n",
      "Epoch 426/1000\n",
      "877/877 [==============================] - 0s 30us/step - loss: 0.1273 - accuracy: 0.9567 - val_loss: 0.1347 - val_accuracy: 0.9318\n",
      "Epoch 427/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.1266 - accuracy: 0.9578 - val_loss: 0.1342 - val_accuracy: 0.9318\n",
      "Epoch 428/1000\n",
      "877/877 [==============================] - 0s 28us/step - loss: 0.1258 - accuracy: 0.9590 - val_loss: 0.1337 - val_accuracy: 0.9318\n",
      "Epoch 429/1000\n",
      "877/877 [==============================] - 0s 35us/step - loss: 0.1251 - accuracy: 0.9601 - val_loss: 0.1332 - val_accuracy: 0.9318\n",
      "Epoch 430/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.1243 - accuracy: 0.9601 - val_loss: 0.1328 - val_accuracy: 0.9318\n",
      "Epoch 431/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.1236 - accuracy: 0.9601 - val_loss: 0.1323 - val_accuracy: 0.9318\n",
      "Epoch 432/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.1229 - accuracy: 0.9601 - val_loss: 0.1318 - val_accuracy: 0.9318\n",
      "Epoch 433/1000\n",
      "877/877 [==============================] - 0s 31us/step - loss: 0.1222 - accuracy: 0.9601 - val_loss: 0.1314 - val_accuracy: 0.9318\n",
      "Epoch 434/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.1215 - accuracy: 0.9601 - val_loss: 0.1309 - val_accuracy: 0.9318\n",
      "Epoch 435/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.1208 - accuracy: 0.9601 - val_loss: 0.1305 - val_accuracy: 0.9364\n",
      "Epoch 436/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.1201 - accuracy: 0.9612 - val_loss: 0.1301 - val_accuracy: 0.9409\n",
      "Epoch 437/1000\n",
      "877/877 [==============================] - ETA: 0s - loss: 0.0990 - accuracy: 0.96 - 0s 25us/step - loss: 0.1194 - accuracy: 0.9612 - val_loss: 0.1296 - val_accuracy: 0.9409\n",
      "Epoch 438/1000\n",
      "877/877 [==============================] - 0s 28us/step - loss: 0.1187 - accuracy: 0.9612 - val_loss: 0.1292 - val_accuracy: 0.9409\n",
      "Epoch 439/1000\n",
      "877/877 [==============================] - 0s 30us/step - loss: 0.1180 - accuracy: 0.9612 - val_loss: 0.1288 - val_accuracy: 0.9409\n",
      "Epoch 440/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.1174 - accuracy: 0.9612 - val_loss: 0.1284 - val_accuracy: 0.9409\n",
      "Epoch 441/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "877/877 [==============================] - 0s 42us/step - loss: 0.1167 - accuracy: 0.9624 - val_loss: 0.1279 - val_accuracy: 0.9409\n",
      "Epoch 442/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.1161 - accuracy: 0.9624 - val_loss: 0.1275 - val_accuracy: 0.9409\n",
      "Epoch 443/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.1155 - accuracy: 0.9635 - val_loss: 0.1271 - val_accuracy: 0.9409\n",
      "Epoch 444/1000\n",
      "877/877 [==============================] - 0s 28us/step - loss: 0.1148 - accuracy: 0.9635 - val_loss: 0.1267 - val_accuracy: 0.9409\n",
      "Epoch 445/1000\n",
      "877/877 [==============================] - 0s 30us/step - loss: 0.1142 - accuracy: 0.9635 - val_loss: 0.1263 - val_accuracy: 0.9409\n",
      "Epoch 446/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.1136 - accuracy: 0.9635 - val_loss: 0.1259 - val_accuracy: 0.9409\n",
      "Epoch 447/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.1130 - accuracy: 0.9647 - val_loss: 0.1255 - val_accuracy: 0.9409\n",
      "Epoch 448/1000\n",
      "877/877 [==============================] - 0s 28us/step - loss: 0.1124 - accuracy: 0.9647 - val_loss: 0.1251 - val_accuracy: 0.9409\n",
      "Epoch 449/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.1118 - accuracy: 0.9647 - val_loss: 0.1248 - val_accuracy: 0.9409\n",
      "Epoch 450/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.1112 - accuracy: 0.9658 - val_loss: 0.1244 - val_accuracy: 0.9409\n",
      "Epoch 451/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.1106 - accuracy: 0.9658 - val_loss: 0.1240 - val_accuracy: 0.9409\n",
      "Epoch 452/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.1100 - accuracy: 0.9658 - val_loss: 0.1236 - val_accuracy: 0.9409\n",
      "Epoch 453/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.1094 - accuracy: 0.9658 - val_loss: 0.1233 - val_accuracy: 0.9409\n",
      "Epoch 454/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.1088 - accuracy: 0.9658 - val_loss: 0.1229 - val_accuracy: 0.9409\n",
      "Epoch 455/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.1083 - accuracy: 0.9658 - val_loss: 0.1225 - val_accuracy: 0.9409\n",
      "Epoch 456/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.1077 - accuracy: 0.9658 - val_loss: 0.1221 - val_accuracy: 0.9409\n",
      "Epoch 457/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.1071 - accuracy: 0.9658 - val_loss: 0.1217 - val_accuracy: 0.9409\n",
      "Epoch 458/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.1066 - accuracy: 0.9658 - val_loss: 0.1214 - val_accuracy: 0.9409\n",
      "Epoch 459/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.1060 - accuracy: 0.9669 - val_loss: 0.1210 - val_accuracy: 0.9409\n",
      "Epoch 460/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.1054 - accuracy: 0.9669 - val_loss: 0.1206 - val_accuracy: 0.9409\n",
      "Epoch 461/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.1049 - accuracy: 0.9669 - val_loss: 0.1202 - val_accuracy: 0.9409\n",
      "Epoch 462/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.1044 - accuracy: 0.9669 - val_loss: 0.1199 - val_accuracy: 0.9409\n",
      "Epoch 463/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.1038 - accuracy: 0.9669 - val_loss: 0.1195 - val_accuracy: 0.9409\n",
      "Epoch 464/1000\n",
      "877/877 [==============================] - 0s 17us/step - loss: 0.1033 - accuracy: 0.9669 - val_loss: 0.1192 - val_accuracy: 0.9409\n",
      "Epoch 465/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.1028 - accuracy: 0.9669 - val_loss: 0.1188 - val_accuracy: 0.9409\n",
      "Epoch 466/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.1023 - accuracy: 0.9681 - val_loss: 0.1185 - val_accuracy: 0.9409\n",
      "Epoch 467/1000\n",
      "877/877 [==============================] - 0s 14us/step - loss: 0.1018 - accuracy: 0.9681 - val_loss: 0.1181 - val_accuracy: 0.9409\n",
      "Epoch 468/1000\n",
      "877/877 [==============================] - 0s 16us/step - loss: 0.1013 - accuracy: 0.9681 - val_loss: 0.1178 - val_accuracy: 0.9409\n",
      "Epoch 469/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.1008 - accuracy: 0.9692 - val_loss: 0.1175 - val_accuracy: 0.9409\n",
      "Epoch 470/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.1003 - accuracy: 0.9704 - val_loss: 0.1171 - val_accuracy: 0.9409\n",
      "Epoch 471/1000\n",
      "877/877 [==============================] - 0s 41us/step - loss: 0.0998 - accuracy: 0.9715 - val_loss: 0.1168 - val_accuracy: 0.9409\n",
      "Epoch 472/1000\n",
      "877/877 [==============================] - 0s 32us/step - loss: 0.0993 - accuracy: 0.9715 - val_loss: 0.1165 - val_accuracy: 0.9409\n",
      "Epoch 473/1000\n",
      "877/877 [==============================] - 0s 38us/step - loss: 0.0988 - accuracy: 0.9715 - val_loss: 0.1162 - val_accuracy: 0.9409\n",
      "Epoch 474/1000\n",
      "877/877 [==============================] - 0s 36us/step - loss: 0.0983 - accuracy: 0.9715 - val_loss: 0.1159 - val_accuracy: 0.9409\n",
      "Epoch 475/1000\n",
      "877/877 [==============================] - 0s 28us/step - loss: 0.0979 - accuracy: 0.9715 - val_loss: 0.1155 - val_accuracy: 0.9409\n",
      "Epoch 476/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0974 - accuracy: 0.9726 - val_loss: 0.1152 - val_accuracy: 0.9409\n",
      "Epoch 477/1000\n",
      "877/877 [==============================] - 0s 30us/step - loss: 0.0969 - accuracy: 0.9726 - val_loss: 0.1149 - val_accuracy: 0.9409\n",
      "Epoch 478/1000\n",
      "877/877 [==============================] - 0s 31us/step - loss: 0.0965 - accuracy: 0.9726 - val_loss: 0.1146 - val_accuracy: 0.9409\n",
      "Epoch 479/1000\n",
      "877/877 [==============================] - 0s 28us/step - loss: 0.0960 - accuracy: 0.9726 - val_loss: 0.1143 - val_accuracy: 0.9364\n",
      "Epoch 480/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0955 - accuracy: 0.9692 - val_loss: 0.1140 - val_accuracy: 0.9364\n",
      "Epoch 481/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.0951 - accuracy: 0.9692 - val_loss: 0.1136 - val_accuracy: 0.9364\n",
      "Epoch 482/1000\n",
      "877/877 [==============================] - 0s 33us/step - loss: 0.0946 - accuracy: 0.9692 - val_loss: 0.1133 - val_accuracy: 0.9364\n",
      "Epoch 483/1000\n",
      "877/877 [==============================] - 0s 35us/step - loss: 0.0942 - accuracy: 0.9692 - val_loss: 0.1130 - val_accuracy: 0.9364\n",
      "Epoch 484/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0937 - accuracy: 0.9692 - val_loss: 0.1127 - val_accuracy: 0.9364\n",
      "Epoch 485/1000\n",
      "877/877 [==============================] - 0s 34us/step - loss: 0.0933 - accuracy: 0.9692 - val_loss: 0.1124 - val_accuracy: 0.9364\n",
      "Epoch 486/1000\n",
      "877/877 [==============================] - 0s 35us/step - loss: 0.0929 - accuracy: 0.9692 - val_loss: 0.1121 - val_accuracy: 0.9364\n",
      "Epoch 487/1000\n",
      "877/877 [==============================] - 0s 35us/step - loss: 0.0924 - accuracy: 0.9692 - val_loss: 0.1117 - val_accuracy: 0.9364\n",
      "Epoch 488/1000\n",
      "877/877 [==============================] - 0s 31us/step - loss: 0.0920 - accuracy: 0.9692 - val_loss: 0.1114 - val_accuracy: 0.9364\n",
      "Epoch 489/1000\n",
      "877/877 [==============================] - 0s 28us/step - loss: 0.0916 - accuracy: 0.9692 - val_loss: 0.1111 - val_accuracy: 0.9364\n",
      "Epoch 490/1000\n",
      "877/877 [==============================] - 0s 30us/step - loss: 0.0912 - accuracy: 0.9692 - val_loss: 0.1108 - val_accuracy: 0.9364\n",
      "Epoch 491/1000\n",
      "877/877 [==============================] - 0s 30us/step - loss: 0.0908 - accuracy: 0.9692 - val_loss: 0.1105 - val_accuracy: 0.9364\n",
      "Epoch 492/1000\n",
      "877/877 [==============================] - 0s 31us/step - loss: 0.0904 - accuracy: 0.9692 - val_loss: 0.1102 - val_accuracy: 0.9364\n",
      "Epoch 493/1000\n",
      "877/877 [==============================] - 0s 28us/step - loss: 0.0900 - accuracy: 0.9704 - val_loss: 0.1099 - val_accuracy: 0.9364\n",
      "Epoch 494/1000\n",
      "877/877 [==============================] - 0s 27us/step - loss: 0.0896 - accuracy: 0.9692 - val_loss: 0.1096 - val_accuracy: 0.9364\n",
      "Epoch 495/1000\n",
      "877/877 [==============================] - 0s 31us/step - loss: 0.0892 - accuracy: 0.9715 - val_loss: 0.1093 - val_accuracy: 0.9364\n",
      "Epoch 496/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.0888 - accuracy: 0.9715 - val_loss: 0.1090 - val_accuracy: 0.9364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 497/1000\n",
      "877/877 [==============================] - 0s 28us/step - loss: 0.0885 - accuracy: 0.9704 - val_loss: 0.1087 - val_accuracy: 0.9364\n",
      "Epoch 498/1000\n",
      "877/877 [==============================] - 0s 27us/step - loss: 0.0881 - accuracy: 0.9704 - val_loss: 0.1084 - val_accuracy: 0.9364\n",
      "Epoch 499/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0877 - accuracy: 0.9738 - val_loss: 0.1081 - val_accuracy: 0.9364\n",
      "Epoch 500/1000\n",
      "877/877 [==============================] - 0s 30us/step - loss: 0.0873 - accuracy: 0.9704 - val_loss: 0.1078 - val_accuracy: 0.9364\n",
      "Epoch 501/1000\n",
      "877/877 [==============================] - ETA: 0s - loss: 0.0710 - accuracy: 0.99 - 0s 27us/step - loss: 0.0870 - accuracy: 0.9704 - val_loss: 0.1075 - val_accuracy: 0.9364\n",
      "Epoch 502/1000\n",
      "877/877 [==============================] - 0s 28us/step - loss: 0.0866 - accuracy: 0.9704 - val_loss: 0.1072 - val_accuracy: 0.9364\n",
      "Epoch 503/1000\n",
      "877/877 [==============================] - 0s 28us/step - loss: 0.0863 - accuracy: 0.9715 - val_loss: 0.1070 - val_accuracy: 0.9364\n",
      "Epoch 504/1000\n",
      "877/877 [==============================] - 0s 34us/step - loss: 0.0859 - accuracy: 0.9715 - val_loss: 0.1067 - val_accuracy: 0.9364\n",
      "Epoch 505/1000\n",
      "877/877 [==============================] - 0s 34us/step - loss: 0.0856 - accuracy: 0.9715 - val_loss: 0.1064 - val_accuracy: 0.9364\n",
      "Epoch 506/1000\n",
      "877/877 [==============================] - 0s 31us/step - loss: 0.0853 - accuracy: 0.9726 - val_loss: 0.1061 - val_accuracy: 0.9364\n",
      "Epoch 507/1000\n",
      "877/877 [==============================] - 0s 30us/step - loss: 0.0849 - accuracy: 0.9715 - val_loss: 0.1059 - val_accuracy: 0.9364\n",
      "Epoch 508/1000\n",
      "877/877 [==============================] - 0s 33us/step - loss: 0.0846 - accuracy: 0.9715 - val_loss: 0.1056 - val_accuracy: 0.9364\n",
      "Epoch 509/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.0843 - accuracy: 0.9715 - val_loss: 0.1053 - val_accuracy: 0.9364\n",
      "Epoch 510/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.0839 - accuracy: 0.9715 - val_loss: 0.1051 - val_accuracy: 0.9364\n",
      "Epoch 511/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0836 - accuracy: 0.9715 - val_loss: 0.1048 - val_accuracy: 0.9364\n",
      "Epoch 512/1000\n",
      "877/877 [==============================] - 0s 39us/step - loss: 0.0833 - accuracy: 0.9715 - val_loss: 0.1045 - val_accuracy: 0.9364\n",
      "Epoch 513/1000\n",
      "877/877 [==============================] - 0s 27us/step - loss: 0.0830 - accuracy: 0.9715 - val_loss: 0.1043 - val_accuracy: 0.9364\n",
      "Epoch 514/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.0827 - accuracy: 0.9715 - val_loss: 0.1040 - val_accuracy: 0.9364\n",
      "Epoch 515/1000\n",
      "877/877 [==============================] - 0s 36us/step - loss: 0.0824 - accuracy: 0.9715 - val_loss: 0.1038 - val_accuracy: 0.9364\n",
      "Epoch 516/1000\n",
      "877/877 [==============================] - 0s 30us/step - loss: 0.0821 - accuracy: 0.9715 - val_loss: 0.1035 - val_accuracy: 0.9364\n",
      "Epoch 517/1000\n",
      "877/877 [==============================] - 0s 30us/step - loss: 0.0818 - accuracy: 0.9715 - val_loss: 0.1033 - val_accuracy: 0.9364\n",
      "Epoch 518/1000\n",
      "877/877 [==============================] - 0s 27us/step - loss: 0.0815 - accuracy: 0.9715 - val_loss: 0.1031 - val_accuracy: 0.9364\n",
      "Epoch 519/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.0812 - accuracy: 0.9715 - val_loss: 0.1028 - val_accuracy: 0.9364\n",
      "Epoch 520/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0809 - accuracy: 0.9715 - val_loss: 0.1026 - val_accuracy: 0.9364\n",
      "Epoch 521/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0806 - accuracy: 0.9715 - val_loss: 0.1024 - val_accuracy: 0.9364\n",
      "Epoch 522/1000\n",
      "877/877 [==============================] - 0s 16us/step - loss: 0.0803 - accuracy: 0.9715 - val_loss: 0.1022 - val_accuracy: 0.9364\n",
      "Epoch 523/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.0800 - accuracy: 0.9715 - val_loss: 0.1019 - val_accuracy: 0.9364\n",
      "Epoch 524/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0797 - accuracy: 0.9715 - val_loss: 0.1017 - val_accuracy: 0.9364\n",
      "Epoch 525/1000\n",
      "877/877 [==============================] - 0s 44us/step - loss: 0.0794 - accuracy: 0.9715 - val_loss: 0.1015 - val_accuracy: 0.9364\n",
      "Epoch 526/1000\n",
      "877/877 [==============================] - 0s 38us/step - loss: 0.0792 - accuracy: 0.9715 - val_loss: 0.1013 - val_accuracy: 0.9364\n",
      "Epoch 527/1000\n",
      "877/877 [==============================] - 0s 28us/step - loss: 0.0789 - accuracy: 0.9715 - val_loss: 0.1010 - val_accuracy: 0.9364\n",
      "Epoch 528/1000\n",
      "877/877 [==============================] - 0s 31us/step - loss: 0.0786 - accuracy: 0.9715 - val_loss: 0.1008 - val_accuracy: 0.9364\n",
      "Epoch 529/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0784 - accuracy: 0.9726 - val_loss: 0.1006 - val_accuracy: 0.9364\n",
      "Epoch 530/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.0781 - accuracy: 0.9726 - val_loss: 0.1004 - val_accuracy: 0.9364\n",
      "Epoch 531/1000\n",
      "877/877 [==============================] - 0s 27us/step - loss: 0.0778 - accuracy: 0.9726 - val_loss: 0.1002 - val_accuracy: 0.9364\n",
      "Epoch 532/1000\n",
      "877/877 [==============================] - 0s 28us/step - loss: 0.0776 - accuracy: 0.9726 - val_loss: 0.1000 - val_accuracy: 0.9364\n",
      "Epoch 533/1000\n",
      "877/877 [==============================] - 0s 28us/step - loss: 0.0773 - accuracy: 0.9726 - val_loss: 0.0998 - val_accuracy: 0.9364\n",
      "Epoch 534/1000\n",
      "877/877 [==============================] - 0s 27us/step - loss: 0.0770 - accuracy: 0.9726 - val_loss: 0.0996 - val_accuracy: 0.9364\n",
      "Epoch 535/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0768 - accuracy: 0.9726 - val_loss: 0.0994 - val_accuracy: 0.9364\n",
      "Epoch 536/1000\n",
      "877/877 [==============================] - ETA: 0s - loss: 0.0908 - accuracy: 0.94 - 0s 35us/step - loss: 0.0765 - accuracy: 0.9726 - val_loss: 0.0992 - val_accuracy: 0.9364\n",
      "Epoch 537/1000\n",
      "877/877 [==============================] - 0s 33us/step - loss: 0.0763 - accuracy: 0.9726 - val_loss: 0.0990 - val_accuracy: 0.9364\n",
      "Epoch 538/1000\n",
      "877/877 [==============================] - 0s 33us/step - loss: 0.0760 - accuracy: 0.9726 - val_loss: 0.0988 - val_accuracy: 0.9364\n",
      "Epoch 539/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.0757 - accuracy: 0.9726 - val_loss: 0.0986 - val_accuracy: 0.9364\n",
      "Epoch 540/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0755 - accuracy: 0.9726 - val_loss: 0.0984 - val_accuracy: 0.9364\n",
      "Epoch 541/1000\n",
      "877/877 [==============================] - 0s 38us/step - loss: 0.0752 - accuracy: 0.9726 - val_loss: 0.0982 - val_accuracy: 0.9364\n",
      "Epoch 542/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0750 - accuracy: 0.9726 - val_loss: 0.0980 - val_accuracy: 0.9364\n",
      "Epoch 543/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0747 - accuracy: 0.9726 - val_loss: 0.0978 - val_accuracy: 0.9364\n",
      "Epoch 544/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0745 - accuracy: 0.9726 - val_loss: 0.0976 - val_accuracy: 0.9364\n",
      "Epoch 545/1000\n",
      "877/877 [==============================] - 0s 32us/step - loss: 0.0742 - accuracy: 0.9726 - val_loss: 0.0974 - val_accuracy: 0.9409\n",
      "Epoch 546/1000\n",
      "877/877 [==============================] - 0s 33us/step - loss: 0.0740 - accuracy: 0.9726 - val_loss: 0.0972 - val_accuracy: 0.9409\n",
      "Epoch 547/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.0738 - accuracy: 0.9726 - val_loss: 0.0970 - val_accuracy: 0.9409\n",
      "Epoch 548/1000\n",
      "877/877 [==============================] - 0s 51us/step - loss: 0.0735 - accuracy: 0.9726 - val_loss: 0.0969 - val_accuracy: 0.9409\n",
      "Epoch 549/1000\n",
      "877/877 [==============================] - 0s 27us/step - loss: 0.0733 - accuracy: 0.9726 - val_loss: 0.0967 - val_accuracy: 0.9409\n",
      "Epoch 550/1000\n",
      "877/877 [==============================] - 0s 32us/step - loss: 0.0730 - accuracy: 0.9726 - val_loss: 0.0965 - val_accuracy: 0.9409\n",
      "Epoch 551/1000\n",
      "877/877 [==============================] - 0s 27us/step - loss: 0.0728 - accuracy: 0.9726 - val_loss: 0.0963 - val_accuracy: 0.9455\n",
      "Epoch 552/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "877/877 [==============================] - 0s 33us/step - loss: 0.0726 - accuracy: 0.9726 - val_loss: 0.0961 - val_accuracy: 0.9455\n",
      "Epoch 553/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0724 - accuracy: 0.9726 - val_loss: 0.0960 - val_accuracy: 0.9455\n",
      "Epoch 554/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0721 - accuracy: 0.9726 - val_loss: 0.0958 - val_accuracy: 0.9455\n",
      "Epoch 555/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0719 - accuracy: 0.9726 - val_loss: 0.0956 - val_accuracy: 0.9455\n",
      "Epoch 556/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0717 - accuracy: 0.9726 - val_loss: 0.0955 - val_accuracy: 0.9455\n",
      "Epoch 557/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0715 - accuracy: 0.9726 - val_loss: 0.0953 - val_accuracy: 0.9455\n",
      "Epoch 558/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0713 - accuracy: 0.9726 - val_loss: 0.0951 - val_accuracy: 0.9455\n",
      "Epoch 559/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0710 - accuracy: 0.9726 - val_loss: 0.0950 - val_accuracy: 0.9455\n",
      "Epoch 560/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.0708 - accuracy: 0.9726 - val_loss: 0.0948 - val_accuracy: 0.9500\n",
      "Epoch 561/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0706 - accuracy: 0.9726 - val_loss: 0.0946 - val_accuracy: 0.9500\n",
      "Epoch 562/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.0704 - accuracy: 0.9726 - val_loss: 0.0945 - val_accuracy: 0.9500\n",
      "Epoch 563/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0702 - accuracy: 0.9726 - val_loss: 0.0943 - val_accuracy: 0.9500\n",
      "Epoch 564/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0700 - accuracy: 0.9726 - val_loss: 0.0941 - val_accuracy: 0.9500\n",
      "Epoch 565/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.0698 - accuracy: 0.9726 - val_loss: 0.0940 - val_accuracy: 0.9500\n",
      "Epoch 566/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.0696 - accuracy: 0.9726 - val_loss: 0.0938 - val_accuracy: 0.9500\n",
      "Epoch 567/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0694 - accuracy: 0.9726 - val_loss: 0.0937 - val_accuracy: 0.9500\n",
      "Epoch 568/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.0691 - accuracy: 0.9726 - val_loss: 0.0935 - val_accuracy: 0.9500\n",
      "Epoch 569/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.0689 - accuracy: 0.9726 - val_loss: 0.0933 - val_accuracy: 0.9500\n",
      "Epoch 570/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0687 - accuracy: 0.9726 - val_loss: 0.0932 - val_accuracy: 0.9500\n",
      "Epoch 571/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0685 - accuracy: 0.9726 - val_loss: 0.0930 - val_accuracy: 0.9500\n",
      "Epoch 572/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.0683 - accuracy: 0.9726 - val_loss: 0.0928 - val_accuracy: 0.9500\n",
      "Epoch 573/1000\n",
      "877/877 [==============================] - 0s 30us/step - loss: 0.0681 - accuracy: 0.9726 - val_loss: 0.0926 - val_accuracy: 0.9500\n",
      "Epoch 574/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.0679 - accuracy: 0.9726 - val_loss: 0.0925 - val_accuracy: 0.9500\n",
      "Epoch 575/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0676 - accuracy: 0.9726 - val_loss: 0.0923 - val_accuracy: 0.9500\n",
      "Epoch 576/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0674 - accuracy: 0.9726 - val_loss: 0.0921 - val_accuracy: 0.9500\n",
      "Epoch 577/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0672 - accuracy: 0.9726 - val_loss: 0.0919 - val_accuracy: 0.9500\n",
      "Epoch 578/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.0670 - accuracy: 0.9726 - val_loss: 0.0918 - val_accuracy: 0.9500\n",
      "Epoch 579/1000\n",
      "877/877 [==============================] - 0s 17us/step - loss: 0.0668 - accuracy: 0.9726 - val_loss: 0.0916 - val_accuracy: 0.9545\n",
      "Epoch 580/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.0666 - accuracy: 0.9726 - val_loss: 0.0914 - val_accuracy: 0.9545\n",
      "Epoch 581/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.0664 - accuracy: 0.9726 - val_loss: 0.0913 - val_accuracy: 0.9545\n",
      "Epoch 582/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.0662 - accuracy: 0.9738 - val_loss: 0.0911 - val_accuracy: 0.9545\n",
      "Epoch 583/1000\n",
      "877/877 [==============================] - 0s 17us/step - loss: 0.0660 - accuracy: 0.9738 - val_loss: 0.0909 - val_accuracy: 0.9545\n",
      "Epoch 584/1000\n",
      "877/877 [==============================] - 0s 16us/step - loss: 0.0658 - accuracy: 0.9738 - val_loss: 0.0908 - val_accuracy: 0.9545\n",
      "Epoch 585/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.0656 - accuracy: 0.9738 - val_loss: 0.0906 - val_accuracy: 0.9545\n",
      "Epoch 586/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0654 - accuracy: 0.9738 - val_loss: 0.0905 - val_accuracy: 0.9545\n",
      "Epoch 587/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0652 - accuracy: 0.9738 - val_loss: 0.0903 - val_accuracy: 0.9545\n",
      "Epoch 588/1000\n",
      "877/877 [==============================] - 0s 34us/step - loss: 0.0651 - accuracy: 0.9749 - val_loss: 0.0901 - val_accuracy: 0.9545\n",
      "Epoch 589/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0649 - accuracy: 0.9749 - val_loss: 0.0899 - val_accuracy: 0.9545\n",
      "Epoch 590/1000\n",
      "877/877 [==============================] - 0s 27us/step - loss: 0.0646 - accuracy: 0.9749 - val_loss: 0.0897 - val_accuracy: 0.9545\n",
      "Epoch 591/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.0644 - accuracy: 0.9749 - val_loss: 0.0895 - val_accuracy: 0.9545\n",
      "Epoch 592/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0642 - accuracy: 0.9749 - val_loss: 0.0893 - val_accuracy: 0.9545\n",
      "Epoch 593/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0640 - accuracy: 0.9749 - val_loss: 0.0891 - val_accuracy: 0.9545\n",
      "Epoch 594/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0638 - accuracy: 0.9749 - val_loss: 0.0889 - val_accuracy: 0.9545\n",
      "Epoch 595/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0636 - accuracy: 0.9761 - val_loss: 0.0888 - val_accuracy: 0.9545\n",
      "Epoch 596/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0634 - accuracy: 0.9761 - val_loss: 0.0886 - val_accuracy: 0.9545\n",
      "Epoch 597/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.0632 - accuracy: 0.9761 - val_loss: 0.0884 - val_accuracy: 0.9545\n",
      "Epoch 598/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.0630 - accuracy: 0.9761 - val_loss: 0.0882 - val_accuracy: 0.9545\n",
      "Epoch 599/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0628 - accuracy: 0.9761 - val_loss: 0.0880 - val_accuracy: 0.9545\n",
      "Epoch 600/1000\n",
      "877/877 [==============================] - 0s 30us/step - loss: 0.0626 - accuracy: 0.9761 - val_loss: 0.0878 - val_accuracy: 0.9591\n",
      "Epoch 601/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0624 - accuracy: 0.9761 - val_loss: 0.0876 - val_accuracy: 0.9591\n",
      "Epoch 602/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0622 - accuracy: 0.9761 - val_loss: 0.0874 - val_accuracy: 0.9591\n",
      "Epoch 603/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0620 - accuracy: 0.9761 - val_loss: 0.0872 - val_accuracy: 0.9591\n",
      "Epoch 604/1000\n",
      "877/877 [==============================] - 0s 30us/step - loss: 0.0618 - accuracy: 0.9761 - val_loss: 0.0871 - val_accuracy: 0.9591\n",
      "Epoch 605/1000\n",
      "877/877 [==============================] - 0s 27us/step - loss: 0.0616 - accuracy: 0.9761 - val_loss: 0.0869 - val_accuracy: 0.9591\n",
      "Epoch 606/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0614 - accuracy: 0.9761 - val_loss: 0.0867 - val_accuracy: 0.9591\n",
      "Epoch 607/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0612 - accuracy: 0.9761 - val_loss: 0.0866 - val_accuracy: 0.9591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 608/1000\n",
      "877/877 [==============================] - 0s 27us/step - loss: 0.0611 - accuracy: 0.9761 - val_loss: 0.0864 - val_accuracy: 0.9591\n",
      "Epoch 609/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0609 - accuracy: 0.9761 - val_loss: 0.0862 - val_accuracy: 0.9591\n",
      "Epoch 610/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0607 - accuracy: 0.9761 - val_loss: 0.0861 - val_accuracy: 0.9591\n",
      "Epoch 611/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.0605 - accuracy: 0.9761 - val_loss: 0.0859 - val_accuracy: 0.9591\n",
      "Epoch 612/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0603 - accuracy: 0.9761 - val_loss: 0.0857 - val_accuracy: 0.9591\n",
      "Epoch 613/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0602 - accuracy: 0.9761 - val_loss: 0.0856 - val_accuracy: 0.9591\n",
      "Epoch 614/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0600 - accuracy: 0.9761 - val_loss: 0.0854 - val_accuracy: 0.9591\n",
      "Epoch 615/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0598 - accuracy: 0.9761 - val_loss: 0.0853 - val_accuracy: 0.9591\n",
      "Epoch 616/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0596 - accuracy: 0.9761 - val_loss: 0.0851 - val_accuracy: 0.9591\n",
      "Epoch 617/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.0595 - accuracy: 0.9761 - val_loss: 0.0850 - val_accuracy: 0.9591\n",
      "Epoch 618/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0593 - accuracy: 0.9761 - val_loss: 0.0848 - val_accuracy: 0.9591\n",
      "Epoch 619/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.0591 - accuracy: 0.9761 - val_loss: 0.0847 - val_accuracy: 0.9591\n",
      "Epoch 620/1000\n",
      "877/877 [==============================] - 0s 30us/step - loss: 0.0590 - accuracy: 0.9761 - val_loss: 0.0845 - val_accuracy: 0.9591\n",
      "Epoch 621/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0588 - accuracy: 0.9761 - val_loss: 0.0844 - val_accuracy: 0.9591\n",
      "Epoch 622/1000\n",
      "877/877 [==============================] - 0s 48us/step - loss: 0.0586 - accuracy: 0.9761 - val_loss: 0.0842 - val_accuracy: 0.9591\n",
      "Epoch 623/1000\n",
      "877/877 [==============================] - 0s 50us/step - loss: 0.0585 - accuracy: 0.9761 - val_loss: 0.0841 - val_accuracy: 0.9591\n",
      "Epoch 624/1000\n",
      "877/877 [==============================] - 0s 32us/step - loss: 0.0583 - accuracy: 0.9761 - val_loss: 0.0839 - val_accuracy: 0.9591\n",
      "Epoch 625/1000\n",
      "877/877 [==============================] - 0s 27us/step - loss: 0.0582 - accuracy: 0.9761 - val_loss: 0.0838 - val_accuracy: 0.9591\n",
      "Epoch 626/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0580 - accuracy: 0.9761 - val_loss: 0.0836 - val_accuracy: 0.9591\n",
      "Epoch 627/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0578 - accuracy: 0.9761 - val_loss: 0.0835 - val_accuracy: 0.9591\n",
      "Epoch 628/1000\n",
      "877/877 [==============================] - 0s 38us/step - loss: 0.0577 - accuracy: 0.9761 - val_loss: 0.0834 - val_accuracy: 0.9591\n",
      "Epoch 629/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.0575 - accuracy: 0.9761 - val_loss: 0.0832 - val_accuracy: 0.9591\n",
      "Epoch 630/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0574 - accuracy: 0.9761 - val_loss: 0.0831 - val_accuracy: 0.9591\n",
      "Epoch 631/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0572 - accuracy: 0.9761 - val_loss: 0.0830 - val_accuracy: 0.9591\n",
      "Epoch 632/1000\n",
      "877/877 [==============================] - 0s 28us/step - loss: 0.0571 - accuracy: 0.9761 - val_loss: 0.0828 - val_accuracy: 0.9591\n",
      "Epoch 633/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0569 - accuracy: 0.9761 - val_loss: 0.0827 - val_accuracy: 0.9591\n",
      "Epoch 634/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0568 - accuracy: 0.9761 - val_loss: 0.0826 - val_accuracy: 0.9591\n",
      "Epoch 635/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0566 - accuracy: 0.9761 - val_loss: 0.0824 - val_accuracy: 0.9591\n",
      "Epoch 636/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0565 - accuracy: 0.9761 - val_loss: 0.0823 - val_accuracy: 0.9591\n",
      "Epoch 637/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0563 - accuracy: 0.9761 - val_loss: 0.0822 - val_accuracy: 0.9591\n",
      "Epoch 638/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0562 - accuracy: 0.9761 - val_loss: 0.0821 - val_accuracy: 0.9591\n",
      "Epoch 639/1000\n",
      "877/877 [==============================] - 0s 30us/step - loss: 0.0561 - accuracy: 0.9761 - val_loss: 0.0819 - val_accuracy: 0.9591\n",
      "Epoch 640/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0559 - accuracy: 0.9761 - val_loss: 0.0818 - val_accuracy: 0.9591\n",
      "Epoch 641/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.0557 - accuracy: 0.9761 - val_loss: 0.0817 - val_accuracy: 0.9591\n",
      "Epoch 642/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0556 - accuracy: 0.9761 - val_loss: 0.0816 - val_accuracy: 0.9591\n",
      "Epoch 643/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0555 - accuracy: 0.9761 - val_loss: 0.0815 - val_accuracy: 0.9591\n",
      "Epoch 644/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.0553 - accuracy: 0.9761 - val_loss: 0.0814 - val_accuracy: 0.9591\n",
      "Epoch 645/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0552 - accuracy: 0.9761 - val_loss: 0.0812 - val_accuracy: 0.9591\n",
      "Epoch 646/1000\n",
      "877/877 [==============================] - ETA: 0s - loss: 0.0444 - accuracy: 0.97 - 0s 22us/step - loss: 0.0551 - accuracy: 0.9761 - val_loss: 0.0811 - val_accuracy: 0.9591\n",
      "Epoch 647/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0549 - accuracy: 0.9761 - val_loss: 0.0810 - val_accuracy: 0.9591\n",
      "Epoch 648/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.0548 - accuracy: 0.9761 - val_loss: 0.0809 - val_accuracy: 0.9591\n",
      "Epoch 649/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0547 - accuracy: 0.9761 - val_loss: 0.0807 - val_accuracy: 0.9591\n",
      "Epoch 650/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.0546 - accuracy: 0.9761 - val_loss: 0.0806 - val_accuracy: 0.9636\n",
      "Epoch 651/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0544 - accuracy: 0.9783 - val_loss: 0.0805 - val_accuracy: 0.9636\n",
      "Epoch 652/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0543 - accuracy: 0.9783 - val_loss: 0.0804 - val_accuracy: 0.9636\n",
      "Epoch 653/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.0542 - accuracy: 0.9783 - val_loss: 0.0803 - val_accuracy: 0.9636\n",
      "Epoch 654/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.0540 - accuracy: 0.9783 - val_loss: 0.0801 - val_accuracy: 0.9636\n",
      "Epoch 655/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0539 - accuracy: 0.9783 - val_loss: 0.0800 - val_accuracy: 0.9636\n",
      "Epoch 656/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0538 - accuracy: 0.9783 - val_loss: 0.0799 - val_accuracy: 0.9636\n",
      "Epoch 657/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.0537 - accuracy: 0.9783 - val_loss: 0.0798 - val_accuracy: 0.9636\n",
      "Epoch 658/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.0535 - accuracy: 0.9783 - val_loss: 0.0797 - val_accuracy: 0.9636\n",
      "Epoch 659/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.0534 - accuracy: 0.9783 - val_loss: 0.0795 - val_accuracy: 0.9636\n",
      "Epoch 660/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0533 - accuracy: 0.9795 - val_loss: 0.0794 - val_accuracy: 0.9636\n",
      "Epoch 661/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0532 - accuracy: 0.9795 - val_loss: 0.0793 - val_accuracy: 0.9636\n",
      "Epoch 662/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0531 - accuracy: 0.9795 - val_loss: 0.0792 - val_accuracy: 0.9636\n",
      "Epoch 663/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "877/877 [==============================] - 0s 23us/step - loss: 0.0529 - accuracy: 0.9795 - val_loss: 0.0791 - val_accuracy: 0.9636\n",
      "Epoch 664/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0528 - accuracy: 0.9795 - val_loss: 0.0790 - val_accuracy: 0.9636\n",
      "Epoch 665/1000\n",
      "877/877 [==============================] - 0s 28us/step - loss: 0.0527 - accuracy: 0.9795 - val_loss: 0.0788 - val_accuracy: 0.9636\n",
      "Epoch 666/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0526 - accuracy: 0.9795 - val_loss: 0.0787 - val_accuracy: 0.9636\n",
      "Epoch 667/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0525 - accuracy: 0.9795 - val_loss: 0.0786 - val_accuracy: 0.9636\n",
      "Epoch 668/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.0524 - accuracy: 0.9795 - val_loss: 0.0785 - val_accuracy: 0.9636\n",
      "Epoch 669/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.0522 - accuracy: 0.9795 - val_loss: 0.0784 - val_accuracy: 0.9636\n",
      "Epoch 670/1000\n",
      "877/877 [==============================] - 0s 30us/step - loss: 0.0521 - accuracy: 0.9795 - val_loss: 0.0783 - val_accuracy: 0.9636\n",
      "Epoch 671/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0520 - accuracy: 0.9795 - val_loss: 0.0781 - val_accuracy: 0.9636\n",
      "Epoch 672/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0519 - accuracy: 0.9795 - val_loss: 0.0780 - val_accuracy: 0.9591\n",
      "Epoch 673/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0518 - accuracy: 0.9795 - val_loss: 0.0779 - val_accuracy: 0.9591\n",
      "Epoch 674/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0517 - accuracy: 0.9795 - val_loss: 0.0778 - val_accuracy: 0.9591\n",
      "Epoch 675/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0516 - accuracy: 0.9795 - val_loss: 0.0777 - val_accuracy: 0.9591\n",
      "Epoch 676/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0515 - accuracy: 0.9795 - val_loss: 0.0776 - val_accuracy: 0.9591\n",
      "Epoch 677/1000\n",
      "877/877 [==============================] - 0s 31us/step - loss: 0.0514 - accuracy: 0.9795 - val_loss: 0.0775 - val_accuracy: 0.9591\n",
      "Epoch 678/1000\n",
      "877/877 [==============================] - 0s 30us/step - loss: 0.0513 - accuracy: 0.9795 - val_loss: 0.0774 - val_accuracy: 0.9591\n",
      "Epoch 679/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0512 - accuracy: 0.9795 - val_loss: 0.0773 - val_accuracy: 0.9591\n",
      "Epoch 680/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0510 - accuracy: 0.9806 - val_loss: 0.0771 - val_accuracy: 0.9591\n",
      "Epoch 681/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.0509 - accuracy: 0.9806 - val_loss: 0.0770 - val_accuracy: 0.9591\n",
      "Epoch 682/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0508 - accuracy: 0.9806 - val_loss: 0.0769 - val_accuracy: 0.9591\n",
      "Epoch 683/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0507 - accuracy: 0.9806 - val_loss: 0.0768 - val_accuracy: 0.9591\n",
      "Epoch 684/1000\n",
      "877/877 [==============================] - 0s 42us/step - loss: 0.0506 - accuracy: 0.9806 - val_loss: 0.0767 - val_accuracy: 0.9591\n",
      "Epoch 685/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.0505 - accuracy: 0.9806 - val_loss: 0.0766 - val_accuracy: 0.9591\n",
      "Epoch 686/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.0504 - accuracy: 0.9806 - val_loss: 0.0765 - val_accuracy: 0.9591\n",
      "Epoch 687/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0503 - accuracy: 0.9806 - val_loss: 0.0764 - val_accuracy: 0.9591\n",
      "Epoch 688/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0502 - accuracy: 0.9806 - val_loss: 0.0763 - val_accuracy: 0.9591\n",
      "Epoch 689/1000\n",
      "877/877 [==============================] - ETA: 0s - loss: 0.0609 - accuracy: 0.96 - 0s 32us/step - loss: 0.0501 - accuracy: 0.9806 - val_loss: 0.0762 - val_accuracy: 0.9591\n",
      "Epoch 690/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0500 - accuracy: 0.9806 - val_loss: 0.0760 - val_accuracy: 0.9591\n",
      "Epoch 691/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0499 - accuracy: 0.9806 - val_loss: 0.0759 - val_accuracy: 0.9591\n",
      "Epoch 692/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0498 - accuracy: 0.9806 - val_loss: 0.0758 - val_accuracy: 0.9591\n",
      "Epoch 693/1000\n",
      "877/877 [==============================] - 0s 27us/step - loss: 0.0497 - accuracy: 0.9806 - val_loss: 0.0757 - val_accuracy: 0.9591\n",
      "Epoch 694/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0496 - accuracy: 0.9806 - val_loss: 0.0756 - val_accuracy: 0.9591\n",
      "Epoch 695/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.0495 - accuracy: 0.9806 - val_loss: 0.0755 - val_accuracy: 0.9591\n",
      "Epoch 696/1000\n",
      "877/877 [==============================] - 0s 28us/step - loss: 0.0494 - accuracy: 0.9806 - val_loss: 0.0754 - val_accuracy: 0.9591\n",
      "Epoch 697/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0493 - accuracy: 0.9806 - val_loss: 0.0753 - val_accuracy: 0.9591\n",
      "Epoch 698/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0492 - accuracy: 0.9806 - val_loss: 0.0752 - val_accuracy: 0.9591\n",
      "Epoch 699/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0491 - accuracy: 0.9818 - val_loss: 0.0751 - val_accuracy: 0.9591\n",
      "Epoch 700/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.0490 - accuracy: 0.9818 - val_loss: 0.0750 - val_accuracy: 0.9591\n",
      "Epoch 701/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0489 - accuracy: 0.9818 - val_loss: 0.0749 - val_accuracy: 0.9591\n",
      "Epoch 702/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.0489 - accuracy: 0.9818 - val_loss: 0.0748 - val_accuracy: 0.9591\n",
      "Epoch 703/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0488 - accuracy: 0.9818 - val_loss: 0.0747 - val_accuracy: 0.9591\n",
      "Epoch 704/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.0487 - accuracy: 0.9818 - val_loss: 0.0746 - val_accuracy: 0.9591\n",
      "Epoch 705/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0486 - accuracy: 0.9818 - val_loss: 0.0745 - val_accuracy: 0.9591\n",
      "Epoch 706/1000\n",
      "877/877 [==============================] - 0s 40us/step - loss: 0.0485 - accuracy: 0.9818 - val_loss: 0.0744 - val_accuracy: 0.9591\n",
      "Epoch 707/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0484 - accuracy: 0.9818 - val_loss: 0.0743 - val_accuracy: 0.9591\n",
      "Epoch 708/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0483 - accuracy: 0.9818 - val_loss: 0.0742 - val_accuracy: 0.9591\n",
      "Epoch 709/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0482 - accuracy: 0.9818 - val_loss: 0.0741 - val_accuracy: 0.9591\n",
      "Epoch 710/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0481 - accuracy: 0.9818 - val_loss: 0.0740 - val_accuracy: 0.9591\n",
      "Epoch 711/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0480 - accuracy: 0.9818 - val_loss: 0.0739 - val_accuracy: 0.9591\n",
      "Epoch 712/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0479 - accuracy: 0.9818 - val_loss: 0.0738 - val_accuracy: 0.9591\n",
      "Epoch 713/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0478 - accuracy: 0.9818 - val_loss: 0.0737 - val_accuracy: 0.9591\n",
      "Epoch 714/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0477 - accuracy: 0.9818 - val_loss: 0.0736 - val_accuracy: 0.9591\n",
      "Epoch 715/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0477 - accuracy: 0.9818 - val_loss: 0.0735 - val_accuracy: 0.9591\n",
      "Epoch 716/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0476 - accuracy: 0.9818 - val_loss: 0.0734 - val_accuracy: 0.9591\n",
      "Epoch 717/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0475 - accuracy: 0.9818 - val_loss: 0.0733 - val_accuracy: 0.9591\n",
      "Epoch 718/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "877/877 [==============================] - 0s 22us/step - loss: 0.0474 - accuracy: 0.9818 - val_loss: 0.0732 - val_accuracy: 0.9591\n",
      "Epoch 719/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0473 - accuracy: 0.9818 - val_loss: 0.0731 - val_accuracy: 0.9591\n",
      "Epoch 720/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0472 - accuracy: 0.9818 - val_loss: 0.0730 - val_accuracy: 0.9591\n",
      "Epoch 721/1000\n",
      "877/877 [==============================] - ETA: 0s - loss: 0.0407 - accuracy: 0.97 - 0s 24us/step - loss: 0.0471 - accuracy: 0.9818 - val_loss: 0.0729 - val_accuracy: 0.9591\n",
      "Epoch 722/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0471 - accuracy: 0.9818 - val_loss: 0.0728 - val_accuracy: 0.9591\n",
      "Epoch 723/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.0470 - accuracy: 0.9818 - val_loss: 0.0727 - val_accuracy: 0.9591\n",
      "Epoch 724/1000\n",
      "877/877 [==============================] - 0s 31us/step - loss: 0.0469 - accuracy: 0.9818 - val_loss: 0.0726 - val_accuracy: 0.9591\n",
      "Epoch 725/1000\n",
      "877/877 [==============================] - 0s 83us/step - loss: 0.0468 - accuracy: 0.9818 - val_loss: 0.0725 - val_accuracy: 0.9591\n",
      "Epoch 726/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0467 - accuracy: 0.9818 - val_loss: 0.0724 - val_accuracy: 0.9591\n",
      "Epoch 727/1000\n",
      "877/877 [==============================] - 0s 61us/step - loss: 0.0466 - accuracy: 0.9818 - val_loss: 0.0723 - val_accuracy: 0.9591\n",
      "Epoch 728/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.0466 - accuracy: 0.9818 - val_loss: 0.0722 - val_accuracy: 0.9591\n",
      "Epoch 729/1000\n",
      "877/877 [==============================] - 0s 50us/step - loss: 0.0465 - accuracy: 0.9818 - val_loss: 0.0721 - val_accuracy: 0.9591\n",
      "Epoch 730/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0464 - accuracy: 0.9818 - val_loss: 0.0720 - val_accuracy: 0.9591\n",
      "Epoch 731/1000\n",
      "877/877 [==============================] - 0s 43us/step - loss: 0.0463 - accuracy: 0.9818 - val_loss: 0.0719 - val_accuracy: 0.9591\n",
      "Epoch 732/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0462 - accuracy: 0.9818 - val_loss: 0.0718 - val_accuracy: 0.9591\n",
      "Epoch 733/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0462 - accuracy: 0.9818 - val_loss: 0.0717 - val_accuracy: 0.9591\n",
      "Epoch 734/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0461 - accuracy: 0.9818 - val_loss: 0.0717 - val_accuracy: 0.9591\n",
      "Epoch 735/1000\n",
      "877/877 [==============================] - 0s 30us/step - loss: 0.0460 - accuracy: 0.9818 - val_loss: 0.0716 - val_accuracy: 0.9591\n",
      "Epoch 736/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.0459 - accuracy: 0.9818 - val_loss: 0.0715 - val_accuracy: 0.9591\n",
      "Epoch 737/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0458 - accuracy: 0.9818 - val_loss: 0.0714 - val_accuracy: 0.9591\n",
      "Epoch 738/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0457 - accuracy: 0.9818 - val_loss: 0.0713 - val_accuracy: 0.9591\n",
      "Epoch 739/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0457 - accuracy: 0.9829 - val_loss: 0.0712 - val_accuracy: 0.9591\n",
      "Epoch 740/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0456 - accuracy: 0.9818 - val_loss: 0.0711 - val_accuracy: 0.9591\n",
      "Epoch 741/1000\n",
      "877/877 [==============================] - 0s 27us/step - loss: 0.0455 - accuracy: 0.9818 - val_loss: 0.0710 - val_accuracy: 0.9591\n",
      "Epoch 742/1000\n",
      "877/877 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 1.00 - 0s 39us/step - loss: 0.0454 - accuracy: 0.9829 - val_loss: 0.0709 - val_accuracy: 0.9591\n",
      "Epoch 743/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0453 - accuracy: 0.9818 - val_loss: 0.0708 - val_accuracy: 0.9591\n",
      "Epoch 744/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0453 - accuracy: 0.9829 - val_loss: 0.0707 - val_accuracy: 0.9591\n",
      "Epoch 745/1000\n",
      "877/877 [==============================] - 0s 27us/step - loss: 0.0452 - accuracy: 0.9829 - val_loss: 0.0706 - val_accuracy: 0.9591\n",
      "Epoch 746/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0451 - accuracy: 0.9829 - val_loss: 0.0705 - val_accuracy: 0.9591\n",
      "Epoch 747/1000\n",
      "877/877 [==============================] - 0s 28us/step - loss: 0.0450 - accuracy: 0.9829 - val_loss: 0.0705 - val_accuracy: 0.9591\n",
      "Epoch 748/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0450 - accuracy: 0.9829 - val_loss: 0.0704 - val_accuracy: 0.9591\n",
      "Epoch 749/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0449 - accuracy: 0.9829 - val_loss: 0.0703 - val_accuracy: 0.9591\n",
      "Epoch 750/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0448 - accuracy: 0.9829 - val_loss: 0.0702 - val_accuracy: 0.9591\n",
      "Epoch 751/1000\n",
      "877/877 [==============================] - 0s 27us/step - loss: 0.0447 - accuracy: 0.9829 - val_loss: 0.0701 - val_accuracy: 0.9591\n",
      "Epoch 752/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0447 - accuracy: 0.9829 - val_loss: 0.0700 - val_accuracy: 0.9591\n",
      "Epoch 753/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0446 - accuracy: 0.9829 - val_loss: 0.0699 - val_accuracy: 0.9591\n",
      "Epoch 754/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0445 - accuracy: 0.9829 - val_loss: 0.0698 - val_accuracy: 0.9591\n",
      "Epoch 755/1000\n",
      "877/877 [==============================] - 0s 28us/step - loss: 0.0444 - accuracy: 0.9829 - val_loss: 0.0697 - val_accuracy: 0.9591\n",
      "Epoch 756/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0444 - accuracy: 0.9829 - val_loss: 0.0697 - val_accuracy: 0.9591\n",
      "Epoch 757/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0443 - accuracy: 0.9829 - val_loss: 0.0696 - val_accuracy: 0.9591\n",
      "Epoch 758/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0442 - accuracy: 0.9829 - val_loss: 0.0695 - val_accuracy: 0.9591\n",
      "Epoch 759/1000\n",
      "877/877 [==============================] - 0s 65us/step - loss: 0.0442 - accuracy: 0.9829 - val_loss: 0.0694 - val_accuracy: 0.9591\n",
      "Epoch 760/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0441 - accuracy: 0.9829 - val_loss: 0.0693 - val_accuracy: 0.9591\n",
      "Epoch 761/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0440 - accuracy: 0.9829 - val_loss: 0.0692 - val_accuracy: 0.9591\n",
      "Epoch 762/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0439 - accuracy: 0.9829 - val_loss: 0.0691 - val_accuracy: 0.9591\n",
      "Epoch 763/1000\n",
      "877/877 [==============================] - 0s 33us/step - loss: 0.0439 - accuracy: 0.9829 - val_loss: 0.0690 - val_accuracy: 0.9636\n",
      "Epoch 764/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0438 - accuracy: 0.9829 - val_loss: 0.0690 - val_accuracy: 0.9636\n",
      "Epoch 765/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0437 - accuracy: 0.9829 - val_loss: 0.0689 - val_accuracy: 0.9636\n",
      "Epoch 766/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.0437 - accuracy: 0.9829 - val_loss: 0.0688 - val_accuracy: 0.9636\n",
      "Epoch 767/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0436 - accuracy: 0.9829 - val_loss: 0.0687 - val_accuracy: 0.9636\n",
      "Epoch 768/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0435 - accuracy: 0.9829 - val_loss: 0.0686 - val_accuracy: 0.9636\n",
      "Epoch 769/1000\n",
      "877/877 [==============================] - 0s 16us/step - loss: 0.0434 - accuracy: 0.9829 - val_loss: 0.0685 - val_accuracy: 0.9636\n",
      "Epoch 770/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.0434 - accuracy: 0.9829 - val_loss: 0.0685 - val_accuracy: 0.9636\n",
      "Epoch 771/1000\n",
      "877/877 [==============================] - 0s 14us/step - loss: 0.0433 - accuracy: 0.9829 - val_loss: 0.0684 - val_accuracy: 0.9636\n",
      "Epoch 772/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.0432 - accuracy: 0.9829 - val_loss: 0.0683 - val_accuracy: 0.9636\n",
      "Epoch 773/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "877/877 [==============================] - 0s 18us/step - loss: 0.0432 - accuracy: 0.9829 - val_loss: 0.0682 - val_accuracy: 0.9636\n",
      "Epoch 774/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0431 - accuracy: 0.9829 - val_loss: 0.0681 - val_accuracy: 0.9636\n",
      "Epoch 775/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.0430 - accuracy: 0.9829 - val_loss: 0.0681 - val_accuracy: 0.9636\n",
      "Epoch 776/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.0430 - accuracy: 0.9829 - val_loss: 0.0680 - val_accuracy: 0.9636\n",
      "Epoch 777/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0429 - accuracy: 0.9829 - val_loss: 0.0679 - val_accuracy: 0.9636\n",
      "Epoch 778/1000\n",
      "877/877 [==============================] - 0s 30us/step - loss: 0.0428 - accuracy: 0.9829 - val_loss: 0.0678 - val_accuracy: 0.9636\n",
      "Epoch 779/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0428 - accuracy: 0.9829 - val_loss: 0.0677 - val_accuracy: 0.9636\n",
      "Epoch 780/1000\n",
      "877/877 [==============================] - 0s 32us/step - loss: 0.0427 - accuracy: 0.9829 - val_loss: 0.0676 - val_accuracy: 0.9636\n",
      "Epoch 781/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0426 - accuracy: 0.9829 - val_loss: 0.0676 - val_accuracy: 0.9636\n",
      "Epoch 782/1000\n",
      "877/877 [==============================] - 0s 39us/step - loss: 0.0426 - accuracy: 0.9829 - val_loss: 0.0675 - val_accuracy: 0.9636\n",
      "Epoch 783/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0425 - accuracy: 0.9829 - val_loss: 0.0674 - val_accuracy: 0.9636\n",
      "Epoch 784/1000\n",
      "877/877 [==============================] - 0s 27us/step - loss: 0.0425 - accuracy: 0.9829 - val_loss: 0.0673 - val_accuracy: 0.9636\n",
      "Epoch 785/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0424 - accuracy: 0.9829 - val_loss: 0.0672 - val_accuracy: 0.9636\n",
      "Epoch 786/1000\n",
      "877/877 [==============================] - 0s 36us/step - loss: 0.0423 - accuracy: 0.9829 - val_loss: 0.0672 - val_accuracy: 0.9636\n",
      "Epoch 787/1000\n",
      "877/877 [==============================] - 0s 30us/step - loss: 0.0422 - accuracy: 0.9829 - val_loss: 0.0671 - val_accuracy: 0.9636\n",
      "Epoch 788/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.0422 - accuracy: 0.9829 - val_loss: 0.0670 - val_accuracy: 0.9636\n",
      "Epoch 789/1000\n",
      "877/877 [==============================] - 0s 27us/step - loss: 0.0421 - accuracy: 0.9829 - val_loss: 0.0669 - val_accuracy: 0.9636\n",
      "Epoch 790/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0420 - accuracy: 0.9829 - val_loss: 0.0668 - val_accuracy: 0.9636\n",
      "Epoch 791/1000\n",
      "877/877 [==============================] - 0s 33us/step - loss: 0.0420 - accuracy: 0.9829 - val_loss: 0.0668 - val_accuracy: 0.9636\n",
      "Epoch 792/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.0419 - accuracy: 0.9829 - val_loss: 0.0667 - val_accuracy: 0.9636\n",
      "Epoch 793/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0419 - accuracy: 0.9829 - val_loss: 0.0666 - val_accuracy: 0.9636\n",
      "Epoch 794/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0418 - accuracy: 0.9829 - val_loss: 0.0665 - val_accuracy: 0.9636\n",
      "Epoch 795/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.0417 - accuracy: 0.9829 - val_loss: 0.0665 - val_accuracy: 0.9636\n",
      "Epoch 796/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0417 - accuracy: 0.9829 - val_loss: 0.0664 - val_accuracy: 0.9636\n",
      "Epoch 797/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.0416 - accuracy: 0.9829 - val_loss: 0.0663 - val_accuracy: 0.9636\n",
      "Epoch 798/1000\n",
      "877/877 [==============================] - 0s 31us/step - loss: 0.0416 - accuracy: 0.9829 - val_loss: 0.0663 - val_accuracy: 0.9636\n",
      "Epoch 799/1000\n",
      "877/877 [==============================] - 0s 27us/step - loss: 0.0415 - accuracy: 0.9829 - val_loss: 0.0662 - val_accuracy: 0.9636\n",
      "Epoch 800/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0414 - accuracy: 0.9829 - val_loss: 0.0661 - val_accuracy: 0.9636\n",
      "Epoch 801/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0414 - accuracy: 0.9829 - val_loss: 0.0660 - val_accuracy: 0.9636\n",
      "Epoch 802/1000\n",
      "877/877 [==============================] - 0s 33us/step - loss: 0.0413 - accuracy: 0.9829 - val_loss: 0.0659 - val_accuracy: 0.9636\n",
      "Epoch 803/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0413 - accuracy: 0.9829 - val_loss: 0.0659 - val_accuracy: 0.9636\n",
      "Epoch 804/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0412 - accuracy: 0.9829 - val_loss: 0.0658 - val_accuracy: 0.9636\n",
      "Epoch 805/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0411 - accuracy: 0.9829 - val_loss: 0.0657 - val_accuracy: 0.9636\n",
      "Epoch 806/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0411 - accuracy: 0.9829 - val_loss: 0.0656 - val_accuracy: 0.9636\n",
      "Epoch 807/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0410 - accuracy: 0.9829 - val_loss: 0.0656 - val_accuracy: 0.9636\n",
      "Epoch 808/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.0410 - accuracy: 0.9829 - val_loss: 0.0655 - val_accuracy: 0.9636\n",
      "Epoch 809/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0409 - accuracy: 0.9829 - val_loss: 0.0654 - val_accuracy: 0.9636\n",
      "Epoch 810/1000\n",
      "877/877 [==============================] - 0s 28us/step - loss: 0.0408 - accuracy: 0.9829 - val_loss: 0.0653 - val_accuracy: 0.9636\n",
      "Epoch 811/1000\n",
      "877/877 [==============================] - 0s 27us/step - loss: 0.0408 - accuracy: 0.9829 - val_loss: 0.0653 - val_accuracy: 0.9636\n",
      "Epoch 812/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0407 - accuracy: 0.9829 - val_loss: 0.0652 - val_accuracy: 0.9636\n",
      "Epoch 813/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0407 - accuracy: 0.9829 - val_loss: 0.0651 - val_accuracy: 0.9636\n",
      "Epoch 814/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0406 - accuracy: 0.9829 - val_loss: 0.0651 - val_accuracy: 0.9636\n",
      "Epoch 815/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.0406 - accuracy: 0.9829 - val_loss: 0.0650 - val_accuracy: 0.9636\n",
      "Epoch 816/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.0405 - accuracy: 0.9829 - val_loss: 0.0649 - val_accuracy: 0.9636\n",
      "Epoch 817/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0405 - accuracy: 0.9829 - val_loss: 0.0648 - val_accuracy: 0.9636\n",
      "Epoch 818/1000\n",
      "877/877 [==============================] - 0s 58us/step - loss: 0.0404 - accuracy: 0.9829 - val_loss: 0.0648 - val_accuracy: 0.9636\n",
      "Epoch 819/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0403 - accuracy: 0.9829 - val_loss: 0.0647 - val_accuracy: 0.9636\n",
      "Epoch 820/1000\n",
      "877/877 [==============================] - 0s 33us/step - loss: 0.0403 - accuracy: 0.9829 - val_loss: 0.0646 - val_accuracy: 0.9636\n",
      "Epoch 821/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0402 - accuracy: 0.9829 - val_loss: 0.0645 - val_accuracy: 0.9636\n",
      "Epoch 822/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.0402 - accuracy: 0.9829 - val_loss: 0.0645 - val_accuracy: 0.9636\n",
      "Epoch 823/1000\n",
      "877/877 [==============================] - 0s 15us/step - loss: 0.0401 - accuracy: 0.9829 - val_loss: 0.0644 - val_accuracy: 0.9636\n",
      "Epoch 824/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.0401 - accuracy: 0.9829 - val_loss: 0.0643 - val_accuracy: 0.9636\n",
      "Epoch 825/1000\n",
      "877/877 [==============================] - 0s 17us/step - loss: 0.0400 - accuracy: 0.9829 - val_loss: 0.0643 - val_accuracy: 0.9636\n",
      "Epoch 826/1000\n",
      "877/877 [==============================] - 0s 16us/step - loss: 0.0400 - accuracy: 0.9829 - val_loss: 0.0642 - val_accuracy: 0.9636\n",
      "Epoch 827/1000\n",
      "877/877 [==============================] - 0s 17us/step - loss: 0.0399 - accuracy: 0.9829 - val_loss: 0.0641 - val_accuracy: 0.9636\n",
      "Epoch 828/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0398 - accuracy: 0.9829 - val_loss: 0.0641 - val_accuracy: 0.9636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 829/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0398 - accuracy: 0.9829 - val_loss: 0.0640 - val_accuracy: 0.9636\n",
      "Epoch 830/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.0397 - accuracy: 0.9829 - val_loss: 0.0639 - val_accuracy: 0.9636\n",
      "Epoch 831/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0397 - accuracy: 0.9829 - val_loss: 0.0638 - val_accuracy: 0.9636\n",
      "Epoch 832/1000\n",
      "877/877 [==============================] - 0s 31us/step - loss: 0.0396 - accuracy: 0.9829 - val_loss: 0.0638 - val_accuracy: 0.9636\n",
      "Epoch 833/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0396 - accuracy: 0.9829 - val_loss: 0.0637 - val_accuracy: 0.9636\n",
      "Epoch 834/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.0395 - accuracy: 0.9829 - val_loss: 0.0637 - val_accuracy: 0.9636\n",
      "Epoch 835/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0395 - accuracy: 0.9829 - val_loss: 0.0636 - val_accuracy: 0.9636\n",
      "Epoch 836/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0394 - accuracy: 0.9829 - val_loss: 0.0635 - val_accuracy: 0.9636\n",
      "Epoch 837/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0394 - accuracy: 0.9829 - val_loss: 0.0635 - val_accuracy: 0.9636\n",
      "Epoch 838/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0393 - accuracy: 0.9829 - val_loss: 0.0634 - val_accuracy: 0.9636\n",
      "Epoch 839/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0393 - accuracy: 0.9829 - val_loss: 0.0633 - val_accuracy: 0.9636\n",
      "Epoch 840/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.0392 - accuracy: 0.9829 - val_loss: 0.0632 - val_accuracy: 0.9636\n",
      "Epoch 841/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0392 - accuracy: 0.9829 - val_loss: 0.0632 - val_accuracy: 0.9636\n",
      "Epoch 842/1000\n",
      "877/877 [==============================] - 0s 28us/step - loss: 0.0391 - accuracy: 0.9829 - val_loss: 0.0631 - val_accuracy: 0.9636\n",
      "Epoch 843/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.0391 - accuracy: 0.9829 - val_loss: 0.0630 - val_accuracy: 0.9636\n",
      "Epoch 844/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0390 - accuracy: 0.9829 - val_loss: 0.0630 - val_accuracy: 0.9636\n",
      "Epoch 845/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0389 - accuracy: 0.9829 - val_loss: 0.0629 - val_accuracy: 0.9636\n",
      "Epoch 846/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0389 - accuracy: 0.9829 - val_loss: 0.0629 - val_accuracy: 0.9636\n",
      "Epoch 847/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0389 - accuracy: 0.9829 - val_loss: 0.0628 - val_accuracy: 0.9636\n",
      "Epoch 848/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0388 - accuracy: 0.9829 - val_loss: 0.0627 - val_accuracy: 0.9636\n",
      "Epoch 849/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0388 - accuracy: 0.9829 - val_loss: 0.0627 - val_accuracy: 0.9636\n",
      "Epoch 850/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0387 - accuracy: 0.9829 - val_loss: 0.0626 - val_accuracy: 0.9636\n",
      "Epoch 851/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.0387 - accuracy: 0.9829 - val_loss: 0.0625 - val_accuracy: 0.9636\n",
      "Epoch 852/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0386 - accuracy: 0.9829 - val_loss: 0.0625 - val_accuracy: 0.9636\n",
      "Epoch 853/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.0386 - accuracy: 0.9829 - val_loss: 0.0624 - val_accuracy: 0.9636\n",
      "Epoch 854/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.0385 - accuracy: 0.9829 - val_loss: 0.0623 - val_accuracy: 0.9636\n",
      "Epoch 855/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0385 - accuracy: 0.9829 - val_loss: 0.0623 - val_accuracy: 0.9636\n",
      "Epoch 856/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0384 - accuracy: 0.9829 - val_loss: 0.0622 - val_accuracy: 0.9636\n",
      "Epoch 857/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0384 - accuracy: 0.9829 - val_loss: 0.0622 - val_accuracy: 0.9636\n",
      "Epoch 858/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.0383 - accuracy: 0.9829 - val_loss: 0.0621 - val_accuracy: 0.9636\n",
      "Epoch 859/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.0383 - accuracy: 0.9829 - val_loss: 0.0620 - val_accuracy: 0.9636\n",
      "Epoch 860/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0382 - accuracy: 0.9829 - val_loss: 0.0620 - val_accuracy: 0.9636\n",
      "Epoch 861/1000\n",
      "877/877 [==============================] - 0s 27us/step - loss: 0.0382 - accuracy: 0.9829 - val_loss: 0.0619 - val_accuracy: 0.9636\n",
      "Epoch 862/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0381 - accuracy: 0.9829 - val_loss: 0.0618 - val_accuracy: 0.9636\n",
      "Epoch 863/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0381 - accuracy: 0.9829 - val_loss: 0.0618 - val_accuracy: 0.9636\n",
      "Epoch 864/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0380 - accuracy: 0.9829 - val_loss: 0.0617 - val_accuracy: 0.9636\n",
      "Epoch 865/1000\n",
      "877/877 [==============================] - 0s 35us/step - loss: 0.0380 - accuracy: 0.9829 - val_loss: 0.0617 - val_accuracy: 0.9636\n",
      "Epoch 866/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0379 - accuracy: 0.9829 - val_loss: 0.0616 - val_accuracy: 0.9636\n",
      "Epoch 867/1000\n",
      "877/877 [==============================] - 0s 27us/step - loss: 0.0379 - accuracy: 0.9829 - val_loss: 0.0615 - val_accuracy: 0.9636\n",
      "Epoch 868/1000\n",
      "877/877 [==============================] - 0s 32us/step - loss: 0.0378 - accuracy: 0.9829 - val_loss: 0.0615 - val_accuracy: 0.9636\n",
      "Epoch 869/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0378 - accuracy: 0.9829 - val_loss: 0.0614 - val_accuracy: 0.9636\n",
      "Epoch 870/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.0377 - accuracy: 0.9829 - val_loss: 0.0614 - val_accuracy: 0.9636\n",
      "Epoch 871/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.0377 - accuracy: 0.9829 - val_loss: 0.0613 - val_accuracy: 0.9636\n",
      "Epoch 872/1000\n",
      "877/877 [==============================] - 0s 28us/step - loss: 0.0377 - accuracy: 0.9829 - val_loss: 0.0612 - val_accuracy: 0.9636\n",
      "Epoch 873/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0376 - accuracy: 0.9829 - val_loss: 0.0612 - val_accuracy: 0.9636\n",
      "Epoch 874/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0376 - accuracy: 0.9829 - val_loss: 0.0611 - val_accuracy: 0.9636\n",
      "Epoch 875/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0375 - accuracy: 0.9829 - val_loss: 0.0610 - val_accuracy: 0.9636\n",
      "Epoch 876/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.0375 - accuracy: 0.9829 - val_loss: 0.0610 - val_accuracy: 0.9636\n",
      "Epoch 877/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0374 - accuracy: 0.9829 - val_loss: 0.0609 - val_accuracy: 0.9636\n",
      "Epoch 878/1000\n",
      "877/877 [==============================] - 0s 28us/step - loss: 0.0374 - accuracy: 0.9829 - val_loss: 0.0609 - val_accuracy: 0.9636\n",
      "Epoch 879/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0373 - accuracy: 0.9829 - val_loss: 0.0608 - val_accuracy: 0.9636\n",
      "Epoch 880/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.0373 - accuracy: 0.9829 - val_loss: 0.0608 - val_accuracy: 0.9636\n",
      "Epoch 881/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.0373 - accuracy: 0.9829 - val_loss: 0.0607 - val_accuracy: 0.9636\n",
      "Epoch 882/1000\n",
      "877/877 [==============================] - 0s 17us/step - loss: 0.0372 - accuracy: 0.9829 - val_loss: 0.0607 - val_accuracy: 0.9636\n",
      "Epoch 883/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.0372 - accuracy: 0.9829 - val_loss: 0.0606 - val_accuracy: 0.9636\n",
      "Epoch 884/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.0371 - accuracy: 0.9829 - val_loss: 0.0605 - val_accuracy: 0.9636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 885/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0371 - accuracy: 0.9829 - val_loss: 0.0605 - val_accuracy: 0.9636\n",
      "Epoch 886/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.0370 - accuracy: 0.9829 - val_loss: 0.0604 - val_accuracy: 0.9636\n",
      "Epoch 887/1000\n",
      "877/877 [==============================] - 0s 27us/step - loss: 0.0370 - accuracy: 0.9829 - val_loss: 0.0604 - val_accuracy: 0.9636\n",
      "Epoch 888/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0370 - accuracy: 0.9829 - val_loss: 0.0603 - val_accuracy: 0.9636\n",
      "Epoch 889/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0369 - accuracy: 0.9829 - val_loss: 0.0603 - val_accuracy: 0.9636\n",
      "Epoch 890/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0369 - accuracy: 0.9829 - val_loss: 0.0602 - val_accuracy: 0.9636\n",
      "Epoch 891/1000\n",
      "877/877 [==============================] - ETA: 0s - loss: 0.0290 - accuracy: 0.99 - 0s 23us/step - loss: 0.0368 - accuracy: 0.9829 - val_loss: 0.0602 - val_accuracy: 0.9636\n",
      "Epoch 892/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.0368 - accuracy: 0.9829 - val_loss: 0.0601 - val_accuracy: 0.9636\n",
      "Epoch 893/1000\n",
      "877/877 [==============================] - 0s 27us/step - loss: 0.0367 - accuracy: 0.9829 - val_loss: 0.0601 - val_accuracy: 0.9636\n",
      "Epoch 894/1000\n",
      "877/877 [==============================] - 0s 27us/step - loss: 0.0367 - accuracy: 0.9829 - val_loss: 0.0600 - val_accuracy: 0.9636\n",
      "Epoch 895/1000\n",
      "877/877 [==============================] - 0s 33us/step - loss: 0.0367 - accuracy: 0.9829 - val_loss: 0.0600 - val_accuracy: 0.9636\n",
      "Epoch 896/1000\n",
      "877/877 [==============================] - 0s 31us/step - loss: 0.0366 - accuracy: 0.9829 - val_loss: 0.0599 - val_accuracy: 0.9636\n",
      "Epoch 897/1000\n",
      "877/877 [==============================] - 0s 28us/step - loss: 0.0366 - accuracy: 0.9829 - val_loss: 0.0599 - val_accuracy: 0.9636\n",
      "Epoch 898/1000\n",
      "877/877 [==============================] - 0s 28us/step - loss: 0.0365 - accuracy: 0.9829 - val_loss: 0.0598 - val_accuracy: 0.9636\n",
      "Epoch 899/1000\n",
      "877/877 [==============================] - 0s 30us/step - loss: 0.0365 - accuracy: 0.9829 - val_loss: 0.0598 - val_accuracy: 0.9636\n",
      "Epoch 900/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.0365 - accuracy: 0.9829 - val_loss: 0.0597 - val_accuracy: 0.9636\n",
      "Epoch 901/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.0364 - accuracy: 0.9829 - val_loss: 0.0596 - val_accuracy: 0.9636\n",
      "Epoch 902/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0364 - accuracy: 0.9829 - val_loss: 0.0596 - val_accuracy: 0.9636\n",
      "Epoch 903/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0363 - accuracy: 0.9829 - val_loss: 0.0595 - val_accuracy: 0.9636\n",
      "Epoch 904/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0363 - accuracy: 0.9829 - val_loss: 0.0595 - val_accuracy: 0.9636\n",
      "Epoch 905/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0363 - accuracy: 0.9829 - val_loss: 0.0594 - val_accuracy: 0.9636\n",
      "Epoch 906/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0362 - accuracy: 0.9829 - val_loss: 0.0594 - val_accuracy: 0.9636\n",
      "Epoch 907/1000\n",
      "877/877 [==============================] - 0s 41us/step - loss: 0.0362 - accuracy: 0.9829 - val_loss: 0.0593 - val_accuracy: 0.9636\n",
      "Epoch 908/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0361 - accuracy: 0.9829 - val_loss: 0.0593 - val_accuracy: 0.9636\n",
      "Epoch 909/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0361 - accuracy: 0.9829 - val_loss: 0.0593 - val_accuracy: 0.9636\n",
      "Epoch 910/1000\n",
      "877/877 [==============================] - 0s 45us/step - loss: 0.0361 - accuracy: 0.9829 - val_loss: 0.0592 - val_accuracy: 0.9636\n",
      "Epoch 911/1000\n",
      "877/877 [==============================] - 0s 31us/step - loss: 0.0360 - accuracy: 0.9829 - val_loss: 0.0592 - val_accuracy: 0.9636\n",
      "Epoch 912/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0360 - accuracy: 0.9829 - val_loss: 0.0591 - val_accuracy: 0.9636\n",
      "Epoch 913/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.0360 - accuracy: 0.9829 - val_loss: 0.0591 - val_accuracy: 0.9636\n",
      "Epoch 914/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0359 - accuracy: 0.9829 - val_loss: 0.0590 - val_accuracy: 0.9636\n",
      "Epoch 915/1000\n",
      "877/877 [==============================] - ETA: 0s - loss: 0.0475 - accuracy: 0.97 - 0s 23us/step - loss: 0.0359 - accuracy: 0.9829 - val_loss: 0.0590 - val_accuracy: 0.9636\n",
      "Epoch 916/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0358 - accuracy: 0.9829 - val_loss: 0.0589 - val_accuracy: 0.9636\n",
      "Epoch 917/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0358 - accuracy: 0.9829 - val_loss: 0.0589 - val_accuracy: 0.9636\n",
      "Epoch 918/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0358 - accuracy: 0.9829 - val_loss: 0.0588 - val_accuracy: 0.9636\n",
      "Epoch 919/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.0357 - accuracy: 0.9829 - val_loss: 0.0588 - val_accuracy: 0.9636\n",
      "Epoch 920/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0357 - accuracy: 0.9829 - val_loss: 0.0587 - val_accuracy: 0.9636\n",
      "Epoch 921/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0356 - accuracy: 0.9829 - val_loss: 0.0587 - val_accuracy: 0.9636\n",
      "Epoch 922/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0356 - accuracy: 0.9829 - val_loss: 0.0586 - val_accuracy: 0.9636\n",
      "Epoch 923/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0356 - accuracy: 0.9829 - val_loss: 0.0586 - val_accuracy: 0.9636\n",
      "Epoch 924/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0355 - accuracy: 0.9829 - val_loss: 0.0585 - val_accuracy: 0.9636\n",
      "Epoch 925/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0355 - accuracy: 0.9829 - val_loss: 0.0585 - val_accuracy: 0.9636\n",
      "Epoch 926/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.0355 - accuracy: 0.9829 - val_loss: 0.0584 - val_accuracy: 0.9636\n",
      "Epoch 927/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0354 - accuracy: 0.9829 - val_loss: 0.0584 - val_accuracy: 0.9636\n",
      "Epoch 928/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0354 - accuracy: 0.9829 - val_loss: 0.0584 - val_accuracy: 0.9636\n",
      "Epoch 929/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.0353 - accuracy: 0.9829 - val_loss: 0.0583 - val_accuracy: 0.9636\n",
      "Epoch 930/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0353 - accuracy: 0.9829 - val_loss: 0.0583 - val_accuracy: 0.9636\n",
      "Epoch 931/1000\n",
      "877/877 [==============================] - 0s 15us/step - loss: 0.0353 - accuracy: 0.9829 - val_loss: 0.0582 - val_accuracy: 0.9682\n",
      "Epoch 932/1000\n",
      "877/877 [==============================] - 0s 15us/step - loss: 0.0353 - accuracy: 0.9829 - val_loss: 0.0582 - val_accuracy: 0.9682\n",
      "Epoch 933/1000\n",
      "877/877 [==============================] - 0s 15us/step - loss: 0.0352 - accuracy: 0.9863 - val_loss: 0.0581 - val_accuracy: 0.9682\n",
      "Epoch 934/1000\n",
      "877/877 [==============================] - 0s 14us/step - loss: 0.0352 - accuracy: 0.9863 - val_loss: 0.0581 - val_accuracy: 0.9682\n",
      "Epoch 935/1000\n",
      "877/877 [==============================] - 0s 15us/step - loss: 0.0351 - accuracy: 0.9863 - val_loss: 0.0580 - val_accuracy: 0.9682\n",
      "Epoch 936/1000\n",
      "877/877 [==============================] - 0s 15us/step - loss: 0.0351 - accuracy: 0.9852 - val_loss: 0.0580 - val_accuracy: 0.9682\n",
      "Epoch 937/1000\n",
      "877/877 [==============================] - 0s 15us/step - loss: 0.0351 - accuracy: 0.9863 - val_loss: 0.0579 - val_accuracy: 0.9682\n",
      "Epoch 938/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0350 - accuracy: 0.9863 - val_loss: 0.0579 - val_accuracy: 0.9682\n",
      "Epoch 939/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.0350 - accuracy: 0.9863 - val_loss: 0.0578 - val_accuracy: 0.9682\n",
      "Epoch 940/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "877/877 [==============================] - 0s 19us/step - loss: 0.0350 - accuracy: 0.9863 - val_loss: 0.0578 - val_accuracy: 0.9682\n",
      "Epoch 941/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.0349 - accuracy: 0.9863 - val_loss: 0.0577 - val_accuracy: 0.9682\n",
      "Epoch 942/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.0349 - accuracy: 0.9863 - val_loss: 0.0577 - val_accuracy: 0.9682\n",
      "Epoch 943/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0349 - accuracy: 0.9863 - val_loss: 0.0576 - val_accuracy: 0.9682\n",
      "Epoch 944/1000\n",
      "877/877 [==============================] - 0s 45us/step - loss: 0.0348 - accuracy: 0.9863 - val_loss: 0.0576 - val_accuracy: 0.9682\n",
      "Epoch 945/1000\n",
      "877/877 [==============================] - 0s 32us/step - loss: 0.0348 - accuracy: 0.9863 - val_loss: 0.0576 - val_accuracy: 0.9682\n",
      "Epoch 946/1000\n",
      "877/877 [==============================] - 0s 32us/step - loss: 0.0347 - accuracy: 0.9863 - val_loss: 0.0575 - val_accuracy: 0.9682\n",
      "Epoch 947/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0347 - accuracy: 0.9863 - val_loss: 0.0575 - val_accuracy: 0.9682\n",
      "Epoch 948/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0347 - accuracy: 0.9863 - val_loss: 0.0574 - val_accuracy: 0.9682\n",
      "Epoch 949/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0346 - accuracy: 0.9863 - val_loss: 0.0574 - val_accuracy: 0.9682\n",
      "Epoch 950/1000\n",
      "877/877 [==============================] - 0s 33us/step - loss: 0.0346 - accuracy: 0.9863 - val_loss: 0.0573 - val_accuracy: 0.9682\n",
      "Epoch 951/1000\n",
      "877/877 [==============================] - 0s 27us/step - loss: 0.0346 - accuracy: 0.9863 - val_loss: 0.0573 - val_accuracy: 0.9682\n",
      "Epoch 952/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0345 - accuracy: 0.9863 - val_loss: 0.0573 - val_accuracy: 0.9682\n",
      "Epoch 953/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0345 - accuracy: 0.9863 - val_loss: 0.0572 - val_accuracy: 0.9682\n",
      "Epoch 954/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0345 - accuracy: 0.9863 - val_loss: 0.0572 - val_accuracy: 0.9682\n",
      "Epoch 955/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0345 - accuracy: 0.9863 - val_loss: 0.0571 - val_accuracy: 0.9682\n",
      "Epoch 956/1000\n",
      "877/877 [==============================] - 0s 31us/step - loss: 0.0344 - accuracy: 0.9863 - val_loss: 0.0571 - val_accuracy: 0.9682\n",
      "Epoch 957/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0344 - accuracy: 0.9863 - val_loss: 0.0570 - val_accuracy: 0.9682\n",
      "Epoch 958/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0343 - accuracy: 0.9875 - val_loss: 0.0570 - val_accuracy: 0.9682\n",
      "Epoch 959/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0343 - accuracy: 0.9875 - val_loss: 0.0570 - val_accuracy: 0.9682\n",
      "Epoch 960/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0343 - accuracy: 0.9875 - val_loss: 0.0569 - val_accuracy: 0.9682\n",
      "Epoch 961/1000\n",
      "877/877 [==============================] - 0s 32us/step - loss: 0.0342 - accuracy: 0.9875 - val_loss: 0.0569 - val_accuracy: 0.9682\n",
      "Epoch 962/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0342 - accuracy: 0.9875 - val_loss: 0.0568 - val_accuracy: 0.9682\n",
      "Epoch 963/1000\n",
      "877/877 [==============================] - 0s 28us/step - loss: 0.0342 - accuracy: 0.9875 - val_loss: 0.0568 - val_accuracy: 0.9682\n",
      "Epoch 964/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.0341 - accuracy: 0.9875 - val_loss: 0.0567 - val_accuracy: 0.9682\n",
      "Epoch 965/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0341 - accuracy: 0.9875 - val_loss: 0.0567 - val_accuracy: 0.9682\n",
      "Epoch 966/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0341 - accuracy: 0.9875 - val_loss: 0.0567 - val_accuracy: 0.9682\n",
      "Epoch 967/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.0340 - accuracy: 0.9875 - val_loss: 0.0566 - val_accuracy: 0.9682\n",
      "Epoch 968/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0340 - accuracy: 0.9875 - val_loss: 0.0566 - val_accuracy: 0.9682\n",
      "Epoch 969/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.0340 - accuracy: 0.9875 - val_loss: 0.0565 - val_accuracy: 0.9682\n",
      "Epoch 970/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.0340 - accuracy: 0.9875 - val_loss: 0.0565 - val_accuracy: 0.9682\n",
      "Epoch 971/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0339 - accuracy: 0.9875 - val_loss: 0.0564 - val_accuracy: 0.9682\n",
      "Epoch 972/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0339 - accuracy: 0.9875 - val_loss: 0.0564 - val_accuracy: 0.9682\n",
      "Epoch 973/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0339 - accuracy: 0.9875 - val_loss: 0.0563 - val_accuracy: 0.9682\n",
      "Epoch 974/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0338 - accuracy: 0.9875 - val_loss: 0.0563 - val_accuracy: 0.9682\n",
      "Epoch 975/1000\n",
      "877/877 [==============================] - 0s 23us/step - loss: 0.0338 - accuracy: 0.9875 - val_loss: 0.0563 - val_accuracy: 0.9682\n",
      "Epoch 976/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0338 - accuracy: 0.9875 - val_loss: 0.0562 - val_accuracy: 0.9682\n",
      "Epoch 977/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0337 - accuracy: 0.9875 - val_loss: 0.0562 - val_accuracy: 0.9682\n",
      "Epoch 978/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0337 - accuracy: 0.9875 - val_loss: 0.0561 - val_accuracy: 0.9682\n",
      "Epoch 979/1000\n",
      "877/877 [==============================] - 0s 27us/step - loss: 0.0337 - accuracy: 0.9875 - val_loss: 0.0561 - val_accuracy: 0.9682\n",
      "Epoch 980/1000\n",
      "877/877 [==============================] - 0s 30us/step - loss: 0.0336 - accuracy: 0.9875 - val_loss: 0.0560 - val_accuracy: 0.9682\n",
      "Epoch 981/1000\n",
      "877/877 [==============================] - 0s 25us/step - loss: 0.0336 - accuracy: 0.9875 - val_loss: 0.0560 - val_accuracy: 0.9682\n",
      "Epoch 982/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.0336 - accuracy: 0.9875 - val_loss: 0.0560 - val_accuracy: 0.9682\n",
      "Epoch 983/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0336 - accuracy: 0.9875 - val_loss: 0.0559 - val_accuracy: 0.9682\n",
      "Epoch 984/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0335 - accuracy: 0.9875 - val_loss: 0.0559 - val_accuracy: 0.9682\n",
      "Epoch 985/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0335 - accuracy: 0.9875 - val_loss: 0.0558 - val_accuracy: 0.9682\n",
      "Epoch 986/1000\n",
      "877/877 [==============================] - 0s 20us/step - loss: 0.0335 - accuracy: 0.9875 - val_loss: 0.0558 - val_accuracy: 0.9682\n",
      "Epoch 987/1000\n",
      "877/877 [==============================] - 0s 24us/step - loss: 0.0334 - accuracy: 0.9875 - val_loss: 0.0558 - val_accuracy: 0.9682\n",
      "Epoch 988/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0334 - accuracy: 0.9875 - val_loss: 0.0557 - val_accuracy: 0.9682\n",
      "Epoch 989/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0334 - accuracy: 0.9875 - val_loss: 0.0557 - val_accuracy: 0.9682\n",
      "Epoch 990/1000\n",
      "877/877 [==============================] - 0s 19us/step - loss: 0.0333 - accuracy: 0.9875 - val_loss: 0.0556 - val_accuracy: 0.9682\n",
      "Epoch 991/1000\n",
      "877/877 [==============================] - 0s 18us/step - loss: 0.0333 - accuracy: 0.9875 - val_loss: 0.0556 - val_accuracy: 0.9682\n",
      "Epoch 992/1000\n",
      "877/877 [==============================] - 0s 22us/step - loss: 0.0333 - accuracy: 0.9875 - val_loss: 0.0556 - val_accuracy: 0.9682\n",
      "Epoch 993/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.0333 - accuracy: 0.9875 - val_loss: 0.0555 - val_accuracy: 0.9682\n",
      "Epoch 994/1000\n",
      "877/877 [==============================] - 0s 30us/step - loss: 0.0332 - accuracy: 0.9875 - val_loss: 0.0555 - val_accuracy: 0.9682\n",
      "Epoch 995/1000\n",
      "877/877 [==============================] - 0s 38us/step - loss: 0.0332 - accuracy: 0.9875 - val_loss: 0.0554 - val_accuracy: 0.9682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 996/1000\n",
      "877/877 [==============================] - 0s 33us/step - loss: 0.0332 - accuracy: 0.9875 - val_loss: 0.0554 - val_accuracy: 0.9682\n",
      "Epoch 997/1000\n",
      "877/877 [==============================] - 0s 28us/step - loss: 0.0331 - accuracy: 0.9875 - val_loss: 0.0554 - val_accuracy: 0.9682\n",
      "Epoch 998/1000\n",
      "877/877 [==============================] - 0s 27us/step - loss: 0.0331 - accuracy: 0.9875 - val_loss: 0.0553 - val_accuracy: 0.9682\n",
      "Epoch 999/1000\n",
      "877/877 [==============================] - 0s 26us/step - loss: 0.0331 - accuracy: 0.9875 - val_loss: 0.0553 - val_accuracy: 0.9682\n",
      "Epoch 1000/1000\n",
      "877/877 [==============================] - 0s 28us/step - loss: 0.0330 - accuracy: 0.9875 - val_loss: 0.0552 - val_accuracy: 0.9682\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                   batch_size=128, epochs=1000,\n",
    "                   validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0a8f26d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afbb8a3",
   "metadata": {},
   "source": [
    "## Visualizing our model performance by plotting loss and accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "610bde1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAHwCAYAAADuJ7gwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAA+IklEQVR4nO3deXhU5d3G8fuXHUhCIokgBAkgqIgCGsEdRQUEigsooKi4VqxLa9XavrW21qXu2rqiRcWNTVRccUeLoIACIosiixBZwhYgkP15/8iAISaQhJk8k8n3c11cM2eZmXuYa/TmOc85Y845AQAAoG5F+Q4AAADQEFHCAAAAPKCEAQAAeEAJAwAA8IASBgAA4AElDAAAwANKGICIZ2aZZubMLKYa+44ws//t6/MAwN5QwgCEFTNbbmaFZpZWYf03gQKU6SkaAAQVJQxAOFomadjOBTM7XFJjf3EAIPgoYQDC0QuSLiq3fLGkMeV3MLOmZjbGzHLMbIWZ/dXMogLbos3sfjNbb2ZLJfWv5LH/NbPVZpZtZneYWXRNQ5pZSzObbGYbzWyJmV1Rblt3M5tlZlvMbK2ZPRhYn2BmL5rZBjPbbGYzzax5TV8bQP1HCQMQjmZISjazQwPlaKikFyvs8x9JTSW1k9RTZaXtksC2KyQNkNRNUpakwRUe+5ykYkkHBfbpLenyWuQcK2mVpJaB17jLzHoFtj0i6RHnXLKk9pLGB9ZfHMjdWlIzSVdJ2lGL1wZQz1HCAISrnaNhp0taKCl754ZyxezPzrmtzrnlkh6QdGFgl/MkPeycW+mc2yjp7nKPbS6pn6TfO+fynHPrJD0UeL5qM7PWko6X9CfnXL5zbo6kZ/TLCF6RpIPMLM05t805N6Pc+maSDnLOlTjnZjvnttTktQFEBkoYgHD1gqTzJY1QhUORktIkxUpaUW7dCkmtAvdbSlpZYdtObQKPXR04HLhZ0lOS9q9hvpaSNjrntlaR4TJJHSUtChxyHFDufU2RNNbMfjaze80stoavDSACUMIAhCXn3AqVTdDvJ2lShc3rVTai1KbcugP1y2jZapUd7iu/baeVkgokpTnnUgJ/kp1zh9Uw4s+S9jOzpMoyOOd+cM4NU1m5u0fSRDNr4pwrcs79wznXSdJxKjtsepEANDiUMADh7DJJvZxzeeVXOudKVDbH6k4zSzKzNpJu0C/zxsZLus7MMswsVdIt5R67WtL7kh4ws2QzizKz9mbWsybBnHMrJX0h6e7AZPsjAnlflCQzG25m6c65UkmbAw8rNbNTzOzwwCHVLSork6U1eW0AkYESBiBsOed+dM7NqmLztZLyJC2V9D9JL0saHdj2tMoO+c2V9LV+PZJ2kaQ4SQskbZI0UdIBtYg4TFKmykbFXpN0m3Puw8C2vpK+M7NtKpukP9Q5t0NSi8DrbVHZXLepKjtECaCBMeec7wwAAAANDiNhAAAAHlDCAAAAPKCEAQAAeEAJAwAA8IASBgAA4EGM7wA1lZaW5jIzM33HAAAA2KvZs2evd86lV7at3pWwzMxMzZpV1WWDAAAAwoeZrahqG4cjAQAAPKCEAQAAeBCyEmZmo81snZnNr2L7BWY2z8y+NbMvzKxLqLIAAACEm1DOCXtO0qOSxlSxfZmkns65TWZ2hqRRknqEMA8AAPCsqKhIq1atUn5+vu8oQZWQkKCMjAzFxsZW+zEhK2HOuc/MLHMP278otzhDUkaosgAAgPCwatUqJSUlKTMzU2bmO05QOOe0YcMGrVq1Sm3btq3248JlTthlkt71HQIAAIRWfn6+mjVrFjEFTJLMTM2aNavx6J73S1SY2SkqK2En7GGfKyVdKUkHHnhgHSUDAAChEEkFbKfavCevI2FmdoSkZySd6ZzbUNV+zrlRzrks51xWenql1zsDAAColsTERN8RJHksYWZ2oKRJki50zn3vKwcAAIAPobxExSuSpks62MxWmdllZnaVmV0V2OVvkppJetzM5pgZl8EHAAB1xjmnm266SZ07d9bhhx+ucePGSZJWr16tk046SV27dlXnzp31+eefq6SkRCNGjNi170MPPbTPrx/KsyOH7WX75ZIuD9XrAwCA8Pb7936vOWvmBPU5u7boqof7PlytfSdNmqQ5c+Zo7ty5Wr9+vY4++middNJJevnll9WnTx/93//9n0pKSrR9+3bNmTNH2dnZmj+/7PKnmzdv3ues4XJ2JAAAQJ363//+p2HDhik6OlrNmzdXz549NXPmTB199NF69tln9fe//13ffvutkpKS1K5dOy1dulTXXnut3nvvPSUnJ+/z63s/OxIAADRM1R2xqmsnnXSSPvvsM7399tsaMWKEbrjhBl100UWaO3eupkyZoieffFLjx4/X6NGj9+l1GAkDAAAN0oknnqhx48appKREOTk5+uyzz9S9e3etWLFCzZs31xVXXKHLL79cX3/9tdavX6/S0lINGjRId9xxh77++ut9fn1GwgAAQIN09tlna/r06erSpYvMTPfee69atGih559/Xvfdd59iY2OVmJioMWPGKDs7W5dccolKS0slSXffffc+v7455/b5SepSVlaWmzWLEykBAKiPFi5cqEMPPdR3jJCo7L2Z2WznXFZl+3M4soJSV6rN+ZtVUFzgOwoAAIhglLAK5qyZo9R7UjXlxym+owAAgAhGCaugSWwTSVJeYZ7nJAAAIJJRwipIjCv7Palthds8JwEAIDLVt/no1VGb90QJq4ASBgBA6CQkJGjDhg0RVcScc9qwYYMSEhJq9DguUVFBk7iyw5GUMAAAgi8jI0OrVq1STk6O7yhBlZCQoIyMjBo9hhJWQUxUjOKj45VXxJwwAACCLTY2Vm3btvUdIyxwOLISiXGJjIQBAICQooRVghIGAABCjRJWCUoYAAAINUpYJZrENaGEAQCAkKKEVSIxLpGJ+QAAIKQoYZXgcCQAAAg1SlglKGEAACDUKGGVaBLLnDAAABBalLBKJMYl8gPeAAAgpChhldh5ODKSftcKAACEF0pYJRLjEuXktKN4h+8oAAAgQlHCKtEklh/xBgAAoUUJq0RiXKIkMS8MAACEDCWsEjtLGCNhAAAgVChhlaCEAQCAUKOEVYISBgAAQo0SVokmcUzMBwAAoUUJq0RyfLIkaWvhVs9JAABApKKEVWJnCdtSsMVzEgAAEKkoYZVIikuSRAkDAAChQwmrRHxMvOKj4ylhAAAgZChhVUiOT6aEAQCAkKGEVYESBgAAQokSVoXk+GTlFuT6jgEAACIUJawKjIQBAIBQooRVgRIGAABCiRJWhaYJTSlhAAAgZChhVUiOYyQMAACEDiWsChyOBAAAoUQJq0JyfLIKSwpVUFzgOwoAAIhAlLAq8PuRAAAglChhVaCEAQCAUKKEVWFnCeOCrQAAIBQoYVVgJAwAAIQSJawKlDAAABBKlLAqNE1oKknKzedwJAAACD5KWBVSElIkSZvyN/kNAgAAIhIlrAo7S9jm/M1ecwAAgMhECatCTFSMkuKStGkHI2EAACD4KGF7kNoolcORAAAgJChhe5CSkEIJAwAAIUEJ24PUhFTmhAEAgJCghO1BaqNU5oQBAICQoITtAYcjAQBAqFDC9oDDkQAAIFQoYXuQmpCqbYXbVFRS5DsKAACIMJSwPeCCrQAAIFQoYXuQ2ihVEiUMAAAEHyVsD1ITykoYk/MBAECwhayEmdloM1tnZvOr2G5m9m8zW2Jm88zsyFBlqa1dP+LNZSoAAECQhXIk7DlJffew/QxJHQJ/rpT0RAiz1MrOw5GMhAEAgGALWQlzzn0maeMedjlT0hhXZoakFDM7IFR5aqNZo2aSpA3bN3hOAgAAIo3POWGtJK0st7wqsO5XzOxKM5tlZrNycnLqJJwkNWtcVsLWb19fZ68JAAAahnoxMd85N8o5l+Wcy0pPT6+z142JilFqQqpyttdd8QMAAA2DzxKWLal1ueWMwLqwkt4knZEwAAAQdD5L2GRJFwXOkjxGUq5zbrXHPJVKa5xGCQMAAEEXE6onNrNXJJ0sKc3MVkm6TVKsJDnnnpT0jqR+kpZI2i7pklBl2RdpjdO0fPNy3zEAAECECVkJc84N28t2J+l3oXr9YElvnK5ZP8/yHQMAAESYejEx36e0xmnKyctRWWcEAAAIDkrYXqQ3TldRaZG2Fm71HQUAAEQQSthepDVOk8S1wgAAQHBRwvZiZwnLyeNaYQAAIHgoYXuR3qTs4rCMhAEAgGCihO3FrpEwrpoPAACCiBK2F+mNGQkDAADBRwnbi8S4RMVFx1HCAABAUFHC9sLMlN44nYn5AAAgqChh1ZDWOE3rdzASBgAAgocSVg07r5oPAAAQLJSwakhvks7ZkQAAIKgoYdXQvElzrd221ncMAAAQQShh1dAyqaW2Fm7VtsJtvqMAAIAIQQmrhgMSD5Akrd662nMSAAAQKShh1dAyqaUk6eetP3tOAgAAIgUlrBoOSAqMhG1jJAwAAAQHJawaGAkDAADBRgmrhqbxTZUQk0AJAwAAQUMJqwYzU8uklhyOBAAAQUMJq6aWSS0ZCQMAAEFDCaumAxIP4BIVAAAgaChh1cRIGAAACCZKWDUdkHgAV80HAABBQwmrpp2XqeCQJAAACAZKWDXtvGArhyQBAEAwUMKqiQu2AgCAYKKEVVOrpFaSpFVbVnlOAgAAIgElrJqaJjRVSkKKVuSu8B0FAABEAEpYDbRp2kbLNy/3HQMAAEQASlgNZKZkMhIGAACCghJWAztHwpxzvqMAAIB6jhJWA5kpmdpWuE2b8jf5jgIAAOo5SlgNZKZkShLzwgAAwD6jhNVAm5Q2kqQVm5kXBgAA9g0lrAYYCQMAAMFCCauB1IRUJcYlcoYkAADYZ5SwGjAzZaZkMhIGAAD2GSWshrhWGAAACAZKWA1lNs3U0k1LuVYYAADYJ5SwGurQrIO2FGxRzvYc31EAAEA9RgmroY7NOkqSvt/wveckAACgPqOE1RAlDAAABAMlrIbaNG2juOg4LV6/2HcUAABQj1HCaig6KloH7XeQvt/ISBgAAKg9SlgtdGzWkcORAABgn1DCaqHjfh21ZOMSlZSW+I4CAADqKUpYLXRs1lGFJYVctBUAANQaJawWOEMSAADsK0pYLRycdrAkadH6RZ6TAACA+ooSVgvpjdOV1jhN89fN9x0FAADUU5SwWjAzdWneRfPWzvMdBQAA1FOUsFo6ovkRmr9uPmdIAgCAWqGE1VKX5l20o3iHlmxc4jsKAACohyhhtXRE8yMkSXPXzvWcBAAA1EeUsFrqlN5J0RbNvDAAAFArlLBaio+J1yFphzASBgAAaoUStg+OaH6E5q6hhAEAgJqjhO2Dbi26aeWWlcrJy/EdBQAA1DOUsH3QI6OHJOmr7K88JwEAAPUNJWwfHHnAkYqyKH2Z/aXvKAAAoJ4JaQkzs75mttjMlpjZLZVsP9DMPjGzb8xsnpn1C2WeYEuMS1Tn/TszEgYAAGosZCXMzKIlPSbpDEmdJA0zs04VdvurpPHOuW6Shkp6PFR5QqVHqx76KvsrOed8RwEAAPVIKEfCukta4pxb6pwrlDRW0pkV9nGSkgP3m0r6OYR5QqJ7q+7alL+JK+cDAIAaCWUJayVpZbnlVYF15f1d0nAzWyXpHUnXVvZEZnalmc0ys1k5OeF1JmKPVmWT85kXBgAAasL3xPxhkp5zzmVI6ifpBTP7VSbn3CjnXJZzLis9Pb3OQ+5Jp/ROSopL0rSfpvmOAgAA6pFQlrBsSa3LLWcE1pV3maTxkuScmy4pQVJaCDMFXXRUtE5sc6I+XfGp7ygAAKAeCWUJmympg5m1NbM4lU28n1xhn58knSpJZnaoykpYeB1vrIaT25ysResXac22Nb6jAACAeiJkJcw5VyzpGklTJC1U2VmQ35nZ7WY2MLDbHyVdYWZzJb0iaYSrh6cZnpx5siRp6vKpfoMAAIB6IyaUT+6ce0dlE+7Lr/tbufsLJB0fygx1odsB3ZQUl6RPl3+qIZ2H+I4DAADqAd8T8yNCTFQM88IAAECNUMKC5JTMU7Ro/SJlb6l47gEAAMCvUcKCpE/7PpKk95a85zkJAACoDyhhQdJ5/85qldRK7/1ICQMAAHtHCQsSM1Pfg/rqgx8/UHFpse84AAAgzFHCgqjvQX2VW5CrGatm+I4CAADCHCUsiE5rd5qiLVrv/PDO3ncGAAANGiUsiFISUtQzs6deW/Sa7ygAACDMUcKC7JxDztGi9Yu0MGeh7ygAACCMUcKC7OxDz5YkvbrwVc9JAABAOKOEBVnLpJY6NuNYTVo4yXcUAAAQxihhITDo0EH6Zs03+mHDD76jAACAMEUJC4EhnYfIZHpx3ou+owAAgDBFCQuBjOQM9WrbSy9++6Kcc77jAACAMEQJC5ELj7hQSzct1Rcrv/AdBQAAhCFKWIicc+g5ahzbWM/Nec53FAAAEIYoYSGSFJ+koYcN1cvzX1Zufq7vOAAAIMxQwkJo5NEjtb1ou16Y94LvKAAAIMxQwkIoq2WWjm55tJ6Y9QQT9AEAwG4oYSE2MmukFuQs0GcrPvMdBQAAhBFKWIgN6TxEqQmp+s9X//EdBQAAhBFKWIg1jm2skVkjNWnhJH2/4XvfcQAAQJighNWB63pcp/iYeN037T7fUQAAQJighNWB5onNdWnXS/X83OeVvSXbdxwAABAGKGF15MbjblSpK9WD0x/0HQUAAIQBSlgdaZvaVucffr6emPWEVm9d7TsOAADwjBJWh27reZuKSot01+d3+Y4CAAA8o4TVofb7tdelXS/VU7Of0orNK3zHAQAAHlHC6thfT/qrzEz/mPoP31EAAIBHlLA61rppa13X/To9N+c5zcye6TsOAADwhBLmwa09b1XzxOa65t1rVOpKfccBAAAeUMI8SI5P1r2n3auvsr/Sc3Oe8x0HAAB4QAnzZPgRw3V86+N10wc3ae22tb7jAACAOkYJ88TM9MzAZ5RXmKdr3r3GdxwAAFDHKGEeHZJ2iP5+8t81ccFETVww0XccAABQhyhhnt143I066oCjdNVbV/G7kgAANCCUMM9iomL00jkvKb84XxdMukAlpSW+IwEAgDpACQsDB6cdrEf7PaqpK6byk0YAADQQlLAwcXGXi3XB4Rfo71P/rk+Xf+o7DgAACDFKWJgwMz3R/wkd3OxgnTvhXC3fvNx3JAAAEEKUsDCSFJ+kN4a+oeLSYp059kxtK9zmOxIAAAgRSliY6dCsg8YOGqv56+ZrxOsj+FkjAAAiFCUsDPU5qI/uPe1evbrwVf3tk7/5jgMAAEIgxncAVO6GY2/QwvULdefnd6pdajtd2u1S35EAAEAQUcLC1M6J+iu3rNSVb16pjOQM9W7f23csAAAQJByODGOx0bGacO4EdUrvpMHjB2ve2nm+IwEAgCChhIW55PhkvXPBO0qKT1L/l/tr1ZZVviMBAIAgoITVAxnJGXr7/LeVm5+r3i/0Vk5eju9IAABgH1HC6omuLbrqzWFvatnmZer7Ul/l5uf6jgQAAPYBJawe6ZnZUxPPnah5a+fpN6/8RtuLtvuOBAAAaokSVs/079hfL579ov730/80aPwgFZYU+o4EAABqgRJWDw3pPERPDXhK7y15T8MnDVdJaYnvSAAAoIa4Tlg9dcVRV2hLwRbd+MGNSopL0tMDn1aU0akBAKgvKGH12B+P+6M252/WHZ/foaYJTfVA7wdkZr5jAQCAaqCE1XO3n3K7cgty9dCMh5SakKpbe97qOxIAAKgGSlg9Z2Z6uO/Dyi3I1d8+/ZtSElJ0bY9rfccCAAB7Ua0SZmZNJO1wzpWaWUdJh0h61zlXFNJ0qJYoi9J/B/5Xufm5uu6965SSkKILu1zoOxYAANiD6s7k/kxSgpm1kvS+pAslPReqUKi5mKgYjR08Vr3a9tIlb1yiNxa94TsSAADYg+qWMHPObZd0jqTHnXPnSjosdLFQGwkxCXp9yOs6quVRGjJxiD5Z9onvSAAAoArVLmFmdqykCyS9HVgXHZpI2BdJ8Ul65/x3dNB+B2ng2IH6Kvsr35EAAEAlqlvCfi/pz5Jec859Z2btJO11mMXM+prZYjNbYma3VLHPeWa2wMy+M7OXq50cVWrWuJnev/B9pTdO1xkvnaFF6xf5jgQAACow51zNHmAWJSnRObdlL/tFS/pe0umSVkmaKWmYc25BuX06SBovqZdzbpOZ7e+cW7en583KynKzZs2qUeaG6seNP+q40cepUUwjTb9sug5IOsB3JAAAGhQzm+2cy6psW7VGwszsZTNLDpwlOV/SAjO7aS8P6y5piXNuqXOuUNJYSWdW2OcKSY855zZJ0t4KGGqm/X7t9fb5b2v99vXq/3J/bS3Y6jsSAAAIqO7hyE6Bka+zJL0rqa3KzpDck1aSVpZbXhVYV15HSR3NbJqZzTCzvtXMg2rKapmlCedO0Ly18zR4wmAVlXBVEQAAwkF1S1ismcWqrIRNDlwfrGbHMSsXI6mDpJMlDZP0tJmlVNzJzK40s1lmNisnJycIL9uwnNHhDD39m6f1/o/v6/I3L1dND0EDAIDgq24Je0rScklNJH1mZm0k7XFOmKRsSa3LLWcE1pW3SoFS55xbprI5ZB0qPpFzbpRzLss5l5Wenl7NyCjvkm6X6B8n/0Nj5o7RrZ/w00YAAPhWrRLmnPu3c66Vc66fK7NC0il7edhMSR3MrK2ZxUkaKmlyhX1eV9komMwsTWWHJ5fWID9q4NaTbtUVR16hOz+/U0/Nesp3HAAAGrTq/mxRU0m3STopsGqqpNsl5Vb1GOdcsZldI2mKyq4pNjpweYvbJc1yzk0ObOttZgsklUi6yTm3odbvBntkZnq8/+NavW21rn7namUkZ6h/x/6+YwEA0CBV6xIVZvaqys6KfD6w6kJJXZxz54QwW6W4RMW+yyvMU8/nemrR+kWaduk0dWnRxXckAAAi0j5fokJSe+fcbYHLTSx1zv1DUrvgRURdahLXRJOHTVZqo1QNeGWAft76s+9IAAA0ONUtYTvM7ISdC2Z2vKQdoYmEutAyqaXeGvaWNudv1m9e+Y3yCvN8RwIAoEGpbgm7StJjZrbczJZLelTSb0OWCnWiS4suGjd4nOasmaPzJ52vktIS35EAAGgwqnt25FznXBdJR0g6wjnXTVKvkCZDnejXoZ8e6fuIJi+erJs/uNl3HAAAGozqjoRJkpxzW8r9ZuQNIcgDD67pfo2u7X6tHpzxoJ6c9aTvOAAANAjVukRFFSxoKeDdQ30e0tJNS3XNO9eobUpb9Tmoj+9IAABEtBqNhFXAb99EkOioaL0y6BV13r+zzp1wrr5b953vSAAARLQ9ljAz22pmWyr5s1VSyzrKiDqSFJ+kN4e9qSZxTTRw7EBt2M51cwEACJU9ljDnXJJzLrmSP0nOuX05lIkw1bppa70+5HVlb8nW4AmDVVRS5DsSAAARaV8ORyJC9cjooWcGPqNPl3+q69+73nccAAAiEqNZqNTwI4br27Xf6t4v7tXh+x+ukUeP9B0JAICIwkgYqnTXqXepf4f+uvbda/XJsk98xwEAIKJQwlCl6KhovTzoZR2cdrAGTxisHzf+6DsSAAARgxKGPUqOT9bkoZMlSQPHDtTWgq2eEwEAEBkoYdir9vu114RzJ2jR+kUa8cYIOccl4gAA2FeUMFRLr7a9dN/p92nSwkm66/O7fMcBAKDeo4Sh2v5wzB90weEX6NZPbtXb37/tOw4AAPUaJQzVZmYa9ZtR6tKiiy6YdIF+2PCD70gAANRblDDUSOPYxnptyGuKiYrRWePOYqI+AAC1RAlDjWWmZGr8ueO1eP1iJuoDAFBLlDDUChP1AQDYN5Qw1Nrvj/k9E/UBAKglShhqjYn6AADUHiUM+4SJ+gAA1A4lDPts50T9ResX6dLJlzJRHwCAaqCEISh6te2lf536L01cMFEPTH/AdxwAAMIeJQxBc+NxN2pwp8H604d/0sfLPvYdBwCAsEYJQ9CYmUYPHK1D0g7RkIlDtDJ3pe9IAACELUoYgiopPkmTzpukguICDRo/SPnF+b4jAQAQlihhCLqD0w7WmLPHaObPM3Xdu9f5jgMAQFiihCEkzjrkLP3lhL/o6a+f1tOzn/YdBwCAsEMJQ8jcfsrt6t2+t6559xp9lf2V7zgAAIQVShhCJjoqWi+f87JaJrXUoPGDtC5vne9IAACEDUoYQqpZ42Z69bxXtX77eg2dOFTFpcW+IwEAEBYoYQi5Iw84Uk/2f1KfLP9Ef/noL77jAAAQFihhqBMXd71YV2ddrfu+uE8TvpvgOw4AAN5RwlBnHur7kI7NOFaXvHGJFuQs8B0HAACvKGGoM3HRcZp43kQlxiXq7HFnKzc/13ckAAC8oYShTrVMaqkJ507Q0k1LdfHrF6vUlfqOBACAF5Qw1LkT25yo+0+/X28sfkP/+t+/fMcBAMALShi8uK7HdTr/8PP114//qilLpviOAwBAnaOEwQsz06gBo9R5/846f9L5WrZpme9IAADUKUoYvGkS10SvDXlNpa5U54w/RzuKdviOBABAnaGEwav2+7XXS+e8pLlr5uqqt6+Sc853JAAA6gQlDN7169BPt/W8TWPmjtETs57wHQcAgDpBCUNYuLXnrRrQcYCuf+96fbHyC99xAAAIOUoYwkKURemFs19Qm6ZtNHj8YK3ZtsZ3JAAAQooShrCRkpCiSUMmKbcgV+dNOE9FJUW+IwEAEDKUMISVI5ofoWd+84w+/+lz3fTBTb7jAAAQMjG+AwAVDTt8mL7K/koPf/mwurfqrvMPP993JAAAgo6RMISle0+/Vye1OUmXT75c89bO8x0HAICgo4QhLMVGx2rc4HFKbZSqs8edrU07NvmOBABAUFHCELZaJLbQxHMnamXuSg1/bbhKXanvSAAABA0lDGHt2NbH6pG+j+idH97R7VNv9x0HAICgoYQh7F2VdZVGdB2hf0z9h976/i3fcQAACApKGMKemenxfo/ryAOO1PBJw7Vk4xLfkQAA2GeUMNQLjWIb6dXzXlV0VLTOHne28grzfEcCAGCfUMJQb2SmZOqVQa/ou3Xf6Yo3r5BzznckAABqjRKGeqV3+966s9edemX+K3rky0d8xwEAoNYoYah3bjnhFp11yFm68f0bNXX5VN9xAACoFUoY6h0z0/NnPa/2+7XXeRPPU/aWbN+RAACosZCWMDPra2aLzWyJmd2yh/0GmZkzs6xQ5kHkSI5P1mtDXtP2ou0aPGGwCooLfEcCAKBGQlbCzCxa0mOSzpDUSdIwM+tUyX5Jkq6X9GWosiAydUrvpGfPfFYzVs3QH6b8wXccAABqJJQjYd0lLXHOLXXOFUoaK+nMSvb7p6R7JOWHMAsi1OBOg3XzcTfriVlP6Lk5z/mOAwBAtYWyhLWStLLc8qrAul3M7EhJrZ1zb4cwByLcnafeqV5te+mqt67S16u/9h0HAIBq8TYx38yiJD0o6Y/V2PdKM5tlZrNycnJCHw71SkxUjMYOGqv9m+yvc8ado/Xb1/uOBADAXoWyhGVLal1uOSOwbqckSZ0lfWpmyyUdI2lyZZPznXOjnHNZzrms9PT0EEZGfZXeJF2vnveqVm9brWGvDlNJaYnvSAAA7FEoS9hMSR3MrK2ZxUkaKmnyzo3OuVznXJpzLtM5lylphqSBzrlZIcyECHZ0q6P1eL/H9eHSD3XrJ7f6jgMAwB6FrIQ554olXSNpiqSFksY7574zs9vNbGCoXhcN22VHXqYrj7xSd//vbr228DXfcQAAqJLVt9/fy8rKcrNmMViGqhUUF+ik507SgpwFmnHZDB22/2G+IwEAGigzm+2cq/Q6qFwxHxEnPiZer573qhLjEjVw7EBt2L7BdyQAAH6FEoaIlJGcodeHvK7sLdkaPGGwikqKfEcCAGA3lDBErB4ZPfTMwGf06fJPdd271/mOAwDAbmJ8BwBCafgRwzV/3XzdM+0eHd78cF199NW+IwEAIImRMDQAd/a6UwM6DtB1716nj5Z+5DsOAACSKGFoAKKjovXSOS/pkLRDdO6Ec/XDhh98RwIAgBKGhiE5PlmTh01WlEVp4NiBys3P9R0JANDAUcLQYLRLbadXz3tVSzYu0dBXh/LTRgAAryhhaFB6ZvbUY/0e03tL3tPNH9zsOw4AoAHj7Eg0OFcedaW+XfutHpzxoDrv31mXdLvEdyQAQAPESBgapIf6PqTT2p2m3771W037aZrvOACABogShgYpJipG4wePV2ZKps4ed7aWbVrmOxIAoIGhhKHBSm2UqsnDJqu4tFhnvHQGvzEJAKhTlDA0aIekHaI3hr6hZZuXaeDYgdpRtMN3JABAA0EJQ4N3YpsT9eLZL2r6yuka/tpwLl0BAKgTlDBA0rmHnasH+zyoSQsn6YYpN8g55zsSACDCcYkKIOD3x/xeP+X+pIdmPKQDmx6oPx73R9+RAAARjBIGlHN/7/u1assq3fjBjWqV3EpDOw/1HQkAEKEoYUA5URalMWeP0Zpta3Tx6xfrgMQD1DOzp+9YAIAIxJwwoIKEmAS9PvR1tU9tr4FjB+qb1d/4jgQAiECUMKAS+zXaT1OGT1FKQor6vNhHi9cv9h0JABBhKGFAFVo3ba0PLvxAZqbTXzhdP+X+5DsSACCCUMKAPejYrKOmDJ+iLQVbdPoLp2td3jrfkQAAEYISBuxF1xZd9fb5b2tl7kr1fbGvcvNzfUcCAEQAShhQDccfeLwmDZmk+evma8ArA7S9aLvvSACAeo4SBlRT34P66sVzXtS0n6bprLFnKb8433ckAEA9RgkDauC8w87T6DNH64OlH2jQ+EEqKC7wHQkAUE9RwoAaGtF1hJ4a8JTe+eEdDZk4REUlRb4jAQDqIUoYUAtXHnWlHj3jUb2x+A2dP+l8FZcW+44EAKhn+NkioJZ+1/13Kiwp1A3v36DYqFi9cPYLio6K9h0LAFBPUMKAffCHY/+ggpIC/fmjPysuOk6jzxytKGOAGQCwd5QwYB/dcsItKiwp1G2f3qa46Dg9OeBJihgAYK8oYUAQ3HrSrSosKdSdn9+puOg4/eeM/8jMfMcCAIQxShgQBGamf57yTxUUF+j+6fcrNipWD/Z5kCIGAKgSJQwIEjPTvaffq8KSQj385cOKj4nX3afeTREDAFSKEgYEkZnp4b4Pq6i0SPdMu0eSKGIAgEpRwoAgMzM92u9RSdI90+5RcWmx7jv9PooYAGA3lDAgBKIsSo/1e0wxUTF6YPoDKi4t1kN9HqKIAQB2oYQBIWJmeqTvI4q2aD385cMqLi3mrEkAwC6UMCCEzEwP9nlQMVExun/6/SopLdFj/R/jOmIAAEoYEGo7z5qMiYrRv6b9S8WlxXrqN09RxACggaOEAXXAzHTXqXcpJipGd3x+h4pdsZ75zTP81iQANGCUMKCOmJn+2eufiomK0d+n/l35xfkac9YYxUbH+o4GAPCAEgbUsdtOvk2NYhvpTx/+SXmFeRp/7nglxCT4jgUAqGNMSgE8uPn4m/V4v8f15vdvasDLA7StcJvvSACAOkYJAzwZefRIPX/W8/pk+Sfq82Ifbc7f7DsSAKAOUcIAjy7qcpHGDx6vmdkz1ev5XsrJy/EdCQBQRyhhgGeDOg3S5GGTtXD9Qp303ElambvSdyQAQB2ghAFhoO9BffX+8Pf189afdfzo47Vo/SLfkQAAIUYJA8LEiW1O1NQRU1VQUqATRp+gmdkzfUcCAIQQJQwII11bdNW0S6cpKT5Jvcb00kdLP/IdCQAQIpQwIMwctN9BmnbpNGWmZKrfy/00ccFE35EAACFACQPCUMuklvpsxGfKapml8yacp1GzR/mOBAAIMkoYEKZSG6Xq/eHvq+9BffXbt36ruz6/S84537EAAEFCCQPCWJO4Jnpj6Bu64PAL9H8f/59Gvj1SxaXFvmMBAIKA344EwlxsdKzGnD1GrZNb61/T/qWVW1Zq3OBxSoxL9B0NALAPGAkD6oEoi9Ldp92tJ/o/ofeWvKeez/XUmm1rfMcCAOwDShhQj1yVdZXeGPqGFq1fpGOeOUYLchb4jgQAqCVKGFDPDOg4QFNHTFV+cb6OH328pi6f6jsSAKAWKGFAPZTVMkszLp+hFokt1PvF3nph7gu+IwEAaogSBtRTmSmZ+uLSL3Rc6+N00esX6eYPblZJaYnvWACAagppCTOzvma22MyWmNktlWy/wcwWmNk8M/vIzNqEMg8QaXZeS2xk1kjd98V9OnPsmdpSsMV3LABANYSshJlZtKTHJJ0hqZOkYWbWqcJu30jKcs4dIWmipHtDlQeIVLHRsXq8/+N6vN/jmvLjFB3zzDFasnGJ71gAgL0I5UhYd0lLnHNLnXOFksZKOrP8Ds65T5xz2wOLMyRlhDAPENFGHj1S7w9/X+vy1qn70931zg/v+I4EANiDUJawVpJWllteFVhXlcskvRvCPEDEO6XtKZp5xUy1SWmj/i/3198++RvzxAAgTIXFxHwzGy4pS9J9VWy/0sxmmdmsnJycug0H1DNtU9vqi0u/0CVdL9E/P/un+r3cT+u3r/cdCwBQQShLWLak1uWWMwLrdmNmp0n6P0kDnXMFlT2Rc26Ucy7LOZeVnp4ekrBAJGkU20j/HfhfjRowSp8u/1RHjTpKM7Nn+o4FACgnlCVspqQOZtbWzOIkDZU0ufwOZtZN0lMqK2DrQpgFaHDMTFccdYWmXTpNJtMJz56gJ2Y+Ieec72gAAIWwhDnniiVdI2mKpIWSxjvnvjOz281sYGC3+yQlSppgZnPMbHIVTweglrJaZmn2lbPVq20vXf3O1Rr66lDl5uf6jgUADZ7Vt38VZ2VluVmzZvmOAdQ7pa5U9067V3/9+K9qk9JG4weP11Etj/IdCwAimpnNds5lVbYtLCbmAwi9KIvSLSfcoqkjpqqwpFDHjT5O//nyPxyeBABPKGFAA3P8gcdrzm/nqHf73rruves0eMJgbc7f7DsWADQ4lDCgAWrWuJkmD52sB3o/oMmLJ6vbU930VfZXvmMBQINCCQMaKDPTDcfeoP9d8j8553T86OP14PQHOTwJAHWEEgY0cD0yeuib336jAR0H6I/v/1H9Xu6nNdvW+I4FABGPEgZAqY1SNem8SXqs32P6dPmnOvyJwzV5MVeMAYBQooQBkFR2ePLqo6/W11d+rYzkDJ059kxd9dZVyivM8x0NACISJQzAbg5NP1QzLpuhm467SU/NfkrdnuqmL1Z+4TsWAEQcShiAX4mPide9p9+rjy76SAUlBTrx2RN10/s3aUfRDt/RACBiUMIAVKlX2176duS3urzb5bp/+v06ctSR+nLVl75jAUBEoIQB2KPk+GQ99ZunNGX4FOUV5um40cfpzx/+WfnF+b6jAUC9RgkDUC292/fWtyO/1SVdL9G/pv1LRzxxhD5e9rHvWABQb1HCAFRb04SmembgM3p/+PsqdaU6dcypuvC1C7Uub53vaABQ71DCANTY6e1P17cjv9WtJ92qcfPH6ZBHD9HTs59WqSv1HQ0A6g1KGIBaaRTbSLefcrvmjZynLi266Mq3rtSJz56ouWvm+o4GAPUCJQzAPjkk7RB9fNHHev6s5/X9hu915Kgj9ds3f8shSgDYC0oYgH1mZrqoy0X64dofdH2P6zV6zmh1+E8HPfDFAyosKfQdDwDCEiUMQNCkJKTowT4Pav7I+TrxwBN14wc3qvPjnfXm4jflnPMdDwDCCiUMQNAdnHaw3jr/Lb13wXuKiYrRwLEDdeqYUzV95XTf0QAgbFDCAIRMn4P6aO5Vc/XoGY9qQc4CHTf6OA18ZaDmrZ3nOxoAeEcJAxBSsdGx+l333+nH637U3aferc9/+lxdnuyiYa8O0+L1i33HAwBvKGEA6kSTuCa65YRbtPS6pfrLCX/R5MWTdehjh2rw+MGa9fMs3/EAoM5RwgDUqdRGqbrz1Du17Ppl+suJf9GHSz/U0U8frdNfOF0fLf2ICfwAGgxKGAAv9m+yv+7odYd++sNPuue0ezR/3Xyd9sJp6vFMD70470V+IBxAxKOEAfAqOT5ZNx9/s5Zdv0xPDXhKm/M368LXLlTrh1rrlg9v0bJNy3xHBICQsPo29J+VleVmzWL+CBCpSl2pPl72sR6f+bjeWPyGnHPq16Gfrj76avVp30fRUdG+IwJAtZnZbOdcVqXbKGEAwtXK3JV6+uunNWr2KK3NW6s2Tdvo4i4X6+KuF6tdajvf8QBgryhhAOq1wpJCvb7odf33m//qgx8/kJNTzzY9NaLrCA3uNFiJcYm+IwJApShhACLGytyVemHeC3p2zrNasnGJGsU00oCOA3TeYeepX4d+ahzb2HdEANiFEgYg4jjnNG3lNL3y7SuauHCi1uWtU+PYxmWFrNN5OqPDGRQyAN5RwgBEtJLSEn224jON/268Xl34qnK256hxbGP1bt9bAzsOVP+O/bV/k/19xwTQAFHCADQYxaXFmrp8qiYtnKQ3v39TK7eslMl0TMYxGnjwQA08eKAOTTtUZuY7KoAGgBIGoEFyzmnu2rmavHiyJi+erNmrZ0uSDmx6oHq17aVT256qUzJPUavkVp6TAohUlDAAkJS9JVtvff+WPlz2oT5Z9ok27NggSTq42cFlhaztKTq+9fE6IOkAz0kBRApKGABUUOpKNW/tPH287GN9tOwjfbbiM20r3CapbKTsmIxjdEyrY3Rs62PVrUU3xcfEe04MoD6ihAHAXhSVFOnr1V9r+qrpmrFqhmasmqEVuSskSXHRcerWopu6t+qubi26qWuLrjps/8MUFx3nOTWAcLenEhZT12EAIBzFRseqR0YP9cjosWvd6q2rdxWy6auma/Q3o5VXlFe2f1SsDtv/MHVr0W1XMevSoouS45N9vQUA9QwjYQBQTSWlJfpx04/6ZvU3+mZN4M/qb5SzPWfXPm2atlGn9E46NO3Qstv0Q3Vo2qFKbZTqMTkAXzgcCQAh4pzT6m2r9c3qbzRnzRx9l/OdFq5fqEXrFym/OH/Xfi0SW/xSzNIO1aHpZfebN2nO5TKACEYJA4A6VlJaohW5K7QwZ6EW5CzQwvW/3G4p2LJrv5SEFHVK76SOzTqqXUo7td+vvdqltlP71PZKa5xGQQPqOUoYAISJnSNnC3IW7FbQftj4g37e+vNu+ybFJaldartdpaxd6i8lrU3TNoqNjvX0LgBUFxPzASBMmJlaJrVUy6SWOq3dabtt21G0Q8s2L9PSTUv148Yfy243/ahF6xfpnR/eUUFJwa59oyxKBzY9cFc5q1jUUhJS6vidAagpShgAhIlGsY3UKb2TOqV3+tW2Uleq1VtX68dNZeVsZ0FbummpXl/0+m4nB0hSakLqboc2y99mJGcoOiq6rt4WgCpwOBIAIsDWgq2/Kmc7b5dvXq7i0uJd+8ZGxSozJVPt92uvA5MPVKvkVmqV1Eotk1ruur9fo/2YjwYEAYcjASDCJcUnqUuLLurSosuvthWXFmvVllW/Osz546YfNfvn2b8aRZOkhJiEXYdNWyS2UPMmzXfdNk9s/styYnMlxCTUxVsEIg4jYQDQwBWWFGr11tXK3pqt7C3Zu25/3vazsrdka23eWq3Ztkab8zdX+vjk+GTt32R/NWvUTPs12k/NGjf75X6jZmrW+Jf7O7cnxSUx0oYGgZEwAECV4qLj1CaljdqktNnjfgXFBVqXt25XKVu7be2u+znbc7Rh+waty1unhesXasP2DdpauLXK54qJiqm0pJUvauW3N41vqqYJTZUUl8R8NkQMShgAoFriY+LVumlrtW7aulr7F5UUaeOOjdqwY0PZ7fYNld/fsUHLNi3T7J9na8OODbtd5LYyiXGJu0pZ0/imSo5P3nW/yvUV1vG7nwgHlDAAQEjERseWzR9LbF6jx20v2r6rqO0sabn5ucotyNWWgi277u9c3rhjo5ZtXrZr/d5KnFQ2521nOUuMS1ST2CZqEtdk99vK1u3lNi46jsOsqDZKGAAgrDSObazGsY2VkZxRq8cXlhTuVtZ2K275geXA/dyCXG0r3Ka8ojxt2L5BPxX9pLzCPOUV5SmvME87infU6LWjLXrvha0W5a5JXBM1imlEwYswlDAAQESJi45TWuM0pTVO2+fnKnWl2l60fbdiVvF2Z4n71bZy97cUbNHqbat322d70XY5Vf/kOJPtKqgJMQmKj4lXQkxC2f3o+N3W7Vze67YK6/b2nIz0BRclDACAKkRZlBLjEpUYlxj053bOaUfxjj0WvMputxdtV0FJgQqKC5RfnK+CkrLbHcU7tDl/827rdu6TX5yvotKioOSucYnbS8GLi45TbFRs2W102W35deXX72ldfTxhgxIGAIAHZr+MbKUrPeSvV+pKVVBc8KuCtnO5snXlS9weH1duW15hnjbu2Fjl48tfODiYoiyq2sVt5/qBBw/UNd2vCUme6qCEAQDQAERZlBrFNlKj2EZec5SUluw2kldUWqTCkkIVlZTdFpYU7lpXfn1115Vfv6fHbC3cqu1F273+XVDCAABAnYmOilbjqLIRwIYuyncAAACAhogSBgAA4AElDAAAwANKGAAAgAeUMAAAAA8oYQAAAB6EtISZWV8zW2xmS8zslkq2x5vZuMD2L80sM5R5AAAAwkXISpiZRUt6TNIZkjpJGmZmnSrsdpmkTc65gyQ9JOmeUOUBAAAIJ6EcCesuaYlzbqlzrlDSWElnVtjnTEnPB+5PlHSq8cugAACgAQhlCWslaWW55VWBdZXu45wrlpQrqVkIMwEAAISFejEx38yuNLNZZjYrJyfHdxwAAIB9FsoSli2pdbnljMC6SvcxsxhJTSVtqPhEzrlRzrks51xWenrof2keAAAg1EJZwmZK6mBmbc0sTtJQSZMr7DNZ0sWB+4MlfeyccyHMBAAAEBZiQvXEzrliM7tG0hRJ0ZJGO+e+M7PbJc1yzk2W9F9JL5jZEkkbVVbUAAAAIl7ISpgkOefekfROhXV/K3c/X9K5ocwAAAAQjurFxHwAAIBIQwkDAADwgBIGAADggdW3kxHNLEfSijp4qTRJ6+vgdVB9fCbhic8l/PCZhCc+l/BTF59JG+dcpdfXqnclrK6Y2SznXJbvHPgFn0l44nMJP3wm4YnPJfz4/kw4HAkAAOABJQwAAMADSljVRvkOgF/hMwlPfC7hh88kPPG5hB+vnwlzwgAAADxgJAwAAMADSlgFZtbXzBab2RIzu8V3nobCzFqb2SdmtsDMvjOz6wPr9zOzD8zsh8BtamC9mdm/A5/TPDM70u87iGxmFm1m35jZW4Hltmb2ZeDvf5yZxQXWxweWlwS2Z3oNHsHMLMXMJprZIjNbaGbH8n3xy8z+EPjv13wze8XMEviu1D0zG21m68xsfrl1Nf5umNnFgf1/MLOLQ5GVElaOmUVLekzSGZI6SRpmZp38pmowiiX90TnXSdIxkn4X+Lu/RdJHzrkOkj4KLEtln1GHwJ8rJT1R95EblOslLSy3fI+kh5xzB0naJOmywPrLJG0KrH8osB9C4xFJ7znnDpHURWWfD98XT8yslaTrJGU55zpLipY0VHxXfHhOUt8K62r03TCz/STdJqmHpO6SbttZ3IKJEra77pKWOOeWOucKJY2VdKbnTA2Cc261c+7rwP2tKvsfSiuV/f0/H9jteUlnBe6fKWmMKzNDUoqZHVC3qRsGM8uQ1F/SM4Flk9RL0sTALhU/l52f10RJpwb2RxCZWVNJJ0n6ryQ55wqdc5vF98W3GEmNzCxGUmNJq8V3pc455z6TtLHC6pp+N/pI+sA5t9E5t0nSB/p1sdtnlLDdtZK0stzyqsA61KHAsHw3SV9Kau6cWx3YtEZS88B9Pqu687CkmyWVBpabSdrsnCsOLJf/u9/1uQS25wb2R3C1lZQj6dnAYeJnzKyJ+L5445zLlnS/pJ9UVr5yJc0W35VwUdPvRp18ZyhhCCtmlijpVUm/d85tKb/NlZ3Ky+m8dcjMBkha55yb7TsLdhMj6UhJTzjnuknK0y+HVyTxfalrgUNVZ6qsILeU1EQhGDnBvgun7wYlbHfZklqXW84IrEMdMLNYlRWwl5xzkwKr1+48bBK4XRdYz2dVN46XNNDMlqvs8Hwvlc1FSgkccpF2/7vf9bkEtjeVtKEuAzcQqyStcs59GVieqLJSxvfFn9MkLXPO5TjniiRNUtn3h+9KeKjpd6NOvjOUsN3NlNQhcDZLnMomVU72nKlBCMyF+K+khc65B8ttmixp51kpF0t6o9z6iwJnthwjKbfcUDOCxDn3Z+dchnMuU2Xfh4+dcxdI+kTS4MBuFT+XnZ/X4MD+YfEvzkjinFsjaaWZHRxYdaqkBeL74tNPko4xs8aB/57t/Ez4roSHmn43pkjqbWapgVHO3oF1QcXFWisws34qmwMTLWm0c+5Ov4kaBjM7QdLnkr7VL3OP/qKyeWHjJR0oaYWk85xzGwP/kXtUZcP92yVd4pybVefBGxAzO1nSjc65AWbWTmUjY/tJ+kbScOdcgZklSHpBZXP6Nkoa6pxb6ilyRDOzrio7WSJO0lJJl6jsH9Z8Xzwxs39IGqKys72/kXS5yuYR8V2pQ2b2iqSTJaVJWquysxxfVw2/G2Z2qcr+PyRJdzrnng16VkoYAABA3eNwJAAAgAeUMAAAAA8oYQAAAB5QwgAAADyghAEAAHhACQNQ75lZiZnNKffnlr0/qtrPnWlm84P1fACwU8zedwGAsLfDOdfVdwgAqAlGwgBELDNbbmb3mtm3ZvaVmR0UWJ9pZh+b2Twz+8jMDgysb25mr5nZ3MCf4wJPFW1mT5vZd2b2vpk1Cux/nZktCDzPWE9vE0A9RQkDEAkaVTgcOaTctlzn3OEquyr2w4F1/5H0vHPuCEkvSfp3YP2/JU11znVR2W8xfhdY30HSY865wyRtljQosP4WSd0Cz3NVaN4agEjFFfMB1Htmts05l1jJ+uWSejnnlgZ+IH6Nc66Zma2XdIBzriiwfrVzLs3MciRlOOcKyj1HpqQPnHMdAst/khTrnLvDzN6TtE1lP4nyunNuW4jfKoAIwkgYgEjnqrhfEwXl7pfol/m0/SU9prJRs5lmxjxbANVGCQMQ6YaUu50euP+FpKGB+xeo7MfjJekjSSMlycyizaxpVU9qZlGSWjvnPpH0J0lNJf1qNA4AqsK/2gBEgkZmNqfc8nvOuZ2XqUg1s3kqG80aFlh3raRnzewmSTmSLgmsv17SKDO7TGUjXiMlra7iNaMlvRgoaibp3865zUF6PwAaAOaEAYhYgTlhWc659b6zAEBFHI4EAADwgJEwAAAADxgJAwAA8IASBgAA4AElDAAAwANKGAAAgAeUMAAAAA8oYQAAAB78P6Mvr2U0CU/WAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10,8))\n",
    "plt.plot(history.history['loss'] ,'g', label='loss')\n",
    "plt.title('Model loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c2ef2b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (15,8))\n",
    "plt.plot(history.history['accuracy'], 'b', label='accuracy')\n",
    "\n",
    "plt.title('Model accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30c6e08",
   "metadata": {},
   "source": [
    "## Final Weights and bias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b6c32ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "342041aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.08623009, -0.44842187],\n",
       "        [ 0.94137335, -1.093294  ],\n",
       "        [-1.9437525 ,  0.3843769 ],\n",
       "        [ 1.2778696 , -2.1199322 ]], dtype=float32),\n",
       " array([-0.893957 , -0.2536908], dtype=float32)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b1024f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.08623009, -0.44842187],\n",
       "       [ 0.94137335, -1.093294  ],\n",
       "       [-1.9437525 ,  0.3843769 ],\n",
       "       [ 1.2778696 , -2.1199322 ]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "08a1b4dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.893957 , -0.2536908], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a8402a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "deep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
